<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Filtered Computational Linguistics Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss.xml</link><description>Filtered arXiv papers on computational linguistics</description><lastBuildDate>Wed, 16 Oct 2024 17:29:10 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Crafting Narrative Closures: Zero-Shot Learning with SSM Mamba for Short Story Ending Generation</title><link>https://arxiv.org/abs/2410.10848</link><description>arXiv:2410.10848v1 Announce Type: new 
Abstract: Writing stories is an engaging yet challenging endeavor. Often, authors encounter moments of creative block, where the path forward in their narrative becomes obscured. This paper is designed to address such moments by providing an innovative solution: A tool that completes stories based on given prompts. By inputting a short story prompt, users can receive a conclusion to their story, articulated in one sentence or more, thereby enhancing the storytelling process with AI-driven creativity. This tool aims not only to assist authors in navigating writer's block but also to offer a fun and interactive way for anyone to expand on story ideas spontaneously. Through this paper, we explore the intersection of artificial intelligence and creative writing, pushing the boundaries of how stories can be crafted and concluded. To create our final text-generation models, we used a pre-trained GPT-3.5 model and a newly created finetuned SSM-Mamba model, both of which perform well on a comprehensive list of metrics including BERT score, METEOR, BLEU, ROUGE, and Perplexity. The SSM model has also been made public for the NLP community on HuggingFace models as an open source contribution, which for the timebeing is a first of its kind state-space model for story-generation task on HuggingFace.</description><pubDate>Wed, 16 Oct 2024 17:29:10 GMT</pubDate></item><item><title>On the Reliability of Large Language Models to Misinformed and Demographically-Informed Prompts</title><link>https://arxiv.org/abs/2410.10850</link><description>arXiv:2410.10850v1 Announce Type: new 
Abstract: We investigate and observe the behaviour and performance of Large Language Model (LLM)-backed chatbots in addressing misinformed prompts and questions with demographic information within the domains of Climate Change and Mental Health. Through a combination of quantitative and qualitative methods, we assess the chatbots' ability to discern the veracity of statements, their adherence to facts, and the presence of bias or misinformation in their responses. Our quantitative analysis using True/False questions reveals that these chatbots can be relied on to give the right answers to these close-ended questions. However, the qualitative insights, gathered from domain experts, shows that there are still concerns regarding privacy, ethical implications, and the necessity for chatbots to direct users to professional services. We conclude that while these chatbots hold significant promise, their deployment in sensitive areas necessitates careful consideration, ethical oversight, and rigorous refinement to ensure they serve as a beneficial augmentation to human expertise rather than an autonomous solution.</description><pubDate>Wed, 16 Oct 2024 17:29:10 GMT</pubDate></item><item><title>SafeLLM: Domain-Specific Safety Monitoring for Large Language Models: A Case Study of Offshore Wind Maintenance</title><link>https://arxiv.org/abs/2410.10852</link><description>arXiv:2410.10852v1 Announce Type: new 
Abstract: The Offshore Wind (OSW) industry is experiencing significant expansion, resulting in increased Operations \&amp; Maintenance (O\&amp;amp;M) costs. Intelligent alarm systems offer the prospect of swift detection of component failures and process anomalies, enabling timely and precise interventions that could yield reductions in resource expenditure, as well as scheduled and unscheduled downtime. This paper introduces an innovative approach to tackle this challenge by capitalising on Large Language Models (LLMs). We present a specialised conversational agent that incorporates statistical techniques to calculate distances between sentences for the detection and filtering of hallucinations and unsafe output. This potentially enables improved interpretation of alarm sequences and the generation of safer repair action recommendations by the agent. Preliminary findings are presented with the approach applied to ChatGPT-4 generated test sentences. The limitation of using ChatGPT-4 and the potential for enhancement of this agent through re-training with specialised OSW datasets are discussed.</description><pubDate>Wed, 16 Oct 2024 17:29:10 GMT</pubDate></item></channel></rss>