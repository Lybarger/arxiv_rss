<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Irrelevant arXiv Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss_irrelevant.xml</link><description>Irrelevant arXiv Papers</description><lastBuildDate>Thu, 24 Oct 2024 11:15:41 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation</title><link>https://arxiv.org/abs/2410.13944</link><description>https://arxiv.org/abs/2410.13944&lt;br /&gt;The paper presents RaDis (Rationale Distillation), a novel method that enhances the machine translation skills of Large Language Models (LLMs) while preserving their overall general capabilities by replaying self-generated rationales to prevent forgetting during training.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>From Single to Multi: How LLMs Hallucinate in Multi-Document Summarization</title><link>https://arxiv.org/abs/2410.13961</link><description>https://arxiv.org/abs/2410.13961&lt;br /&gt;This study investigates how hallucinations occur in large language models (LLMs) during multi-document summarization, revealing that up to 75% of content generated can be fabricated, especially in the latter parts of summaries, and emphasizes the need for better mitigation strategies against such errors.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Detecting AI-Generated Texts in Cross-Domains</title><link>https://arxiv.org/abs/2410.13966</link><description>https://arxiv.org/abs/2410.13966&lt;br /&gt;The paper presents RoBERTa-Ranker, a modified ranking classifier that enhances the detection of AI-generated texts across different domains by leveraging fine-tuning techniques with limited labeled data, outperforming existing tools like DetectGPT and GPTZero.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Are LLMs Models of Distributional Semantics? A Case Study on Quantifiers</title><link>https://arxiv.org/abs/2410.13984</link><description>https://arxiv.org/abs/2410.13984&lt;br /&gt;This paper evaluates the performance of Large Language Models (LLMs) in capturing distributional semantics, particularly focusing on their ability to understand vague and exact quantifiers, and finds that LLMs align more closely with human judgments on exact quantifiers than previously expected.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLMs are Biased Teachers: Evaluating LLM Bias in Personalized Education</title><link>https://arxiv.org/abs/2410.14012</link><description>https://arxiv.org/abs/2410.14012&lt;br /&gt;This paper evaluates biases in large language models (LLMs) used in personalized education, highlighting significant disparities in how educational content is generated for different demographic groups, and proposes two metrics to analyze these biases.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Measuring and Modifying the Readability of English Texts with GPT-4</title><link>https://arxiv.org/abs/2410.14028</link><description>https://arxiv.org/abs/2410.14028&lt;br /&gt;This paper investigates the ability of Large Language Models (LLMs) like GPT-4 to assess and modify the readability of English texts, demonstrating high correlation with human judgments and indicating potential for making texts more accessible, despite some unexplained variance in responses.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Efficient Retrieval of Temporal Event Sequences from Textual Descriptions</title><link>https://arxiv.org/abs/2410.14043</link><description>https://arxiv.org/abs/2410.14043&lt;br /&gt;TPP-LLM-Embedding is a unified model that enhances the retrieval of temporal event sequences from textual descriptions by integrating large language models with temporal point processes, enabling efficient embedding and improved performance over baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Learning Metadata-Agnostic Representations for Text-to-SQL In-Context Example Selection</title><link>https://arxiv.org/abs/2410.14049</link><description>https://arxiv.org/abs/2410.14049&lt;br /&gt;MARLO is a technique that enables more effective selection of in-context examples for Text-to-SQL tasks by learning metadata-agnostic representations, aligning natural language questions and SQL queries in a shared embedding space to enhance execution accuracy.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Learning Multimodal Cues of Children's Uncertainty</title><link>https://arxiv.org/abs/2410.14050</link><description>https://arxiv.org/abs/2410.14050&lt;br /&gt;This paper introduces a novel dataset for studying nonverbal cues of children's uncertainty and presents a multimodal machine learning model that predicts uncertainty from video clips, highlighting the importance of understanding uncertainty in human-AI collaboration.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs</title><link>https://arxiv.org/abs/2410.14057</link><description>https://arxiv.org/abs/2410.14057&lt;br /&gt;This paper presents XC-Translate, a benchmark for cross-cultural machine translation focusing on culturally-nuanced entity names, and proposes KG-MT, a novel method that integrates multilingual knowledge graphs into translation models using a dense retrieval mechanism, achieving significant performance improvements over existing models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Be My Donor. Transfer the NLP Datasets Between the Languages Using LLM</title><link>https://arxiv.org/abs/2410.14074</link><description>https://arxiv.org/abs/2410.14074&lt;br /&gt;The paper explores how Large Language Models (LLMs) can be utilized to transfer datasets and annotations between languages, specifically translating the DEFT corpus from English to Russian, to enhance resource availability and expedite data annotation efforts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Lightweight Multi Aspect Controlled Text Generation Solution For Large Language Models</title><link>https://arxiv.org/abs/2410.14144</link><description>https://arxiv.org/abs/2410.14144&lt;br /&gt;This paper presents a lightweight data augmentation pipeline for Multi-Aspect Controllable Text Generation (MCTG) in Large Language Models (LLMs), addressing biases and correlations in traditional datasets, leading to improved performance and accuracy.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent</title><link>https://arxiv.org/abs/2410.14152</link><description>https://arxiv.org/abs/2410.14152&lt;br /&gt;SRAP-Agent is a framework that utilizes Large Language Models (LLMs) to enhance the simulation and optimization of public scarce resource allocation policies, addressing limitations of traditional methods by incorporating real-world dynamics into economic simulations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Towards Faithful Natural Language Explanations: A Study Using Activation Patching in Large Language Models</title><link>https://arxiv.org/abs/2410.14155</link><description>https://arxiv.org/abs/2410.14155&lt;br /&gt;This paper presents a novel metric called Causal Faithfulness, which measures the consistency of causal attributions in Natural Language Explanations generated by Large Language Models (LLMs), proposing that models with alignment tuning yield more faithful explanations than those tested by traditional methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning</title><link>https://arxiv.org/abs/2410.14157</link><description>https://arxiv.org/abs/2410.14157&lt;br /&gt;The paper presents a novel approach using discrete diffusion models for complex reasoning and planning tasks, which demonstrates significant performance improvements over traditional autoregressive language models in handling challenging subgoals.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Automated Genre-Aware Article Scoring and Feedback Using Large Language Models</title><link>https://arxiv.org/abs/2410.14165</link><description>https://arxiv.org/abs/2410.14165&lt;br /&gt;The paper presents an advanced article scoring system that combines the BERT model and Chat-GPT to provide genre-aware evaluations and personalized feedback on written work, outperforming traditional methods in quality assessments.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLM The Genius Paradox: A Linguistic and Math Expert's Struggle with Simple Word-based Counting Problems</title><link>https://arxiv.org/abs/2410.14166</link><description>https://arxiv.org/abs/2410.14166&lt;br /&gt;This paper examines the limitations of Large Language Models (LLMs) in performing simple word-based counting tasks, explores reasons behind their deficiencies, and advocates for leveraging reasoning capabilities to improve performance on such tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart Problems</title><link>https://arxiv.org/abs/2410.14179</link><description>https://arxiv.org/abs/2410.14179&lt;br /&gt;MultiChartQA introduces a benchmark for evaluating Multimodal Large Language Models (MLLMs) on complex multi-chart problems, focusing on various reasoning tasks that reflect real-world applications and highlighting performance gaps compared to human abilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>XForecast: Evaluating Natural Language Explanations for Time Series Forecasting</title><link>https://arxiv.org/abs/2410.14180</link><description>https://arxiv.org/abs/2410.14180&lt;br /&gt;XForecast introduces new performance metrics for evaluating natural language explanations in time series forecasting, focusing on their accessibility to laypeople and the correlation of these metrics with human judgments, while also assessing the explanatory capabilities of large language models (LLMs).</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs</title><link>https://arxiv.org/abs/2410.14182</link><description>https://arxiv.org/abs/2410.14182&lt;br /&gt;LabSafety Bench introduces a benchmarking framework to evaluate the reliability of large language models (LLMs) in providing safety guidance for laboratory settings, highlighting their critical errors despite outperforming human participants.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Speciesism in Natural Language Processing Research</title><link>https://arxiv.org/abs/2410.14194</link><description>https://arxiv.org/abs/2410.14194&lt;br /&gt;This study investigates speciesism, or discrimination against nonhuman animals, in Natural Language Processing (NLP) research, revealing its presence among researchers, in datasets, and within NLP models, and discusses potential strategies for mitigation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Supervised Chain of Thought</title><link>https://arxiv.org/abs/2410.14198</link><description>https://arxiv.org/abs/2410.14198&lt;br /&gt;The paper 'Supervised Chain of Thought' demonstrates that task-specific supervision is crucial for optimizing the prompt use in Large Language Models (LLMs) to enhance reasoning performance, overcoming the limitations of a 'one-prompt-for-all' approach.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Rationale Behind Essay Scores: Enhancing S-LLM's Multi-Trait Essay Scoring with Rationale Generated by LLMs</title><link>https://arxiv.org/abs/2410.14202</link><description>https://arxiv.org/abs/2410.14202&lt;br /&gt;The paper introduces Rationale-based Multiple Trait Scoring (RMTS), a novel method for automated essay scoring that combines large language models with trait-specific rationale generation to improve the accuracy and reliability of multi-trait essay evaluation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning</title><link>https://arxiv.org/abs/2410.14208</link><description>https://arxiv.org/abs/2410.14208&lt;br /&gt;Montessori-Instruct is a data synthesis framework that improves the generation of training data for language models by aligning synthetic data with the learning preferences of student models, leading to significant improvements in their performance over traditional synthesis methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model</title><link>https://arxiv.org/abs/2410.14225</link><description>https://arxiv.org/abs/2410.14225&lt;br /&gt;The paper presents the Knowledge-Enhanced Cross-modal Prompt Model (KECPM) for Few-Shot Joint Multimodal Entity-Relation Extraction, which generates supplementary background knowledge to improve performance on multimodal data involving text-image pairs, surpassing existing methods in evaluation metrics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Unveiling Large Language Models Generated Texts: A Multi-Level Fine-Grained Detection Framework</title><link>https://arxiv.org/abs/2410.14231</link><description>https://arxiv.org/abs/2410.14231&lt;br /&gt;The Multi-level Fine-grained Detection (MFD) framework proposed in this research enhances the detection of Large Language Model (LLM)-generated texts by integrating multiple levels of analysis, improving robustness against evasion techniques, and providing a mechanism to address concerns over authorship and originality.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Towards Robust Knowledge Representations in Multilingual LLMs for Equivalence and Inheritance based Consistent Reasoning</title><link>https://arxiv.org/abs/2410.14235</link><description>https://arxiv.org/abs/2410.14235&lt;br /&gt;The paper investigates the limitations of Large Language Models (LLMs) in performing consistent reasoning across languages, introducing new tasks and benchmarks to evaluate their understanding of equivalence and inheritance relationships, and proposing 'Compositional Representations' to enhance multilingual reasoning consistency.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Novel Method to Metigate Demographic and Expert Bias in ICD Coding with Causal Inference</title><link>https://arxiv.org/abs/2410.14236</link><description>https://arxiv.org/abs/2410.14236&lt;br /&gt;The paper presents DECI, a causal inference-based method designed to mitigate demographic and expert biases in ICD coding, demonstrating improved accuracy and reduced spurious correlations compared to existing models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models</title><link>https://arxiv.org/abs/2410.14248</link><description>https://arxiv.org/abs/2410.14248&lt;br /&gt;This research paper investigates selection bias in Multiple-Choice Question Answering (MCQA) for Video Language Models (VLMs), proposing a calibration technique called BOLD to enhance performance by reducing the impact of bias and improving genuine understanding in evaluations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MoDification: Mixture of Depths Made Easy</title><link>https://arxiv.org/abs/2410.14268</link><description>https://arxiv.org/abs/2410.14268&lt;br /&gt;MoDification presents a method for optimizing large language models (LLMs) by leveraging a mixture of depths to significantly enhance efficiency in terms of latency and memory usage, especially for long-context tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>REEF: Representation Encoding Fingerprints for Large Language Models</title><link>https://arxiv.org/abs/2410.14273</link><description>https://arxiv.org/abs/2410.14273&lt;br /&gt;REEF is a training-free method for identifying relationships between Large Language Models by comparing their feature representations via centered kernel alignment similarity, aiming to protect intellectual property without impairing model capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>EcomEdit: An Automated E-commerce Knowledge Editing Framework for Enhanced Product and Purchase Intention Understanding</title><link>https://arxiv.org/abs/2410.14276</link><description>https://arxiv.org/abs/2410.14276&lt;br /&gt;ECOMEDIT is an automated framework that applies Knowledge Editing to enhance Large Language Models' understanding of product features and customer purchase intentions in the e-commerce sector by enabling automatic conflict detection and improving semantic coverage.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LoGU: Long-form Generation with Uncertainty Expressions</title><link>https://arxiv.org/abs/2410.14309</link><description>https://arxiv.org/abs/2410.14309&lt;br /&gt;LoGU introduces the task of Long-form Generation with Uncertainty, addressing challenges in allowing Large Language Models (LLMs) to express uncertainty accurately while generating longer responses, improving accuracy and reducing hallucinations through a specialized data collection and training approach.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Efficiently Computing Susceptibility to Context in Language Models</title><link>https://arxiv.org/abs/2410.14361</link><description>https://arxiv.org/abs/2410.14361&lt;br /&gt;The paper introduces Fisher susceptibility, an efficient method for estimating the sensitivity of language models to context changes in user queries, demonstrating its effectiveness compared to traditional Monte Carlo methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>How Do Multilingual Models Remember? Investigating Multilingual Factual Recall Mechanisms</title><link>https://arxiv.org/abs/2410.14387</link><description>https://arxiv.org/abs/2410.14387&lt;br /&gt;This paper investigates the mechanisms of factual recall in multilingual Large Language Models (LLMs) and examines the extent to which findings from English monolingual models apply to multilingual contexts, identifying both language-independent and language-dependent mechanisms.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Analyzing Context Utilization of LLMs in Document-Level Translation</title><link>https://arxiv.org/abs/2410.14391</link><description>https://arxiv.org/abs/2410.14391&lt;br /&gt;This paper examines the context utilization of large language models (LLMs) in document-level translation, revealing that while LLMs show enhanced overall translation capabilities, their performance on pronoun translation does not consistently reflect these improvements, emphasizing the importance of context-aware fine-tuning.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Generative AI, Pragmatics, and Authenticity in Second Language Learning</title><link>https://arxiv.org/abs/2410.14395</link><description>https://arxiv.org/abs/2410.14395&lt;br /&gt;This paper discusses the limitations and challenges of using generative AI in second language learning, highlighting issues of cultural bias and the lack of pragmatics and authenticity in AI-generated language compared to human interaction.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic Reasoning</title><link>https://arxiv.org/abs/2410.14399</link><description>https://arxiv.org/abs/2410.14399&lt;br /&gt;SylloBio-NLI introduces a framework for evaluating Large Language Models on biomedical syllogistic reasoning, revealing challenges in zero-shot performance and improvements with few-shot prompting, while highlighting dependencies on model architecture and pre-training for biomedical applications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation</title><link>https://arxiv.org/abs/2410.14425</link><description>https://arxiv.org/abs/2410.14425&lt;br /&gt;The paper presents W2SDefense, a weak-to-strong unlearning algorithm that uses feature alignment knowledge distillation to help large language models (LLMs) effectively unlearn backdoor attacks while maintaining their performance on downstream tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Systematic Study of Cross-Layer KV Sharing for Efficient LLM Inference</title><link>https://arxiv.org/abs/2410.14442</link><description>https://arxiv.org/abs/2410.14442&lt;br /&gt;This paper presents a systematic study on cross-layer key-value (KV) sharing techniques for enhancing the efficiency of large language models (LLMs) during inference, demonstrating that reduced KV cache sizes can maintain competitive performance while improving throughput in various configurations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Combining Entropy and Matrix Nuclear Norm for Enhanced Evaluation of Language Models</title><link>https://arxiv.org/abs/2410.14480</link><description>https://arxiv.org/abs/2410.14480&lt;br /&gt;This paper presents a novel hybrid evaluation method for large language models (LLMs) that combines entropy from covariance matrices and the Matrix Nuclear Norm, offering a comprehensive, efficient evaluation framework adaptable to various objectives.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SignAttention: On the Interpretability of Transformer Models for Sign Language Translation</title><link>https://arxiv.org/abs/2410.14506</link><description>https://arxiv.org/abs/2410.14506&lt;br /&gt;This paper provides an interpretability analysis of a Transformer model for Sign Language Translation, revealing how the model aligns visual inputs with corresponding glosses and text, highlighting the dynamics of attention mechanisms throughout the translation process.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization</title><link>https://arxiv.org/abs/2410.14545</link><description>https://arxiv.org/abs/2410.14545&lt;br /&gt;This paper presents a multi-source meeting summarization approach using large language models that enhances summary relevance and informativeness by integrating supplementary materials and personalizing outputs based on participant characteristics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Large Language Models Are Overparameterized Text Encoders</title><link>https://arxiv.org/abs/2410.14578</link><description>https://arxiv.org/abs/2410.14578&lt;br /&gt;This paper demonstrates that large language models (LLMs) can be effectively pruned to reduce memory and inference time with minimal performance impact, leading to the conclusion that LLMs are overparameterized for text embedding tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Dialetto, ma Quanto Dialetto? Transcribing and Evaluating Dialects on a Continuum</title><link>https://arxiv.org/abs/2410.14589</link><description>https://arxiv.org/abs/2410.14589&lt;br /&gt;This research investigates within-dialect variation in Italian dialects by measuring speech-to-text performance and revealing geographical disparities that correlate with linguistic similarity, while suggesting that existing models bias performance towards dialects similar to standard varieties.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases</title><link>https://arxiv.org/abs/2410.14594</link><description>https://arxiv.org/abs/2410.14594&lt;br /&gt;Toolshed introduces a tool knowledge base and Advanced RAG-Tool Fusion techniques to enhance the performance and retrieval accuracy of tool-equipped agents by optimizing tool selection without requiring model fine-tuning.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>You Shall Know a Tool by the Traces it Leaves: The Predictability of Sentiment Analysis Tools</title><link>https://arxiv.org/abs/2410.14626</link><description>https://arxiv.org/abs/2410.14626&lt;br /&gt;This paper demonstrates that different sentiment analysis tools yield inconsistent results across various datasets and languages, revealing an algorithmic bias that can be predicted from their outcomes, and emphasizes the necessity for improved evaluation standards in natural language processing (NLP).</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>GenEOL: Harnessing the Generative Power of LLMs for Training-Free Sentence Embeddings</title><link>https://arxiv.org/abs/2410.14635</link><description>https://arxiv.org/abs/2410.14635&lt;br /&gt;GenEOL introduces a novel method for obtaining training-free sentence embeddings by leveraging the generative capabilities of large language models (LLMs) to create diverse transformations of sentences, significantly improving performance in semantic text similarity and related tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs</title><link>https://arxiv.org/abs/2410.14641</link><description>https://arxiv.org/abs/2410.14641&lt;br /&gt;The research presents LongPiBench, a benchmark to evaluate positional bias in large language models (LLMs) when processing multiple relevant information pieces, revealing significant biases related to their spacing and the challenges posed by the 'lost in the middle' phenomenon.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie Character-Aware Discourse Graph</title><link>https://arxiv.org/abs/2410.14666</link><description>https://arxiv.org/abs/2410.14666&lt;br /&gt;DiscoGraMS introduces a novel discourse graph representation for movie screenplays that enhances summarization by capturing complex character interactions and contextual nuances, while addressing limitations of current transformer models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image Description and Reasoning Steps</title><link>https://arxiv.org/abs/2410.14668</link><description>https://arxiv.org/abs/2410.14668&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning chains in Multimodal Chain of Thought (MCoT) among multimodal large language models (MLLMs) by assessing both image descriptions and the correctness of reasoning steps.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment</title><link>https://arxiv.org/abs/2410.14676</link><description>https://arxiv.org/abs/2410.14676&lt;br /&gt;SudoLM introduces a framework that enables Large Language Models (LLMs) to learn access control over parametric knowledge using authorization alignment, allowing qualified users to access specific knowledge while restricting it from non-qualified users.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Are AI Detectors Good Enough? A Survey on Quality of Datasets With Machine-Generated Texts</title><link>https://arxiv.org/abs/2410.14677</link><description>https://arxiv.org/abs/2410.14677&lt;br /&gt;This paper surveys the quality of datasets used for training AI detectors of machine-generated texts, questioning the reliability of these detectors and advocating for improved methods in evaluating and enhancing the datasets involved.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Stars, Stripes, and Silicon: Unravelling the ChatGPT's All-American, Monochrome, Cis-centric Bias</title><link>https://arxiv.org/abs/2410.13868</link><description>https://arxiv.org/abs/2410.13868&lt;br /&gt;The paper explores the biases, toxicity, and unreliability of large language models like ChatGPT, attributing these issues to the quality and diversity of training data rather than model architectures, and calls for interdisciplinary collaboration to address these challenges and mitigate societal harm.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Observing the Southern US Culture of Honor Using Large-Scale Social Media Analysis</title><link>https://arxiv.org/abs/2410.13887</link><description>https://arxiv.org/abs/2410.13887&lt;br /&gt;This study examines the 'culture of honor' in the Southern US by analyzing social media interactions, finding that individuals from this region are more likely to retaliate to insults, and utilizes GPT-3.5 for geolocation and insult detection.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>NSmark: Null Space Based Black-box Watermarking Defense Framework for Pre-trained Language Models</title><link>https://arxiv.org/abs/2410.13907</link><description>https://arxiv.org/abs/2410.13907&lt;br /&gt;NSmark is a black-box watermarking defense framework designed for pre-trained language models that resists Linear Functionality Equivalence Attacks by leveraging the invariant properties of the output matrix's null space, ensuring the protection of intellectual property in language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Automatically Interpreting Millions of Features in Large Language Models</title><link>https://arxiv.org/abs/2410.13928</link><description>https://arxiv.org/abs/2410.13928&lt;br /&gt;This paper presents an automated pipeline developed to generate and evaluate natural language explanations for features from sparse autoencoders in large language models, employing new techniques to assess explanation quality and enhancing the interpretability of neural network activations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Identifying High Consideration E-Commerce Search Queries</title><link>https://arxiv.org/abs/2410.13951</link><description>https://arxiv.org/abs/2410.13951&lt;br /&gt;The paper introduces an Engagement-based Query Ranking (EQR) approach to identify High Consideration e-commerce search queries, enabling better user experiences and improved engagement through targeted search features.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Debiasing Large Vision-Language Models by Ablating Protected Attribute Representations</title><link>https://arxiv.org/abs/2410.13976</link><description>https://arxiv.org/abs/2410.13976&lt;br /&gt;This research introduces a debiasing framework for Large Vision-Language Models (LVLMs) that aims to reduce societal biases in text generation by ablating biased attribute representations without requiring additional training.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Graph Neural Flows for Unveiling Systemic Interactions Among Irregularly Sampled Time Series</title><link>https://arxiv.org/abs/2410.14030</link><description>https://arxiv.org/abs/2410.14030&lt;br /&gt;This paper presents a graph-based model called graph neural flows that effectively captures systemic interactions among irregularly sampled time series by learning conditional dependencies and improving prediction accuracy compared to traditional methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models</title><link>https://arxiv.org/abs/2410.14059</link><description>https://arxiv.org/abs/2410.14059&lt;br /&gt;The UCFE benchmark is a user-centric framework for evaluating large language models' ability to manage complex financial tasks, combining human expert assessments with dynamic interactions to simulate real-world scenarios, and demonstrating alignment with user preferences.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Efficient Vision-Language Models by Summarizing Visual Tokens into Compact Registers</title><link>https://arxiv.org/abs/2410.14072</link><description>https://arxiv.org/abs/2410.14072&lt;br /&gt;The paper introduces 'Victor', a method to enhance the efficiency of vision-language models by summarizing visual tokens into a compact set of register tokens, significantly improving computational efficiency while maintaining model performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ViConsFormer: Constituting Meaningful Phrases of Scene Texts using Transformer-based Method in Vietnamese Text-based Visual Question Answering</title><link>https://arxiv.org/abs/2410.14132</link><description>https://arxiv.org/abs/2410.14132&lt;br /&gt;ViConsFormer is a novel transformer-based method for Vietnamese Text-based Visual Question Answering (VQA) that effectively utilizes the meaning extracted from scene texts in images to improve answer accuracy, achieving state-of-the-art results on two large-scale datasets.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Coherence-Driven Multimodal Safety Dialogue with Active Learning for Embodied Agents</title><link>https://arxiv.org/abs/2410.14141</link><description>https://arxiv.org/abs/2410.14141&lt;br /&gt;M-CoDAL is a multimodal dialogue system for embodied agents that enhances safety communication in critical situations by interpreting visual cues and leveraging discourse coherence relations, evaluated through a user study with safety scenarios.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in Vision-Language Alignment</title><link>https://arxiv.org/abs/2410.14148</link><description>https://arxiv.org/abs/2410.14148&lt;br /&gt;This paper introduces FiSAO, a self-alignment method that uses a model's own visual encoder as a fine-grained verifier to enhance alignment between vision and language in Vision-Language Large Models (VLLMs), addressing misalignment issues without requiring additional data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Utilizing Large Language Models for Event Deconstruction to Enhance Multimodal Aspect-Based Sentiment Analysis</title><link>https://arxiv.org/abs/2410.14150</link><description>https://arxiv.org/abs/2410.14150&lt;br /&gt;This paper presents a novel framework, MABSA-RL, that utilizes Large Language Models (LLMs) for event decomposition to improve Multimodal Aspect-Based Sentiment Analysis (MABSA) by simplifying the complexity of analysis through reinforcement learning optimization.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation</title><link>https://arxiv.org/abs/2410.14251</link><description>https://arxiv.org/abs/2410.14251&lt;br /&gt;The paper presents MATRIX, a multi-agent simulation framework that generates diverse text-based scenarios for post-training data synthesis, enabling LLMs to better follow human instructions, and demonstrates its effectiveness through superior performance on various benchmarks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Good Parenting is all you need -- Multi-agentic LLM Hallucination Mitigation</title><link>https://arxiv.org/abs/2410.14262</link><description>https://arxiv.org/abs/2410.14262&lt;br /&gt;This study demonstrates that multi-agent setups using advanced Large Language Models (LLMs) can effectively detect and correct hallucinations in AI-generated content, achieving high accuracy in identifying inaccuracies and revising outputs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fine-Tuning Pre-trained Language Models for Robust Causal Representation Learning</title><link>https://arxiv.org/abs/2410.14375</link><description>https://arxiv.org/abs/2410.14375&lt;br /&gt;The research investigates how fine-tuning pre-trained language models can enhance their generalizability in single-domain scenarios by utilizing causal mechanisms to mitigate the effect of spurious features, demonstrating superior performance in both synthetic and real-world settings.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts</title><link>https://arxiv.org/abs/2410.14574</link><description>https://arxiv.org/abs/2410.14574&lt;br /&gt;MomentumSMoE introduces a new framework for Sparse Mixture of Experts by integrating momentum to enhance stability and robustness during training, demonstrating improved performance across various practical tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Optimizing Attention with Mirror Descent: Generalized Max-Margin Token Selection</title><link>https://arxiv.org/abs/2410.14581</link><description>https://arxiv.org/abs/2410.14581&lt;br /&gt;This paper explores the optimization dynamics and convergence properties of mirror descent algorithms for softmax attention mechanisms, demonstrating their effectiveness in token selection and generalization in classification tasks compared to traditional gradient descent methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Do LLMs estimate uncertainty well in instruction-following?</title><link>https://arxiv.org/abs/2410.14582</link><description>https://arxiv.org/abs/2410.14582&lt;br /&gt;This paper systematically evaluates the ability of large language models (LLMs) to estimate uncertainty while following instructions and identifies challenges in existing benchmarks, aiming to improve the reliability of LLMs in high-stakes applications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CELI: Controller-Embedded Language Model Interactions</title><link>https://arxiv.org/abs/2410.14627</link><description>https://arxiv.org/abs/2410.14627&lt;br /&gt;CELI introduces a framework that embeds control logic within language model prompts to enhance complex task execution and dynamic adaptation, leading to significant performance improvements in code generation and content creation tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples</title><link>https://arxiv.org/abs/2410.14669</link><description>https://arxiv.org/abs/2410.14669&lt;br /&gt;NaturalBench is a new benchmark for evaluating vision-language models (VLMs) using 10,000 human-verified visual-question-answering samples that highlight the models' struggles with natural images and complex reasoning, exposing significant biases and performance gaps compared to human understanding.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Improving Word Translation via Two-Stage Contrastive Learning</title><link>https://arxiv.org/abs/2203.08307</link><description>https://arxiv.org/abs/2203.08307&lt;br /&gt;This paper introduces a two-stage contrastive learning framework for improving bilingual lexicon induction (BLI), enhancing word translation by refining cross-lingual linear maps and fine-tuning mBERT to achieve substantial performance gains across multiple language pairs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Improving Bilingual Lexicon Induction with Cross-Encoder Reranking</title><link>https://arxiv.org/abs/2210.16953</link><description>https://arxiv.org/abs/2210.16953&lt;br /&gt;The paper presents BLICEr, a novel semi-supervised post-hoc reranking method that enhances bilingual lexicon induction by combining cross-lingual word embeddings with semantic similarity scores from a fine-tuned multilingual pre-trained language model.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition</title><link>https://arxiv.org/abs/2302.08102</link><description>https://arxiv.org/abs/2302.08102&lt;br /&gt;The paper presents a method for improving speaker-adaptive Visual Speech Recognition (VSR) by using prompt tuning of Deep Neural Networks (DNNs), allowing the model to better adapt to unseen speakers with minimal adaptation data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>I run as fast as a rabbit, can you? A Multilingual Simile Dialogue Dataset</title><link>https://arxiv.org/abs/2306.05672</link><description>https://arxiv.org/abs/2306.05672&lt;br /&gt;The paper introduces the Multilingual Simile Dialogue (MSD) dataset, the largest manually annotated simile data that facilitates the study of complex simile phenomena in dialogues, featuring tasks for simile recognition, interpretation, generation, and dialogue generation using English and Chinese data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models</title><link>https://arxiv.org/abs/2306.15087</link><description>https://arxiv.org/abs/2306.15087&lt;br /&gt;WinoQueer is a benchmark created to assess and quantify the anti-LGBTQ+ bias present in large language models (LLMs), utilizing community input to generate the benchmark and demonstrating that bias can be mitigated by fine-tuning with data produced by community members.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Entity Matching using Large Language Models</title><link>https://arxiv.org/abs/2310.11244</link><description>https://arxiv.org/abs/2310.11244&lt;br /&gt;This paper explores the use of generative large language models (LLMs) for entity matching, demonstrating their reduced dependency on task-specific training data and increased robustness compared to traditional pre-trained language models (PLMs).</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>"We Demand Justice!": Towards Social Context Grounding of Political Texts</title><link>https://arxiv.org/abs/2311.09106</link><description>https://arxiv.org/abs/2311.09106&lt;br /&gt;This paper explores the social context necessary for understanding ambiguous political discourse on social media, proposing datasets to benchmark large pre-trained models and structured models in their capacity for contextual and pragmatic language understanding.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models</title><link>https://arxiv.org/abs/2402.13606</link><description>https://arxiv.org/abs/2402.13606&lt;br /&gt;This paper presents a comprehensive study of multilingual confidence estimation in Large Language Models (LLMs), highlighting the performance disparities across languages and introducing a native-tone prompting strategy to enhance reliability and accuracy on language-specific tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Framing in the Presence of Supporting Data: A Case Study in U.S. Economic News</title><link>https://arxiv.org/abs/2402.14224</link><description>https://arxiv.org/abs/2402.14224&lt;br /&gt;The paper presents a computational framework for analyzing editorial choices in U.S. economic news by framing prediction with objective measures derived from economic indicators, allowing for evaluation of how publications select and frame economic information from 2015 to 2023.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis</title><link>https://arxiv.org/abs/2403.01976</link><description>https://arxiv.org/abs/2403.01976&lt;br /&gt;SciAssess is a benchmarking framework that evaluates the proficiency of Large Language Models (LLMs) in analyzing scientific literature across various domains, focusing on their Memorization, Comprehension, and Analysis &amp; Reasoning capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MaiBaam Annotation Guidelines</title><link>https://arxiv.org/abs/2403.05902</link><description>https://arxiv.org/abs/2403.05902&lt;br /&gt;The MaiBaam Annotation Guidelines document outlines the processes and principles for annotating the Bavarian corpus with part-of-speech tags and syntactic dependencies, contributing to the Universal Dependencies project.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>One size doesn't fit all: Predicting the Number of Examples for In-Context Learning</title><link>https://arxiv.org/abs/2403.06402</link><description>https://arxiv.org/abs/2403.06402&lt;br /&gt;The study introduces a dynamic approach to In-Context Learning (ICL) by predicting the optimal number of examples to use for each data instance in few-shot inference with Large Language Models (LLMs), leading to improved performance compared to standard ICL methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Efficiently Quantifying and Mitigating Ripple Effects in Model Editing</title><link>https://arxiv.org/abs/2403.07825</link><description>https://arxiv.org/abs/2403.07825&lt;br /&gt;This paper presents Graphical Impact Evaluation (GIE) and Selective Impact Revision (SIR) as methodologies to quantify and mitigate the ripple effects in model editing for Large Language Models, which can adversely affect model performance and editing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Train &amp; Constrain: Phonologically Informed Tongue-Twister Generation from Topics and Paraphrases</title><link>https://arxiv.org/abs/2403.13901</link><description>https://arxiv.org/abs/2403.13901&lt;br /&gt;The paper introduces TwisterLister, a pipeline for generating English tongue twisters using phonologically informed methods, which utilizes a phonologically constrained vocabulary and large language models to create the largest annotated dataset of tongue twisters while maintaining semantic consistency and grammatical correctness.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Multi-Conditional Ranking with Large Language Models</title><link>https://arxiv.org/abs/2404.00211</link><description>https://arxiv.org/abs/2404.00211&lt;br /&gt;This paper introduces MCRank, a benchmark for evaluating large language models (LLMs) in the task of multi-conditional ranking, and presents a decomposed reasoning method (EXSIR) that significantly improves LLM performance on complex ranking tasks involving diverse conditions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural Knowledge</title><link>https://arxiv.org/abs/2404.06833</link><description>https://arxiv.org/abs/2404.06833&lt;br /&gt;This research investigates the cultural biases present in Large Language Models (LLMs) concerning food-related knowledge, introducing the FmLAMA dataset to analyze LLM performance in both monolingual and multilingual settings, highlighting the influence of cultural context on LLMs' ability to access and accurately represent food-related cultural facts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>What's under the hood: Investigating Automatic Metrics on Meeting Summarization</title><link>https://arxiv.org/abs/2404.11124</link><description>https://arxiv.org/abs/2404.11124&lt;br /&gt;This paper investigates the effectiveness of automatic metrics for evaluating meeting summarization, identifying their shortcomings in capturing meeting-specific errors and correlating these metrics with human evaluations across a detailed error taxonomy, revealing that existing metrics often mask important summarization errors.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding</title><link>https://arxiv.org/abs/2404.16710</link><description>https://arxiv.org/abs/2404.16710&lt;br /&gt;LayerSkip is an end-to-end solution designed to accelerate inference in large language models (LLMs) by employing layer dropout during training and a self-speculative decoding approach that allows for early exit inference, resulting in significant speedups without additional model complexity.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Everything is Editable: Extend Knowledge Editing to Unstructured Data in Large Language Models</title><link>https://arxiv.org/abs/2405.15349</link><description>https://arxiv.org/abs/2405.15349&lt;br /&gt;The paper proposes UnKE, a novel method for editing unstructured knowledge in large language models by introducing non-local block key-value storage and cause-driven optimization to improve representation and context preservation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>PertEval: Unveiling Real Knowledge Capacity of LLMs with Knowledge-Invariant Perturbations</title><link>https://arxiv.org/abs/2405.19740</link><description>https://arxiv.org/abs/2405.19740&lt;br /&gt;PertEval is a toolkit designed to assess the knowledge capacity of large language models (LLMs) through knowledge-invariant perturbations, revealing significant overestimations in LLM performance on traditional benchmarks and providing insights for advancing their knowledge mastery.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Fundamental Trade-off in Aligned Language Models and its Relation to Sampling Adaptors</title><link>https://arxiv.org/abs/2406.10203</link><description>https://arxiv.org/abs/2406.10203&lt;br /&gt;This paper explores the trade-off between quality and probability in aligned language models, particularly focusing on how sampling adaptors can influence the balance between average reward and log-likelihood when samples are drawn from a model aligned to human preferences through reinforcement learning.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Error Span Annotation: A Balanced Approach for Human Evaluation of Machine Translation</title><link>https://arxiv.org/abs/2406.11580</link><description>https://arxiv.org/abs/2406.11580&lt;br /&gt;Error Span Annotation (ESA) is a new human evaluation protocol for machine translation that balances the efficiency of Direct Assessment with the detailed error classification of Multidimensional Quality Metrics, offering quicker and more cost-effective evaluations without needing expert involvement.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLM Critics Help Catch Bugs in Mathematics: Towards a Better Mathematical Verifier with Natural Language Feedback</title><link>https://arxiv.org/abs/2406.14024</link><description>https://arxiv.org/abs/2406.14024&lt;br /&gt;The paper presents Math-Minos, a natural language feedback-enhanced mathematical verifier that improves assessment accuracy of solutions by using step-wise natural language feedback instead of binary classification labels.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MACAROON: Training Vision-Language Models To Be Your Engaged Partners</title><link>https://arxiv.org/abs/2406.14137</link><description>https://arxiv.org/abs/2406.14137&lt;br /&gt;MACAROON introduces a framework that enhances the proactive engagement capabilities of large vision-language models (LVLMs) by enabling them to autonomously generate contrastive response pairs to improve their interaction with ambiguous or personalizable questions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Evaluating Contextualized Representations of (Spanish) Ambiguous Words: A New Lexical Resource and Empirical Analysis</title><link>https://arxiv.org/abs/2406.14678</link><description>https://arxiv.org/abs/2406.14678&lt;br /&gt;This paper evaluates how different BERT-based language models represent ambiguous Spanish nouns in context, providing a novel dataset for understanding their capacity to reflect human semantic judgments, and analyzing the influence of model architecture and size on performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>"Vorbe\c{s}ti Rom\^ane\c{s}te?" A Recipe to Train Powerful Romanian LLMs with English Instructions</title><link>https://arxiv.org/abs/2406.18266</link><description>https://arxiv.org/abs/2406.18266&lt;br /&gt;This paper presents the development and training of Romanian Large Language Models (RoLLMs) using a large collection of translated texts and benchmarks to achieve high performance and state-of-the-art results, aimed at improving LLM capabilities for Romanian and supporting research on low-resourced languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models</title><link>https://arxiv.org/abs/2407.02067</link><description>https://arxiv.org/abs/2407.02067&lt;br /&gt;The paper explores cultural understanding in Large Multimodal Models (LMMs) through a study involving a dataset of images and cultural artifact extraction, revealing disparities in cultural understanding and emphasizing the importance of culture-aware systems.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>P3: A Policy-Driven, Pace-Adaptive, and Diversity-Promoted Framework for data pruning in LLM Training</title><link>https://arxiv.org/abs/2408.05541</link><description>https://arxiv.org/abs/2408.05541&lt;br /&gt;P3 is an adaptive framework for fine-tuning Large Language Models (LLMs) that optimizes data pruning through policy-driven difficulty measurement, pace-adaptive selection, and diversity promotion, enhancing model performance on reasoning tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding</title><link>https://arxiv.org/abs/2409.03258</link><description>https://arxiv.org/abs/2409.03258&lt;br /&gt;GraphInsight is a framework designed to enhance Large Language Models' comprehension of graph structures by addressing positional biases in memory performance and leveraging an external knowledge base for improved understanding and multi-step reasoning in graph tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models</title><link>https://arxiv.org/abs/2409.14917</link><description>https://arxiv.org/abs/2409.14917&lt;br /&gt;The study investigates the ability of Vision Language Models (VLMs) and Large Language Models (LLMs) to understand sound symbolism through experiments that explore the connection between sounds and concepts by using visual and textual information.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>English offensive text detection using CNN based Bi-GRU model</title><link>https://arxiv.org/abs/2409.15652</link><description>https://arxiv.org/abs/2409.15652&lt;br /&gt;This paper presents a novel Bi-GRU-CNN model for automating the detection of offensive text on social media platforms, improving the classification of inappropriate content compared to existing models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Modular-based Strategy for Mitigating Gradient Conflicts in Simultaneous Speech Translation</title><link>https://arxiv.org/abs/2409.15911</link><description>https://arxiv.org/abs/2409.15911&lt;br /&gt;The study introduces a Modular Gradient Conflict Mitigation (MGCM) strategy that detects and resolves optimization conflicts in Simultaneous Speech Translation (SimulST), leading to improved performance and significantly reduced GPU memory consumption.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding for Large Language Models</title><link>https://arxiv.org/abs/2409.19700</link><description>https://arxiv.org/abs/2409.19700&lt;br /&gt;The paper introduces 2D-TPE, a Two-Dimensional Positional Encoding method designed to enhance the ability of large language models (LLMs) in understanding table structures by preserving spatial relationships and improving performance on tabular data tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning</title><link>https://arxiv.org/abs/2410.02052</link><description>https://arxiv.org/abs/2410.02052&lt;br /&gt;ExACT presents a novel approach that combines Reflective Monte Carlo Tree Search and Exploratory Learning to enhance the decision-making capabilities of autonomous agents, particularly in complex multistep tasks, achieving significant performance improvements in various applications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Contextual Document Embeddings</title><link>https://arxiv.org/abs/2410.02525</link><description>https://arxiv.org/abs/2410.02525&lt;br /&gt;This paper introduces two methods for creating contextualized document embeddings that enhance neural retrieval by considering both the target document and its neighboring documents, leading to improved performance over traditional biencoders.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Hyper-multi-step: The Truth Behind Difficult Long-context Tasks</title><link>https://arxiv.org/abs/2410.04422</link><description>https://arxiv.org/abs/2410.04422&lt;br /&gt;The paper investigates the challenges faced by Long-context Language Models (LCLMs) in completing difficult long-context tasks, identifying that the challenges primarily arise from 'multi-matching retrieval' and 'logic-based retrieval' requirements that exceed LCLMs' capabilities due to their hyper-multi-step nature.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization</title><link>https://arxiv.org/abs/2410.04717</link><description>https://arxiv.org/abs/2410.04717&lt;br /&gt;The paper investigates how the diversity of training instructions across various semantic domains affects the generalization abilities of large language models (LLMs) and provides guidelines for effective dataset collection for instruction-tuning.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing</title><link>https://arxiv.org/abs/2410.06331</link><description>https://arxiv.org/abs/2410.06331&lt;br /&gt;The paper presents IFMET, a novel locate-then-edit approach for knowledge editing in Large Language Models (LLMs), which enhances multi-hop factual recall by modifying both shallow and deep MLP layers to overcome limitations of previous methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Advocating Character Error Rate for Multilingual ASR Evaluation</title><link>https://arxiv.org/abs/2410.07400</link><description>https://arxiv.org/abs/2410.07400&lt;br /&gt;The paper advocates for the use of character error rate (CER) as the primary evaluation metric for multilingual automatic speech recognition (ASR) systems, highlighting its advantages over the traditional word error rate (WER) in accounting for the complexities of different languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>GUS-Net: Social Bias Classification in Text with Generalizations, Unfairness, and Stereotypes</title><link>https://arxiv.org/abs/2410.08388</link><description>https://arxiv.org/abs/2410.08388&lt;br /&gt;GUS-Net is a novel approach for detecting social biases in text, focusing on generalizations, unfairness, and stereotypes, utilizing generative AI and automated agents to create a synthetic dataset for improved multi-label token classification.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective</title><link>https://arxiv.org/abs/2410.10291</link><description>https://arxiv.org/abs/2410.10291&lt;br /&gt;The paper introduces a novel metric and benchmark for evaluating the causal relationship between semantic variations in linguistic inputs and outputs in text-to-image synthesis, highlighting the limitations of existing evaluation methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>FAME: Towards Factual Multi-Task Model Editing</title><link>https://arxiv.org/abs/2410.10859</link><description>https://arxiv.org/abs/2410.10859&lt;br /&gt;FAME introduces a factual, comprehensive, and multi-task dataset for model editing in large language models, along with SKEME, a novel editing method that employs a caching mechanism to improve synchronization with real-world information and enhance LLM capabilities in practical applications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models</title><link>https://arxiv.org/abs/2410.12478</link><description>https://arxiv.org/abs/2410.12478&lt;br /&gt;MlingConf presents a comprehensive study of Multilingual Confidence Estimation on Large Language Models, revealing insights on language dominance and proposing a native-tone prompting strategy to enhance the reliability and accuracy of LLMs in different languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Comparative Analysis of Extrinsic Factors for NER in French</title><link>https://arxiv.org/abs/2410.12750</link><description>https://arxiv.org/abs/2410.12750&lt;br /&gt;This paper explores various extrinsic factors including model structure, corpus annotation schemes, and data augmentation techniques to enhance the performance of Named Entity Recognition (NER) models for the French language, demonstrating significant improvements in F1 scores with limited data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>UniAutoML: A Human-Centered Framework for Unified Discriminative and Generative AutoML with Large Language Models</title><link>https://arxiv.org/abs/2410.12841</link><description>https://arxiv.org/abs/2410.12841&lt;br /&gt;UniAutoML is a human-centered AutoML framework that integrates Large Language Models to unify discriminative and generative tasks with a conversational user interface, enhancing user engagement, transparency, and control in the AutoML process.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework</title><link>https://arxiv.org/abs/2410.12855</link><description>https://arxiv.org/abs/2410.12855&lt;br /&gt;JAILJUDGE introduces a comprehensive benchmark for evaluating Large Language Model defenses against jailbreak attacks by providing a diverse set of risk scenarios and utilizing a Multi-Agent framework for explainable, fine-grained scoring.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>On Debiasing Text Embeddings Through Context Injection</title><link>https://arxiv.org/abs/2410.12874</link><description>https://arxiv.org/abs/2410.12874&lt;br /&gt;This paper reviews 19 embedding models to analyze their biases and the effectiveness of context injection for debiasing, revealing that higher-performing models are more prone to biases but also better at incorporating context, and it proposes a new algorithm for improved retrieval that addresses bias issues.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs</title><link>https://arxiv.org/abs/2410.13276</link><description>https://arxiv.org/abs/2410.13276&lt;br /&gt;SeerAttention introduces a novel adaptive attention mechanism for Large Language Models (LLMs) that learns attention sparsity dynamically, significantly improving efficiency and scalability for long-context language tasks while balancing accuracy and speedup.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BANTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla</title><link>https://arxiv.org/abs/2410.13281</link><description>https://arxiv.org/abs/2410.13281&lt;br /&gt;BANTH introduces the first multi-label hate speech detection dataset for transliterated Bangla, consisting of 37.3k samples sourced from YouTube comments, and establishes novel transformer encoder-based baselines that achieve state-of-the-art performance while addressing classification challenges in low-resource languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BenTo: Benchmark Task Reduction with In-Context Transferability</title><link>https://arxiv.org/abs/2410.13804</link><description>https://arxiv.org/abs/2410.13804&lt;br /&gt;BenTo introduces a method for efficiently reducing the number of tasks used to benchmark large language models (LLMs) by utilizing task transferability and relevance to identify a representative subset, achieving significant task reduction while maintaining evaluation quality.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off</title><link>https://arxiv.org/abs/2403.04808</link><description>https://arxiv.org/abs/2403.04808&lt;br /&gt;WaterMax introduces a novel watermarking scheme for Large Language Models that achieves high watermark detectability while maintaining the quality of the generated text, overcoming the traditional quality-robustness trade-off in watermarking techniques.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Movie101v2: Improved Movie Narration Benchmark</title><link>https://arxiv.org/abs/2404.13370</link><description>https://arxiv.org/abs/2404.13370&lt;br /&gt;Movie101v2 introduces a large-scale, bilingual dataset and establishes a benchmark for automatic movie narration to support visually impaired audiences, focusing on generating video-aligned plot descriptions across multiple shots.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>On the Use of Large Language Models to Generate Capability Ontologies</title><link>https://arxiv.org/abs/2404.17524</link><description>https://arxiv.org/abs/2404.17524&lt;br /&gt;This paper investigates how Large Language Models (LLMs) can assist in the generation of capability ontologies by creating machine-interpretable models from natural language and evaluating the quality of generated ontologies through various experiments and checks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs</title><link>https://arxiv.org/abs/2406.02958</link><description>https://arxiv.org/abs/2406.02958&lt;br /&gt;PrE-Text is a method for generating differentially private synthetic textual data that allows small models to outperform traditional on-device training while requiring significantly less communication and computation, and also enhances the performance of large language models on private data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Toward a Method to Generate Capability Ontologies from Natural Language Descriptions</title><link>https://arxiv.org/abs/2406.07962</link><description>https://arxiv.org/abs/2406.07962&lt;br /&gt;This paper presents an automated method for generating capability ontologies from natural language descriptions using Large Language Models (LLMs), which includes a looped verification process to ensure correctness and reduce manual effort.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction</title><link>https://arxiv.org/abs/2406.12950</link><description>https://arxiv.org/abs/2406.12950&lt;br /&gt;MolecularGPT introduces a fine-tuned large language model (LLM) for few-shot molecular property prediction, showcasing its ability to adapt to new tasks with minimal examples and outperforming traditional methods and standard LLMs in various evaluation metrics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Amphista: Bi-directional Multi-head Decoding for Accelerating LLM Inference</title><link>https://arxiv.org/abs/2406.13170</link><description>https://arxiv.org/abs/2406.13170&lt;br /&gt;Amphista is a speculative decoding framework for Large Language Models (LLMs) that enhances inference speed through bi-directional multi-head decoding, achieving significant speedup while maintaining the quality of generated content.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multi-modal Foundation Models</title><link>https://arxiv.org/abs/2406.14862</link><description>https://arxiv.org/abs/2406.14862&lt;br /&gt;LatentExplainer is a framework that generates semantically meaningful explanations of latent variables in deep generative models by perturbing these variables and utilizing multi-modal large language models to produce human-understandable interpretations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>From Introspection to Best Practices: Principled Analysis of Demonstrations in Multimodal In-Context Learning</title><link>https://arxiv.org/abs/2407.00902</link><description>https://arxiv.org/abs/2407.00902&lt;br /&gt;The paper presents a principled analysis of multimodal in-context learning (ICL) in Large Language Models (LLMs), exploring how different modalities affect task performance and recommending strategies for effective demonstrations to enhance ICL across various tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Dating ancient manuscripts using radiocarbon and AI-based writing style analysis</title><link>https://arxiv.org/abs/2407.12013</link><description>https://arxiv.org/abs/2407.12013&lt;br /&gt;The study presents Enoch, an AI-based model leveraging Bayesian ridge regression and handwriting style analysis to predict the dates of ancient manuscripts, particularly the Dead Sea Scrolls, achieving improved granularity and contributing to the chronology of historical texts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Improving Retrieval in Sponsored Search by Leveraging Query Context Signals</title><link>https://arxiv.org/abs/2407.14346</link><description>https://arxiv.org/abs/2407.14346&lt;br /&gt;This paper presents an approach to enhance retrieval in Sponsored Search by utilizing query context signals from web search results and large language models to improve understanding of user intent, leading to better performance in retrieving relevant keywords for short, ambiguous queries.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Tighter Complexity Analysis of SparseGPT</title><link>https://arxiv.org/abs/2408.12151</link><description>https://arxiv.org/abs/2408.12151&lt;br /&gt;This paper presents an improved analysis of SparseGPT's running time, reducing it from $O(d^{3})$ to $O(d^{2.53})$ by examining the lazy update behavior in iterative maintenance problems.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding</title><link>https://arxiv.org/abs/2408.15545</link><description>https://arxiv.org/abs/2408.15545&lt;br /&gt;SciLitLLM is a framework that enhances Large Language Models (LLMs) for scientific literature understanding through continual pre-training and supervised fine-tuning, addressing challenges in knowledge infusion and instructional generation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Supervised Fine-Tuning Achieve Rapid Task Adaption Via Alternating Attention Head Activation Patterns</title><link>https://arxiv.org/abs/2409.15820</link><description>https://arxiv.org/abs/2409.15820&lt;br /&gt;The paper explores how supervised fine-tuning (SFT) can enhance the rapid adaptation of Large Language Models (LLMs) to complex tasks by analyzing attention head activation patterns, revealing that selective activation of task-specific heads and parameter changes can improve task performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models</title><link>https://arxiv.org/abs/2410.00131</link><description>https://arxiv.org/abs/2410.00131&lt;br /&gt;FibecFed is a Fisher Information-based framework that enhances the efficiency of Federated Learning for fine-tuning Large Language Models by implementing adaptive sampling and sparse parameter updates to reduce communication costs and improve training speed.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>System 2 thinking in OpenAI's o1-preview model: Near-perfect performance on a mathematics exam</title><link>https://arxiv.org/abs/2410.07114</link><description>https://arxiv.org/abs/2410.07114&lt;br /&gt;The study evaluates OpenAI's o1-preview model, which demonstrates near-perfect performance on a mathematics exam, indicating its capability for System 2-like reasoning, while also identifying variability in outputs and the importance of a self-consistency approach for improving accuracy.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment</title><link>https://arxiv.org/abs/2410.09421</link><description>https://arxiv.org/abs/2410.09421&lt;br /&gt;VLFeedback introduces a large-scale dataset for AI feedback aimed at aligning large vision-language models (LVLMs), demonstrating improved performance in helpfulness, visual faithfulness, and safety, while addressing challenges such as hallucinations and vulnerability to adversarial attacks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models</title><link>https://arxiv.org/abs/2410.09804</link><description>https://arxiv.org/abs/2410.09804&lt;br /&gt;BlackDAN is a multi-objective optimization framework designed to enhance the effectiveness and contextual relevance of jailbreak attacks on large language models (LLMs) while minimizing their detectability, utilizing Multiobjective Evolutionary Algorithms for prompt generation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Learning Linear Attention in Polynomial Time</title><link>https://arxiv.org/abs/2410.10101</link><description>https://arxiv.org/abs/2410.10101&lt;br /&gt;This study demonstrates that single-layer Transformers with linear attention can be learned in polynomial time and provides insights into their theoretical expressivity and practical applications, including associative memories and finite automata.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis</title><link>https://arxiv.org/abs/2410.10270</link><description>https://arxiv.org/abs/2410.10270&lt;br /&gt;QUIS is a fully automated exploratory data analysis system that generates and refines questions to drive insight generation from large datasets, eliminating the need for human intervention and allowing for adaptability to new data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Liger Kernel: Efficient Triton Kernels for LLM Training</title><link>https://arxiv.org/abs/2410.10989</link><description>https://arxiv.org/abs/2410.10989&lt;br /&gt;Liger Kernel introduces a set of optimized Triton kernels for efficient training of Large Language Models (LLMs), achieving significant improvements in training throughput and GPU memory usage.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Scaling laws for post-training quantized large language models</title><link>https://arxiv.org/abs/2410.12119</link><description>https://arxiv.org/abs/2410.12119&lt;br /&gt;This research paper investigates the predictability of post-training performance in quantized large language models (LLMs) by identifying scaling factors related to the local loss landscape, providing a statistical model for estimating their performance after compression.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>An Evolved Universal Transformer Memory</title><link>https://arxiv.org/abs/2410.13166</link><description>https://arxiv.org/abs/2410.13166&lt;br /&gt;The paper introduces Neural Attention Memory Models (NAMMs), which enhance the performance and efficiency of transformers by evolving memory management to focus on the most relevant information for attention layers, achieving significant improvements in long-context tasks and demonstrating general applicability across various transformer architectures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MoR: Mixture of Ranks for Low-Rank Adaptation Tuning</title><link>https://arxiv.org/abs/2410.13408</link><description>https://arxiv.org/abs/2410.13408&lt;br /&gt;MoR introduces a new framework for Low-Rank Adaptation that efficiently captures task-specific information and integrates multi-rank data to improve performance while reducing parameter usage in comparison to traditional methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Harnessing Webpage UIs for Text-Rich Visual Understanding</title><link>https://arxiv.org/abs/2410.13824</link><description>https://arxiv.org/abs/2410.13824&lt;br /&gt;The paper presents MultiUI, a dataset comprising 7.3 million samples from 1 million websites, which synthesizes multimodal instructions from webpage UIs to train models for improved text-rich visual understanding across various tasks, demonstrating significant performance enhancements in web UI and non-UI applications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles</title><link>https://arxiv.org/abs/2410.14042</link><description>https://arxiv.org/abs/2410.14042&lt;br /&gt;Style-Compress is a framework that enables a smaller language model to effectively compress prompts for larger models by utilizing task-specific styles, improving efficiency and performance across multiple tasks while significantly reducing computational costs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion</title><link>https://arxiv.org/abs/2410.14405</link><description>https://arxiv.org/abs/2410.14405&lt;br /&gt;The paper investigates the distinct behaviors of language models (LMs) in processing factual information through a model-specific framework called PrISM, revealing variations in model reliability across different prediction scenarios for fact completion.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas</title><link>https://arxiv.org/abs/2410.14255</link><description>https://arxiv.org/abs/2410.14255&lt;br /&gt;Nova presents an iterative planning and search methodology that enhances the novelty and diversity of ideas generated by large language models (LLMs) by effectively retrieving and integrating external knowledge, resulting in a significant increase in the generation of unique and high-quality research ideas.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data</title><link>https://arxiv.org/abs/2406.15053</link><description>https://arxiv.org/abs/2406.15053&lt;br /&gt;The paper investigates the agreement between human evaluators and Large Language Models (LLMs) on the assessment of multilingual models across various Indic languages, revealing differences in evaluation performance and biases.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs</title><link>https://arxiv.org/abs/2410.13987</link><description>https://arxiv.org/abs/2410.13987&lt;br /&gt;The paper presents a two-stage contrastive learning framework for improving bilingual lexicon induction (BLI), successfully refining cross-lingual mappings and enhancing word translation capabilities of mBERT through fine-tuning.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Generating Signed Language Instructions in Large-Scale Dialogue Systems</title><link>https://arxiv.org/abs/2410.14026</link><description>https://arxiv.org/abs/2410.14026&lt;br /&gt;This paper introduces the concept of entity-level unlearning for large language models, highlighting the limitations of current instance-level unlearning methods and presenting a comprehensive evaluation of unlearning algorithms in the context of removing entity-related knowledge.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A two-stage transliteration approach to improve performance of a multilingual ASR</title><link>https://arxiv.org/abs/2410.14709</link><description>https://arxiv.org/abs/2410.14709&lt;br /&gt;CAP introduces a novel framework for detecting data contamination in large language models (LLMs) through performance consistency measurement, offering a practical solution applicable across various benchmarks and model types.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Eliciting Uncertainty in Chain-of-Thought to Mitigate Bias against Forecasting Harmful User Behaviors</title><link>https://arxiv.org/abs/2410.14744</link><description>https://arxiv.org/abs/2410.14744&lt;br /&gt;This paper investigates the effects of scaling inference compute by analyzing the coverage improvements through repeated sampling in large language models (LLMs) across two domains, proposing an enumeration baseline for more accurate performance measurement.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Controllable Discovery of Intents: Incremental Deep Clustering Using Semi-Supervised Contrastive Learning</title><link>https://arxiv.org/abs/2410.14755</link><description>https://arxiv.org/abs/2410.14755&lt;br /&gt;This study assesses the rhetorical styles of various large language models (LLMs) by comparing their outputs to human-written texts, revealing systematic differences in grammatical and rhetorical features that persist across different model sizes and tuning strategies.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Enabling Scalable Evaluation of Bias Patterns in Medical LLMs</title><link>https://arxiv.org/abs/2410.14763</link><description>https://arxiv.org/abs/2410.14763&lt;br /&gt;RepoGraph is a plugin module designed to enhance large language models' performance in AI software engineering by providing a repository-level code structure, enabling better context understanding and interaction with code repositories.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Cross-Document Event-Keyed Summarization</title><link>https://arxiv.org/abs/2410.14795</link><description>https://arxiv.org/abs/2410.14795&lt;br /&gt;ChitroJera introduces a large-scale visual question answering dataset specifically tailored for the Bangla language, addressing the lack of culturally relevant resources and demonstrating improved performance with novel dual-encoder models and large language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Isolated Causal Effects of Natural Language</title><link>https://arxiv.org/abs/2410.14812</link><description>https://arxiv.org/abs/2410.14812&lt;br /&gt;The proposed Generalized Probabilistic Attention Mechanism (GPAM) enhances the Transformer architecture by addressing rank-collapse and gradient vanishing issues while allowing for negative attention scores, thereby improving performance across various natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Adapting Multilingual LLMs to Low-Resource Languages using Continued Pre-training and Synthetic Corpus</title><link>https://arxiv.org/abs/2410.14815</link><description>https://arxiv.org/abs/2410.14815&lt;br /&gt;This paper introduces the Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in Large Language Models (LLMs) during stance detection tasks, demonstrating its effectiveness through experimental results that show an enhancement in calibration and generalizability.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Complexity-Based Theory of Compositionality</title><link>https://arxiv.org/abs/2410.14817</link><description>https://arxiv.org/abs/2410.14817&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) architecture in large language models, highlighting features such as the behavior of neurons as experts, router selection of experts, and the increasing diversity of experts across layers, aiming to provide insights for future improvements in MoE designs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SPRIG: Improving Large Language Model Performance by System Prompt Optimization</title><link>https://arxiv.org/abs/2410.14826</link><description>https://arxiv.org/abs/2410.14826&lt;br /&gt;The CLC-UKET dataset is developed to benchmark case outcome prediction in the UK Employment Tribunal by utilizing a large language model for automatic annotation of approximately 19,000 cases and their legal metadata, aiming to improve access to justice through empirical comparison of model performance in predicting case outcomes.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DFlow: Diverse Dialogue Flow Simulation with Large Language Models</title><link>https://arxiv.org/abs/2410.14853</link><description>https://arxiv.org/abs/2410.14853&lt;br /&gt;This paper investigates how well contextualized representations in neural autoregressive language models encode long-range context, finding that different architectures and training configurations significantly impact their ability to capture complex sequences.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Which LLMs are Difficult to Detect? A Detailed Analysis of Potential Factors Contributing to Difficulties in LLM Text Detection</title><link>https://arxiv.org/abs/2410.14875</link><description>https://arxiv.org/abs/2410.14875&lt;br /&gt;RACCooN is a versatile video editing framework that employs a two-stage process to transform videos into structured natural language descriptions and back to modified videos, allowing for flexible adaptations without complex human annotations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>From Test-Taking to Test-Making: Examining LLM Authoring of Commonsense Assessment Items</title><link>https://arxiv.org/abs/2410.14897</link><description>https://arxiv.org/abs/2410.14897&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to evaluate systems developed to attack voice anonymization techniques, with specific datasets and metrics for participant assessment, culminating in a presentation of results at ICASSP 2025.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SemiHVision: Enhancing Medical Multimodal Models with a Semi-Human Annotated Dataset and Fine-Tuned Instruction Generation</title><link>https://arxiv.org/abs/2410.14948</link><description>https://arxiv.org/abs/2410.14948&lt;br /&gt;MathGAP is a framework designed to evaluate Large Language Models (LLMs) on arithmetic problems with arbitrarily complex proofs, revealing significant performance drops in models as proof complexity increases, particularly in complex, nonlinear structures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Agent Skill Acquisition for Large Language Models via CycleQD</title><link>https://arxiv.org/abs/2410.14735</link><description>https://arxiv.org/abs/2410.14735&lt;br /&gt;This study investigates the impact of soft-domain transfer and named entity information on deception detection by analyzing multiple datasets and utilizing transfer learning with fine-tuned BERT models to improve classifier accuracy.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SemiEvol: Semi-supervised Fine-tuning for LLM Adaptation</title><link>https://arxiv.org/abs/2410.14745</link><description>https://arxiv.org/abs/2410.14745&lt;br /&gt;This study investigates the effects of soft-domain transfer and named entity information on deception detection, demonstrating that leveraging multiple datasets through transfer learning can significantly improve classifier accuracy in identifying deceitful online communications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Accounting for Sycophancy in Language Model Uncertainty Estimation</title><link>https://arxiv.org/abs/2410.14746</link><description>https://arxiv.org/abs/2410.14746&lt;br /&gt;This paper explores the use of transfer learning from various text-only domains and the incorporation of named entity information to enhance the performance of deception detection classifiers based on fine-tuned BERT models, resulting in significant accuracy improvements.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Effects of Soft-Domain Transfer and Named Entity Information on Deception Detection</title><link>https://arxiv.org/abs/2410.14814</link><description>https://arxiv.org/abs/2410.14814&lt;br /&gt;This paper investigates the impact of soft-domain transfer learning and the incorporation of named entity information on improving deception detection accuracy across multiple text-only domains using fine-tuned BERT models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ChronoFact: Timeline-based Temporal Fact Verification</title><link>https://arxiv.org/abs/2410.14964</link><description>https://arxiv.org/abs/2410.14964&lt;br /&gt;CAP introduces a novel framework for detecting data contamination in large language models (LLMs) through Performance Consistency Ratio (PCR), enabling differentiation between fine-tuning and contamination while being applicable across various benchmarks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Subversive Characters and Stereotyping Readers: Characterizing Queer Relationalities with Dialogue-Based Relation Extraction</title><link>https://arxiv.org/abs/2410.14978</link><description>https://arxiv.org/abs/2410.14978&lt;br /&gt;CAP introduces a novel framework for detecting data contamination in large language models via Performance Consistency Ratio, effectively distinguishing between fine-tuning and contamination across various benchmarks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CAP: Data Contamination Detection via Consistency Amplification</title><link>https://arxiv.org/abs/2410.15005</link><description>https://arxiv.org/abs/2410.15005&lt;br /&gt;The CAP framework introduces a novel method for detecting data contamination in large language models by measuring the Performance Consistency Ratio (PCR) to differentiate between fine-tuning and contamination, enhancing reliability in LLM evaluations across various benchmarks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>On the Diversity of Synthetic Data and its Impact on Training Large Language Models</title><link>https://arxiv.org/abs/2410.15226</link><description>https://arxiv.org/abs/2410.15226&lt;br /&gt;This paper proposes a baseline for evaluating the impact of repeated sampling on inference coverage in large language models (LLMs), revealing that for certain models, a prevalence-based baseline outperforms repeated sampling in tasks like mathematical reasoning and factual knowledge.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Lossless KV Cache Compression to 2%</title><link>https://arxiv.org/abs/2410.15252</link><description>https://arxiv.org/abs/2410.15252&lt;br /&gt;This paper investigates the effect of repeated sampling on inference scaling in large language models (LLMs), determining that a baseline method of answer enumeration can outperform or match the effectiveness of repeated model sampling in enhancing problem-solving coverage.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Back to School: Translation Using Grammar Books</title><link>https://arxiv.org/abs/2410.15263</link><description>https://arxiv.org/abs/2410.15263&lt;br /&gt;The paper investigates the effects of repeated sampling for inference scaling in large language models (LLMs), proposing a baseline that enumerates answers based on their prevalence in training data, which outperforms some sampling strategies in improving coverage for various tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BRIEF: Bridging Retrieval and Inference for Multi-hop Reasoning via Compression</title><link>https://arxiv.org/abs/2410.15277</link><description>https://arxiv.org/abs/2410.15277&lt;br /&gt;This paper investigates the impact of inference scaling and repeated sampling in large language models (LLMs), proposing a new baseline that outperforms traditional repeated sampling in certain contexts and highlighting the importance of answer distributions in evaluating model performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Training Language Models to Critique With Multi-agent Feedback</title><link>https://arxiv.org/abs/2410.15287</link><description>https://arxiv.org/abs/2410.15287&lt;br /&gt;The paper investigates the effects of scaling inference compute in large language models (LLMs) through repeated sampling and proposes a baseline method that accounts for answer distribution, revealing that this baseline often outperforms or matches the coverage improvement achieved by repeated model sampling in various domains.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Redefining Proactivity for Information Seeking Dialogue</title><link>https://arxiv.org/abs/2410.15297</link><description>https://arxiv.org/abs/2410.15297&lt;br /&gt;This paper investigates the effects of repeated sampling in large language models (LLMs) on inference scaling and coverage, revealing that a simple baseline approach can outperform or match the performance of repeated sampling in certain contexts, emphasizing the importance of benchmarking against prevalent answer distributions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Does ChatGPT Have a Poetic Style?</title><link>https://arxiv.org/abs/2410.15299</link><description>https://arxiv.org/abs/2410.15299&lt;br /&gt;This paper investigates the effectiveness of repeated sampling in large language models for improving inference coverage, comparing it against a baseline that enumerates common answers from the training set, revealing that the baseline can outperform or match the performance of sampling strategies in certain scenarios.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LlamaLens: Specialized Multilingual LLM for Analyzing News and Social Media Content</title><link>https://arxiv.org/abs/2410.15308</link><description>https://arxiv.org/abs/2410.15308&lt;br /&gt;This paper investigates the effectiveness of scaling inference compute in large language models (LLMs) through repeated sampling, proposing a baseline that enumerates common answers and demonstrating its potential to outperform some sampling strategies in specific domains.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>KTCR: Improving Implicit Hate Detection with Knowledge Transfer driven Concept Refinement</title><link>https://arxiv.org/abs/2410.15314</link><description>https://arxiv.org/abs/2410.15314&lt;br /&gt;This paper investigates the effects of repeated sampling in large language models (LLMs) on inference scaling and coverage, proposing a baseline approach that enumerates answers based on their prevalence in the training set, revealing that this approach can outperform or match the performance of repeated sampling strategies for certain models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Causality for Large Language Models</title><link>https://arxiv.org/abs/2410.15319</link><description>https://arxiv.org/abs/2410.15319&lt;br /&gt;This paper examines the effectiveness of baselines for increasing coverage in large language model (LLM) inference by contrasting repeated sampling with a new baseline that leverages the prevalence of answers in training datasets, revealing variable performance across different models in mathematical reasoning and factual knowledge domains.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Survey of Uncertainty Estimation in LLMs: Theory Meets Practice</title><link>https://arxiv.org/abs/2410.15326</link><description>https://arxiv.org/abs/2410.15326&lt;br /&gt;The paper investigates the effects of repeated sampling for inference in large language models (LLMs), arguing that improvements in coverage can be attributed to skewed answer distributions in evaluation benchmarks and proposing a baseline that uses answer prevalence for a fairer comparison against model sampling.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BERTtime Stories: Investigating the Role of Synthetic Story Data in Language pre-training</title><link>https://arxiv.org/abs/2410.15365</link><description>https://arxiv.org/abs/2410.15365&lt;br /&gt;This paper introduces a baseline for evaluating the efficacy of repeated sampling in large language models (LLMs) by comparing it against a method that enumerates answers based on their prevalence in the training set, revealing that for certain LLMs, this baseline can outperform repeated sampling in coverage on standard evaluation benchmarks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges</title><link>https://arxiv.org/abs/2410.15393</link><description>https://arxiv.org/abs/2410.15393&lt;br /&gt;This paper investigates the efficacy of inference scaling in large language models (LLMs) by comparing repeated sampling strategies with a baseline that enumerates answers according to their prevalence in the training set, revealing insights into how these strategies impact coverage in mathematical reasoning and factual knowledge domains.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Comprehensive Evaluation of Cognitive Biases in LLMs</title><link>https://arxiv.org/abs/2410.15413</link><description>https://arxiv.org/abs/2410.15413&lt;br /&gt;This paper examines the effects of scaling inference compute in large language models, positing that traditional evaluation benchmarks may skew results, and introduces a new baseline that enumerates answers based on training set prevalence to enhance the understanding of coverage improvements from repeated sampling methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Evaluating Consistencies in LLM responses through a Semantic Clustering of Question Answering</title><link>https://arxiv.org/abs/2410.15440</link><description>https://arxiv.org/abs/2410.15440&lt;br /&gt;The paper investigates the effects of repeated sampling in large language models (LLMs) on inference scaling, proposing a baseline that enumerates answer prevalence in the training set to compare against the benefits of repeated model sampling in terms of coverage and problem-solving ability.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CROPE: Evaluating In-Context Adaptation of Vision and Language Models to Culture-Specific Concepts</title><link>https://arxiv.org/abs/2410.15453</link><description>https://arxiv.org/abs/2410.15453&lt;br /&gt;This paper investigates the effectiveness of scaling inference in large language models (LLMs) through repeated sampling, proposing a baseline based on the prevalence of answers in training data, and showing that this baseline may outperform traditional sampling methods in certain domains, thereby allowing for more accurate assessments of inference improvement.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MedLogic-AQA: Enhancing Medical Question Answering with Abstractive Models Focusing on Logical Structures</title><link>https://arxiv.org/abs/2410.15463</link><description>https://arxiv.org/abs/2410.15463&lt;br /&gt;The paper investigates the effectiveness of scaling inference in large language models (LLMs) through repeated sampling, revealing that a newly defined baseline based on answer prevalence can surpass or match the performance of sampling methods, thus providing a clearer understanding of their true impact on coverage of problem-solving across various domains.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Novel Interpretability Metric for Explaining Bias in Language Models: Applications on Multilingual Models from Southeast Asia</title><link>https://arxiv.org/abs/2410.15464</link><description>https://arxiv.org/abs/2410.15464&lt;br /&gt;The paper proposes a new baseline for evaluating the effectiveness of repeated sampling in large language models (LLMs), suggesting that this strategy may not consistently outperform a simpler approach that enumerates answers based on their prevalence in training data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Keep Guessing? When Considering Inference Scaling, Mind the Baselines</title><link>https://arxiv.org/abs/2410.15466</link><description>https://arxiv.org/abs/2410.15466&lt;br /&gt;This paper investigates the effect of scaling inference compute through repeated sampling in large language models, proposing a baseline answer enumeration method that challenges the performance of repeated model sampling in improving problem coverage across domains like mathematical reasoning and factual knowledge.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Hey GPT, Can You be More Racist? Analysis from Crowdsourced Attempts to Elicit Biased Content from Generative AI</title><link>https://arxiv.org/abs/2410.15467</link><description>https://arxiv.org/abs/2410.15467&lt;br /&gt;This paper investigates security vulnerabilities in large language models (LLMs) related to chemistry, introducing a novel SMILES-prompting technique that can bypass safety mechanisms and provide instructions for synthesizing hazardous substances, thus highlighting the need for improved safeguards.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>"What is the value of {templates}?" Rethinking Document Information Extraction Datasets for LLMs</title><link>https://arxiv.org/abs/2410.15484</link><description>https://arxiv.org/abs/2410.15484&lt;br /&gt;This paper investigates the vulnerabilities of large language models (LLMs) in chemistry, focusing on how certain prompting techniques, particularly SMILES-prompting, can exploit these models to provide instructions for synthesizing hazardous substances, thereby revealing the need for improved safety mechanisms.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>RoMemes: A multimodal meme corpus for the Romanian language</title><link>https://arxiv.org/abs/2410.15497</link><description>https://arxiv.org/abs/2410.15497&lt;br /&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in chemistry, introducing a novel attack method called SMILES-prompting, which uses chemical notation to bypass safety mechanisms and provide potentially dangerous synthesis instructions, underscoring the need for improved safeguards in LLM applications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Reverse Question Answering: Can an LLM Write a Question so Hard (or Bad) that it Can't Answer?</title><link>https://arxiv.org/abs/2410.15512</link><description>https://arxiv.org/abs/2410.15512&lt;br /&gt;This paper introduces SMILES-prompting, a novel attack method that utilizes the Simplified Molecular-Input Line-Entry System (SMILES) to exploit security vulnerabilities in large language models (LLMs) specific to the field of chemistry, demonstrating the effectiveness of such attacks in bypassing existing safety mechanisms.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SceneGraMMi: Scene Graph-boosted Hybrid-fusion for Multi-Modal Misinformation Veracity Prediction</title><link>https://arxiv.org/abs/2410.15517</link><description>https://arxiv.org/abs/2410.15517&lt;br /&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in the chemistry domain, introducing a new attack technique called SMILES-prompting, which exploits the Simplified Molecular-Input Line-Entry System to bypass existing safety mechanisms and potentially provide instructions for synthesizing hazardous substances.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>M-RewardBench: Evaluating Reward Models in Multilingual Settings</title><link>https://arxiv.org/abs/2410.15522</link><description>https://arxiv.org/abs/2410.15522&lt;br /&gt;The paper examines security vulnerabilities in large language models (LLMs) related to chemical synthesis, introducing a novel attack method called SMILES-prompting that effectively bypasses current safety mechanisms, underscoring the need for improved safeguards against misuse.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Do RAG Systems Cover What Matters? Evaluating and Optimizing Responses with Sub-Question Coverage</title><link>https://arxiv.org/abs/2410.15531</link><description>https://arxiv.org/abs/2410.15531&lt;br /&gt;This paper examines the security vulnerabilities of large language models (LLMs) in the field of chemistry, introducing a novel attack method called SMILES-prompting that effectively bypasses safety mechanisms to provide instructions for synthesizing hazardous substances, thereby emphasizing the need for improved safeguards.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Grammatical Error Correction for Low-Resource Languages: The Case of Zarma</title><link>https://arxiv.org/abs/2410.15539</link><description>https://arxiv.org/abs/2410.15539&lt;br /&gt;The paper investigates security vulnerabilities within large language models (LLMs) regarding their potential to provide dangerous information in chemical synthesis, introducing a novel attack technique called SMILES-prompting that successfully bypasses existing safety mechanisms.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>WHoW: A Cross-domain Approach for Analysing Conversation Moderation</title><link>https://arxiv.org/abs/2410.15551</link><description>https://arxiv.org/abs/2410.15551&lt;br /&gt;The paper investigates the security vulnerabilities of large language models (LLMs) in chemistry, introducing SMILES-prompting as a novel attack method that can bypass safety mechanisms to potentially provide instructions for synthesizing hazardous substances, thus highlighting the need for enhanced safeguards in LLM applications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Multi-IF: Benchmarking LLMs on Multi-Turn and Multilingual Instructions Following</title><link>https://arxiv.org/abs/2410.15553</link><description>https://arxiv.org/abs/2410.15553&lt;br /&gt;The paper investigates security vulnerabilities in large language models (LLMs) within the field of chemistry, particularly focusing on the risks of LLMs providing instructions for synthesizing hazardous substances, and introduces a novel attack technique called SMILES-prompting that effectively bypasses safety mechanisms.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Stacking Small Language Models for Generalizability</title><link>https://arxiv.org/abs/2410.15570</link><description>https://arxiv.org/abs/2410.15570&lt;br /&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in chemistry, particularly their ability to provide dangerous synthesis instructions, and introduces a novel attack method called SMILES-prompting that can bypass existing safety mechanisms.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Leveraging Retrieval-Augmented Generation for Culturally Inclusive Hakka Chatbots: Design Insights and User Perceptions</title><link>https://arxiv.org/abs/2410.15572</link><description>https://arxiv.org/abs/2410.15572&lt;br /&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in the field of chemistry, particularly focusing on a novel attack method called SMILES-prompting, which uses the Simplified Molecular-Input Line-Entry System to bypass safety mechanisms and potentially facilitate harmful chemical synthesis.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Survey of Conversational Search</title><link>https://arxiv.org/abs/2410.15576</link><description>https://arxiv.org/abs/2410.15576&lt;br /&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in chemistry, specifically focusing on prompt injection attack techniques and introducing a novel method called SMILES-prompting that effectively bypasses safety mechanisms designed to prevent dangerous chemical synthesis instructions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Interventional Speech Noise Injection for ASR Generalizable Spoken Language Understanding</title><link>https://arxiv.org/abs/2410.15609</link><description>https://arxiv.org/abs/2410.15609&lt;br /&gt;This paper investigates security vulnerabilities in large language models (LLMs) regarding their ability to provide potentially hazardous chemical synthesis instructions and introduces a novel attack method called SMILES-prompting, which bypasses existing safety mechanisms.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Guardians of Discourse: Evaluating LLMs on Multilingual Offensive Language Detection</title><link>https://arxiv.org/abs/2410.15623</link><description>https://arxiv.org/abs/2410.15623&lt;br /&gt;This paper investigates the vulnerabilities of large language models (LLMs) in providing instructions for synthesizing hazardous substances and introduces a novel attack method called SMILES-prompting, demonstrating its effectiveness in bypassing safety mechanisms.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Can Large Language Models Invent Algorithms to Improve Themselves?</title><link>https://arxiv.org/abs/2410.15639</link><description>https://arxiv.org/abs/2410.15639&lt;br /&gt;SMILES-Prompting introduces a novel attack technique that exploits the vulnerabilities of large language models in the field of chemistry, demonstrating how they can be manipulated to provide dangerous instructions for synthesizing hazardous substances, emphasizing the need for stronger safety measures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SMILES-Prompting: A Novel Approach to LLM Jailbreak Attacks in Chemical Synthesis</title><link>https://arxiv.org/abs/2410.15641</link><description>https://arxiv.org/abs/2410.15641&lt;br /&gt;The paper introduces SMILES-Prompting, a novel attack technique that leverages chemical notation to exploit vulnerabilities in large language models (LLMs) for providing instructions on hazardous substance synthesis, thus underscoring the need for better safety measures in LLM applications in chemistry.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CausalGraph2LLM: Evaluating LLMs for Causal Queries</title><link>https://arxiv.org/abs/2410.15939</link><description>https://arxiv.org/abs/2410.15939&lt;br /&gt;This paper investigates the grammatical and rhetorical style variations between outputs from Large Language Models (LLMs) and human-written texts, revealing systematic differences across various models and highlighting the struggles of LLMs to fully emulate human writing styles.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Findings of the Third Shared Task on Multilingual Coreference Resolution</title><link>https://arxiv.org/abs/2410.15949</link><description>https://arxiv.org/abs/2410.15949&lt;br /&gt;This paper analyzes variations in grammatical and rhetorical styles between human-written text and that generated by Large Language Models (LLMs), revealing systematic differences that persist across model sizes and imply that LLMs struggle to replicate human writing styles despite their advanced capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs</title><link>https://arxiv.org/abs/2410.15956</link><description>https://arxiv.org/abs/2410.15956&lt;br /&gt;This study investigates the rhetorical and grammatical style differences between human-written texts and those generated by various Large Language Models (LLMs), revealing systematic variations even as LLMs improve in producing grammatically correct outputs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Systematic Exploration of Dialogue Summarization Approaches for Reproducibility, Comparative Assessment, and Methodological Innovations for Advancing Natural Language Processing in Abstractive Summarization</title><link>https://arxiv.org/abs/2410.15962</link><description>https://arxiv.org/abs/2410.15962&lt;br /&gt;This study analyzes the grammatical and rhetorical styles of Large Language Models (LLMs) compared to human writing, revealing systematic differences even among advanced models like Llama 3 and GPT-4o, particularly in instruction-tuned variants, and suggesting that LLMs still struggle to fully emulate human styles.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Self-Explained Keywords Empower Large Language Models for Code Generation</title><link>https://arxiv.org/abs/2410.15966</link><description>https://arxiv.org/abs/2410.15966&lt;br /&gt;This study investigates the grammatical and rhetorical styles of output generated by various Large Language Models (LLMs), revealing systematic differences from human-written text despite the advanced capabilities of LLMs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Policy-driven Knowledge Selection and Response Generation for Document-grounded Dialogue</title><link>https://arxiv.org/abs/2410.15970</link><description>https://arxiv.org/abs/2410.15970&lt;br /&gt;The paper analyzes the differences in grammatical and rhetorical styles between human-written texts and outputs generated by various large language models (LLMs), revealing systematic variations that indicate LLMs do not fully emulate human writing styles despite their advanced capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Large Language Models for Cross-lingual Emotion Detection</title><link>https://arxiv.org/abs/2410.15974</link><description>https://arxiv.org/abs/2410.15974&lt;br /&gt;This paper investigates the differences in grammatical and rhetorical styles between human-written texts and those generated by various Large Language Models (LLMs), revealing systematic variations that persist across different model sizes and specific tuning techniques.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence</title><link>https://arxiv.org/abs/2410.15990</link><description>https://arxiv.org/abs/2410.15990&lt;br /&gt;This paper investigates the differences in grammatical and rhetorical styles between human-written texts and those generated by various large language models (LLMs), revealing systematic variations that persist across model sizes and types, and highlighting the challenges LLMs face in mimicking human writing styles.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>1024m at SMM4H 2024: Tasks 3, 5 &amp; 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification</title><link>https://arxiv.org/abs/2410.15998</link><description>https://arxiv.org/abs/2410.15998&lt;br /&gt;This paper investigates the grammatical and rhetorical differences between human-written texts and those generated by Large Language Models (LLMs), revealing systematic variations that persist across model sizes and types, thereby highlighting challenges LLMs face in fully mimicking human writing styles.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering</title><link>https://arxiv.org/abs/2410.15999</link><description>https://arxiv.org/abs/2410.15999&lt;br /&gt;This study investigates the grammatical and rhetorical styles of Large Language Models (LLMs) compared to human writing, revealing systematic differences in their outputs, particularly in instruction-tuned models, despite their ability to produce grammatical text.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Exploring Continual Fine-Tuning for Enhancing Language Ability in Large Language Model</title><link>https://arxiv.org/abs/2410.16006</link><description>https://arxiv.org/abs/2410.16006&lt;br /&gt;This paper investigates the grammatical and rhetorical styles of Large Language Models (LLMs), revealing systematic differences between LLM and human-written texts, especially in the context of instruction-tuned models compared to base models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CA*: Addressing Evaluation Pitfalls in Computation-Aware Latency for Simultaneous Speech Translation</title><link>https://arxiv.org/abs/2410.16011</link><description>https://arxiv.org/abs/2410.16011&lt;br /&gt;This paper analyzes the differences in grammatical and rhetorical styles between human-written texts and those generated by various large language models (LLMs), revealing systematic variations that indicate LLMs often cannot fully emulate human writing despite their advanced capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ComPO: Community Preferences for Language Model Personalization</title><link>https://arxiv.org/abs/2410.16027</link><description>https://arxiv.org/abs/2410.16027&lt;br /&gt;This paper investigates grammatical and rhetorical style differences between human-written and Large Language Model (LLM)-produced texts, revealing that LLMs exhibit systematic variations in style despite their advanced output capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TreeBoN: Enhancing Inference-Time Alignment with Speculative Tree-Search and Best-of-N Sampling</title><link>https://arxiv.org/abs/2410.16033</link><description>https://arxiv.org/abs/2410.16033&lt;br /&gt;This paper examines the differences in grammatical and rhetorical styles between outputs generated by large language models (LLMs) and human-written text, revealing systematic variations that persist across different models despite their advanced capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Large Language Models Know What To Say But Not When To Speak</title><link>https://arxiv.org/abs/2410.16044</link><description>https://arxiv.org/abs/2410.16044&lt;br /&gt;This paper investigates the differences in grammatical and rhetorical styles between human-written texts and those generated by large language models (LLMs), revealing systematic variations that persist across different model sizes and types.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse</title><link>https://arxiv.org/abs/2410.16062</link><description>https://arxiv.org/abs/2410.16062&lt;br /&gt;This study analyzes grammatical and rhetorical style differences between human-written texts and those produced by various Large Language Models (LLMs), revealing systematic variations in their outputs despite advancements in linguistic capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context</title><link>https://arxiv.org/abs/2410.16069</link><description>https://arxiv.org/abs/2410.16069&lt;br /&gt;This paper investigates the variations in grammatical and rhetorical styles between human-written text and outputs generated by different Large Language Models (LLMs), revealing systematic differences that persist across model sizes and tuning methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fine-Tuning LLMs for Reliable Medical Question-Answering Services</title><link>https://arxiv.org/abs/2410.16088</link><description>https://arxiv.org/abs/2410.16088&lt;br /&gt;This paper explores the variation in grammatical and rhetorical styles between outputs from large language models (LLMs) and human writing, finding systematic differences that persist even as models advance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Analysing the Residual Stream of Language Models Under Knowledge Conflicts</title><link>https://arxiv.org/abs/2410.16090</link><description>https://arxiv.org/abs/2410.16090&lt;br /&gt;This paper examines whether large language models (LLMs) write like humans by analyzing grammatical and rhetorical style differences between human-written and LLM-generated texts, revealing systematic variations in their outputs despite advances in technology.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Do LLMs write like humans? Variation in grammatical and rhetorical styles</title><link>https://arxiv.org/abs/2410.16107</link><description>https://arxiv.org/abs/2410.16107&lt;br /&gt;This study investigates the grammatical and rhetorical style differences between large language models (LLMs) and human writers, revealing systematic distinctions that persist across different model sizes and tuning, indicating that LLMs struggle to fully emulate human writing styles.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Psycholinguistic Evaluation of Language Models' Sensitivity to Argument Roles</title><link>https://arxiv.org/abs/2410.16139</link><description>https://arxiv.org/abs/2410.16139&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by managing a repository-level structure, which significantly improves performance in code generation tasks for large language models (LLMs) in the context of modern software engineering.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs</title><link>https://arxiv.org/abs/2410.16144</link><description>https://arxiv.org/abs/2410.16144&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code understanding, significantly improving the performance of code generation and management systems.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Pangea: A Fully Open Multilingual Multimodal LLM for 39 Languages</title><link>https://arxiv.org/abs/2410.16153</link><description>https://arxiv.org/abs/2410.16153&lt;br /&gt;RepoGraph is a novel plug-in module that enhances AI software engineering by providing repository-level understanding and navigation, significantly improving code generation performance across various methods and benchmarks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns</title><link>https://arxiv.org/abs/2410.16155</link><description>https://arxiv.org/abs/2410.16155&lt;br /&gt;RepoGraph is a plug-in module that enhances AI software engineering by providing repository-level code graph management, significantly improving the performance of code generation methods and enabling better context understanding for modern software engineering tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Limpeh ga li gong: Challenges in Singlish Annotations</title><link>https://arxiv.org/abs/2410.16156</link><description>https://arxiv.org/abs/2410.16156&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code understanding, significantly improving performance across various coding methods on benchmarks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>From Tokens to Materials: Leveraging Language Models for Scientific Discovery</title><link>https://arxiv.org/abs/2410.16165</link><description>https://arxiv.org/abs/2410.16165&lt;br /&gt;RepoGraph is a plug-in module that enhances AI software engineering by managing repository-level structures, improving code generation tasks and overall performance across various AI software engineering frameworks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Exploring Pretraining via Active Forgetting for Improving Cross Lingual Transfer for Decoder Language Models</title><link>https://arxiv.org/abs/2410.16168</link><description>https://arxiv.org/abs/2410.16168&lt;br /&gt;RepoGraph is a plug-in module that enhances AI software engineering by providing a repository-level code graph for better context understanding, thereby improving the performance of various coding methods and achieving state-of-the-art results in software engineering benchmarks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MagicPIG: LSH Sampling for Efficient LLM Generation</title><link>https://arxiv.org/abs/2410.16179</link><description>https://arxiv.org/abs/2410.16179&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code management and navigation capabilities, significantly boosting the performance of various coding frameworks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style</title><link>https://arxiv.org/abs/2410.16184</link><description>https://arxiv.org/abs/2410.16184&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code understanding and guidance, significantly improving the performance of code generation models on software engineering tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Contamination Report for Multilingual Benchmarks</title><link>https://arxiv.org/abs/2410.16186</link><description>https://arxiv.org/abs/2410.16186&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by managing repository-level code graphs, significantly improving the performance of coding systems in a comprehensive evaluation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Information for Conversation Generation: Proposals Utilising Knowledge Graphs</title><link>https://arxiv.org/abs/2410.16196</link><description>https://arxiv.org/abs/2410.16196&lt;br /&gt;RepoGraph is a plug-in module developed to enhance AI software engineering by providing repository-level code understanding and navigation, significantly improving the performance of various code generation methods and achieving state-of-the-art results.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Pre-training Distillation for Large Language Models: A Design Space Exploration</title><link>https://arxiv.org/abs/2410.16215</link><description>https://arxiv.org/abs/2410.16215&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code understanding, significantly improving performance in code generation tasks and establishing a new state-of-the-art in various benchmarks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>On Creating an English-Thai Code-switched Machine Translation in Medical Domain</title><link>https://arxiv.org/abs/2410.16221</link><description>https://arxiv.org/abs/2410.16221&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code understanding and navigation, significantly improving performance across existing coding methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Building A Coding Assistant via the Retrieval-Augmented Language Model</title><link>https://arxiv.org/abs/2410.16229</link><description>https://arxiv.org/abs/2410.16229&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code understanding, significantly improving the performance of large language models on complex coding tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping</title><link>https://arxiv.org/abs/2410.16232</link><description>https://arxiv.org/abs/2410.16232&lt;br /&gt;RepoGraph is a plug-in module that enhances code generation in large language models (LLMs) by providing repository-level structure and management, significantly improving performance on modern AI software engineering tasks compared to traditional coding methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ToW: Thoughts of Words Improve Reasoning in Large Language Models</title><link>https://arxiv.org/abs/2410.16235</link><description>https://arxiv.org/abs/2410.16235&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code understanding and navigation, significantly improving performance across multiple coding frameworks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Analyzing Context Contributions in LLM-based Machine Translation</title><link>https://arxiv.org/abs/2410.16246</link><description>https://arxiv.org/abs/2410.16246&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code understanding and navigation, significantly improving the performance of various coding methods in AI applications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Can Knowledge Editing Really Correct Hallucinations?</title><link>https://arxiv.org/abs/2410.16251</link><description>https://arxiv.org/abs/2410.16251&lt;br /&gt;RepoGraph is a plug-in module that enhances AI software engineering by providing a repository-level code graph structure for better context management and interaction, significantly improving performance across various coding methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution</title><link>https://arxiv.org/abs/2410.16256</link><description>https://arxiv.org/abs/2410.16256&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level code structure and guidance, significantly improving performance in managing and interacting with code repositories, and achieving state-of-the-art results in the SWE-bench framework.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>RepoGraph: Enhancing AI Software Engineering with Repository-level Code Graph</title><link>https://arxiv.org/abs/2410.14684</link><description>https://arxiv.org/abs/2410.14684&lt;br /&gt;RepoGraph is a plug-in module designed to enhance AI software engineering by providing repository-level structure and management, thereby improving the performance of code generation tasks in LLMs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>How to Evaluate Reward Models for RLHF</title><link>https://arxiv.org/abs/2410.14872</link><description>https://arxiv.org/abs/2410.14872&lt;br /&gt;ChitroJera is a new visual question answering dataset designed for Bangla, comprising over 15,000 samples aimed at addressing the lack of culturally relevant benchmarks in this low-resource language, and demonstrating the effectiveness of dual-encoder models and large language models in VQA tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Towards Safer Heuristics With XPlain</title><link>https://arxiv.org/abs/2410.15086</link><description>https://arxiv.org/abs/2410.15086&lt;br /&gt;The paper introduces a Generalized Probabilistic Attention Mechanism (GPAM) within Transformer architectures, which effectively addresses issues of rank-collapse and gradient vanishing associated with traditional attention mechanisms, thereby enhancing performance in natural language processing tasks like language modeling and machine translation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>On Designing Effective RL Reward at Training Time for LLM Reasoning</title><link>https://arxiv.org/abs/2410.15115</link><description>https://arxiv.org/abs/2410.15115&lt;br /&gt;The paper presents the Generalized Probabilistic Attention Mechanism (GPAM), a novel attention mechanism for Transformers that mitigates issues of rank-collapse and gradient vanishing while demonstrating improved performance in natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Evaluation Of P300 Speller Performance Using Large Language Models Along With Cross-Subject Training</title><link>https://arxiv.org/abs/2410.15161</link><description>https://arxiv.org/abs/2410.15161&lt;br /&gt;This paper introduces the generalized probabilistic attention mechanism (GPAM) in Transformers, which effectively resolves the issues of rank-collapse and gradient vanishing in conventional attention mechanisms while demonstrating superior performance in NLP tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Explaining Graph Neural Networks with Large Language Models: A Counterfactual Perspective for Molecular Property Prediction</title><link>https://arxiv.org/abs/2410.15165</link><description>https://arxiv.org/abs/2410.15165&lt;br /&gt;This paper introduces a generalized probabilistic attention mechanism (GPAM) for Transformers, which addresses the rank-collapse and gradient vanishing issues in conventional attention mechanisms by allowing negative attention scores while preserving a fixed sum, demonstrating its effectiveness through theoretical and empirical validation in natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>The Computational Anatomy of Humility: Modeling Intellectual Humility in Online Public Discourse</title><link>https://arxiv.org/abs/2410.15182</link><description>https://arxiv.org/abs/2410.15182&lt;br /&gt;The paper introduces the generalized probabilistic attention mechanism (GPAM) as a novel attention mechanism for Transformers, which addresses the issues of rank-collapse and gradient vanishing while demonstrating superior performance in natural language processing tasks compared to conventional attention mechanisms.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Chasing Random: Instruction Selection Strategies Fail to Generalize</title><link>https://arxiv.org/abs/2410.15225</link><description>https://arxiv.org/abs/2410.15225&lt;br /&gt;This paper introduces a Generalized Probabilistic Attention Mechanism (GPAM) within the Transformer architecture that effectively mitigates the issues of rank-collapse and gradient vanishing, improving performance in natural language processing tasks such as language modeling and neural machine translation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>When Machine Unlearning Meets Retrieval-Augmented Generation (RAG): Keep Secret or Forget Knowledge?</title><link>https://arxiv.org/abs/2410.15267</link><description>https://arxiv.org/abs/2410.15267&lt;br /&gt;This paper introduces a novel generalized probabilistic attention mechanism (GPAM) within the Transformer architecture, which addresses the rank-collapse and gradient vanishing issues of conventional attention mechanisms, and demonstrates its superiority in various natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models</title><link>https://arxiv.org/abs/2410.15268</link><description>https://arxiv.org/abs/2410.15268&lt;br /&gt;This paper introduces the Generalized Probabilistic Attention Mechanism (GPAM) for Transformers, which addresses rank-collapse and gradient vanishing issues in conventional attention mechanisms by allowing negative attention scores while maintaining a fixed total sum, and demonstrates its effectiveness in natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Large Language Models for Autonomous Driving (LLM4AD): Concept, Benchmark, Simulation, and Real-Vehicle Experiment</title><link>https://arxiv.org/abs/2410.15281</link><description>https://arxiv.org/abs/2410.15281&lt;br /&gt;The paper presents a Generalized Probabilistic Attention Mechanism (GPAM) in Transformers, which effectively addresses rank-collapse and gradient vanishing issues associated with conventional attention mechanisms, enhancing performance in natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Who is Undercover? Guiding LLMs to Explore Multi-Perspective Team Tactic in the Game</title><link>https://arxiv.org/abs/2410.15311</link><description>https://arxiv.org/abs/2410.15311&lt;br /&gt;This paper introduces a generalized probabilistic attention mechanism (GPAM) in Transformers that effectively addresses issues of rank-collapse and gradient vanishing while enhancing performance in natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>EPIC: Efficient Position-Independent Context Caching for Serving Large Language Models</title><link>https://arxiv.org/abs/2410.15332</link><description>https://arxiv.org/abs/2410.15332&lt;br /&gt;This paper introduces a generalized probabilistic attention mechanism (GPAM) that addresses the issues of rank-collapse and gradient vanishing in traditional transformer attention mechanisms, enhancing performance in natural language processing tasks like language modeling and neural machine translation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CompAct: Compressed Activations for Memory-Efficient LLM Training</title><link>https://arxiv.org/abs/2410.15352</link><description>https://arxiv.org/abs/2410.15352&lt;br /&gt;The paper introduces a novel generalized probabilistic attention mechanism (GPAM) for Transformers, which addresses the issues of rank-collapse and gradient vanishing in conventional attention mechanisms, thereby demonstrating superior performance in natural language processing tasks such as language modeling and translation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Faster-GCG: Efficient Discrete Optimization Jailbreak Attacks against Aligned Large Language Models</title><link>https://arxiv.org/abs/2410.15362</link><description>https://arxiv.org/abs/2410.15362&lt;br /&gt;The paper introduces a Generalized Probabilistic Attention Mechanism (GPAM) for Transformers, which addresses the challenges of rank-collapse and gradient vanishing in conventional attention mechanisms while enhancing performance in natural language processing tasks such as language modeling and neural machine translation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>IPO: Interpretable Prompt Optimization for Vision-Language Models</title><link>https://arxiv.org/abs/2410.15397</link><description>https://arxiv.org/abs/2410.15397&lt;br /&gt;The paper introduces a novel generalized probabilistic attention mechanism (GPAM) that addresses the rank-collapse and gradient vanishing issues in Transformer architecture, showcasing its effectiveness through theoretical analysis and empirical validation in natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Hallucination Detox: Sensitive Neuron Dropout (SeND) for Large Language Model Training</title><link>https://arxiv.org/abs/2410.15460</link><description>https://arxiv.org/abs/2410.15460&lt;br /&gt;The paper introduces a novel generalized probabilistic attention mechanism (GPAM) for Transformers, addressing rank-collapse and gradient vanishing issues in conventional attention mechanisms while providing empirical evidence of its superiority in natural language processing tasks such as language modeling and neural machine translation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Mitigating Forgetting in LLM Supervised Fine-Tuning and Preference Learning</title><link>https://arxiv.org/abs/2410.15483</link><description>https://arxiv.org/abs/2410.15483&lt;br /&gt;This paper introduces the Generalized Probabilistic Attention Mechanism (GPAM) in Transformers, which effectively tackles the issues of rank-collapse and gradient vanishing inherent in conventional attention mechanisms, demonstrating improved performance in natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Exploring Curriculum Learning for Vision-Language Tasks: A Study on Small-Scale Multimodal Training</title><link>https://arxiv.org/abs/2410.15509</link><description>https://arxiv.org/abs/2410.15509&lt;br /&gt;This paper introduces a Generalized Probabilistic Attention Mechanism (GPAM) in Transformers, addressing the issues of rank-collapse and gradient vanishing while improving performance in natural language processing tasks such as language modeling and machine translation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Pruning Foundation Models for High Accuracy without Retraining</title><link>https://arxiv.org/abs/2410.15567</link><description>https://arxiv.org/abs/2410.15567&lt;br /&gt;The paper introduces a generalized probabilistic attention mechanism (GPAM) and its dual-attention implementation for Transformers, effectively mitigating issues related to rank-collapse and gradient vanishing, and demonstrating improved performance in natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>OpenMU: Your Swiss Army Knife for Music Understanding</title><link>https://arxiv.org/abs/2410.15573</link><description>https://arxiv.org/abs/2410.15573&lt;br /&gt;The paper introduces a generalized probabilistic attention mechanism (GPAM) for Transformers, designed to address the issues of rank-collapse and gradient vanishing inherent in conventional attention mechanisms, while demonstrating improvements in natural language processing tasks such as language modeling and translation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Generalized Probabilistic Attention Mechanism in Transformers</title><link>https://arxiv.org/abs/2410.15578</link><description>https://arxiv.org/abs/2410.15578&lt;br /&gt;This paper introduces the Generalized Probabilistic Attention Mechanism (GPAM) in Transformers, which effectively addresses the issues of rank-collapse and gradient vanishing in conventional attention mechanisms, enhancing the performance of natural language processing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Causally Testing Gender Bias in LLMs: A Case Study on Occupational Bias</title><link>https://arxiv.org/abs/2212.10678</link><description>https://arxiv.org/abs/2212.10678&lt;br /&gt;This paper presents FACTUAL, a Counterfactual Augmented Calibration Network designed to mitigate biases in stance detection by calibrating predictions from Large Language Models (LLMs) and utilizing counterfactual augmented data to enhance debiasing and generalizability.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Benchmarking Machine Translation with Cultural Awareness</title><link>https://arxiv.org/abs/2305.14328</link><description>https://arxiv.org/abs/2305.14328&lt;br /&gt;The paper introduces FACTUAL, a Counterfactual Augmented Calibration Network designed to mitigate biases in Large Language Models (LLMs) during stance detection, thereby enhancing their performance and generalizability across different topics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Persona-aware Generative Model for Code-mixed Language</title><link>https://arxiv.org/abs/2309.02915</link><description>https://arxiv.org/abs/2309.02915&lt;br /&gt;This paper presents FACTUAL, a Counterfactual Augmented Calibration Network designed to mitigate biases in stance detection by calibrating stance predictions from Large Language Models (LLMs) and using counterfactual augmented data for improved generalizability.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Machine-assisted quantitizing designs: augmenting humanities and social sciences with artificial intelligence</title><link>https://arxiv.org/abs/2309.14379</link><description>https://arxiv.org/abs/2309.14379&lt;br /&gt;The paper proposes a Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in stance detection predictions made by Large Language Models (LLMs), addressing spurious correlations that impair performance and enhancing generalizability through counterfactual augmented data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Toxicity Detection is NOT all you Need: Measuring the Gaps to Supporting Volunteer Content Moderators</title><link>https://arxiv.org/abs/2311.07879</link><description>https://arxiv.org/abs/2311.07879&lt;br /&gt;This paper presents the Counterfactual Augmented Calibration Network (FACTUAL), a novel approach to mitigate biases in stance detection performed by Large Language Models (LLMs) by implementing counterfactual augmented data and a calibration network, resulting in improved stance detection performance and reduced bias.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Self-Contradictory Reasoning Evaluation and Detection</title><link>https://arxiv.org/abs/2311.09603</link><description>https://arxiv.org/abs/2311.09603&lt;br /&gt;This paper introduces FACTUAL, a Counterfactual Augmented Calibration Network designed to mitigate biases in stance detection by calibrating the stance predictions of Large Language Models (LLMs) and enhancing generalizability through counterfactual augmented data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Downstream Trade-offs of a Family of Text Watermarks</title><link>https://arxiv.org/abs/2311.09816</link><description>https://arxiv.org/abs/2311.09816&lt;br /&gt;This paper presents a Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in stance detection performed by Large Language Models (LLMs), improving their performance by addressing spurious correlations inherent in their training data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Latent Skill Discovery for Chain-of-Thought Reasoning</title><link>https://arxiv.org/abs/2312.04684</link><description>https://arxiv.org/abs/2312.04684&lt;br /&gt;This paper introduces the Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in stance detection performed by Large Language Models (LLMs), demonstrating that addressing these biases can significantly improve detection performance in both targeted and zero-shot tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Aligning Translation-Specific Understanding to General Understanding in Large Language Models</title><link>https://arxiv.org/abs/2401.05072</link><description>https://arxiv.org/abs/2401.05072&lt;br /&gt;This paper presents the Counterfactual Augmented Calibration Network (FACTUAL), a novel approach aimed at mitigating biases in stance detection by calibrating bias in the predictions of Large Language Models (LLMs) using counterfactual augmented data, ultimately improving their performance in stance detection tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>The Benefits of a Concise Chain of Thought on Problem-Solving in Large Language Models</title><link>https://arxiv.org/abs/2401.05618</link><description>https://arxiv.org/abs/2401.05618&lt;br /&gt;The paper proposes a Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in stance detection by calibrating biases in Large Language Models (LLMs), thereby enhancing performance and generalization capabilities across different tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought Reasoning</title><link>https://arxiv.org/abs/2401.17686</link><description>https://arxiv.org/abs/2401.17686&lt;br /&gt;This paper presents the Counterfactual Augmented Calibration Network (FACTUAL) to effectively mitigate biases in stance detection by calibrating LLMs and enhancing their performance through counterfactual augmented data, addressing the issues of sentiment-stance spurious correlations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>INSIDE: LLMs' Internal States Retain the Power of Hallucination Detection</title><link>https://arxiv.org/abs/2402.03744</link><description>https://arxiv.org/abs/2402.03744&lt;br /&gt;The paper presents FACTUAL, a Counterfactual Augmented Calibration Network designed to mitigate biases in large language models (LLMs) during stance detection, improving their overall performance and generalizability in predicting stances by calibrating potential bias through counterfactual augmented data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Can LLMs Recognize Toxicity? A Structured Investigation Framework and Toxicity Metric</title><link>https://arxiv.org/abs/2402.06900</link><description>https://arxiv.org/abs/2402.06900&lt;br /&gt;This paper introduces a Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in stance detection by Large Language Models (LLMs), demonstrating that enhanced calibration can improve detection performance and generalization in biases related to sentiment and preference.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Neural machine translation of clinical procedure codes for medical diagnosis and uncertainty quantification</title><link>https://arxiv.org/abs/2402.10940</link><description>https://arxiv.org/abs/2402.10940&lt;br /&gt;This paper introduces a Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in stance detection by Large Language Models (LLMs), demonstrating that addressing these biases enhances performance and generalizability in stance detection tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Intervention Lens: from Representation Surgery to String Counterfactuals</title><link>https://arxiv.org/abs/2402.11355</link><description>https://arxiv.org/abs/2402.11355&lt;br /&gt;The paper introduces a Counterfactual Augmented Calibration Network (FACTUAL) designed to mitigate biases in stance detection by calibrating bias in predictions and improving generalizability through counterfactual augmented data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SymBa: Symbolic Backward Chaining for Structured Natural Language Reasoning</title><link>https://arxiv.org/abs/2402.12806</link><description>https://arxiv.org/abs/2402.12806&lt;br /&gt;The paper introduces Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in Large Language Models (LLMs) during stance detection, demonstrating that biased stances adversely affect detection performance and showcasing FACTUAL's effectiveness in achieving state-of-the-art results through debiasing techniques.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Survey on Knowledge Distillation of Large Language Models</title><link>https://arxiv.org/abs/2402.13116</link><description>https://arxiv.org/abs/2402.13116&lt;br /&gt;This paper introduces the Counterfactual Augmented Calibration Network (FACTUAL), which aims to mitigate biases in stance detection by calibrating bias in Large Language Models (LLMs) using counterfactual augmented data, improving both their bias mitigation and generalization performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CriticEval: Evaluating Large Language Model as Critic</title><link>https://arxiv.org/abs/2402.13764</link><description>https://arxiv.org/abs/2402.13764&lt;br /&gt;This paper introduces the Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in Large Language Models (LLMs) during stance detection, demonstrating that addressing these biases can significantly enhance performance and generalization in stance recognition tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Mitigating Biases of Large Language Models in Stance Detection with Counterfactual Augmented Calibration</title><link>https://arxiv.org/abs/2402.14296</link><description>https://arxiv.org/abs/2402.14296&lt;br /&gt;The paper introduces the Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in stance detection by calibrating bias in predictions of Large Language Models (LLMs) while using counterfactual augmented data for improved generalization.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Beware of Words: Evaluating the Lexical Diversity of Conversational LLMs using ChatGPT as Case Study</title><link>https://arxiv.org/abs/2402.15518</link><description>https://arxiv.org/abs/2402.15518&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) in large language models, revealing insights about parameter activation, expert selection mechanisms, and the diversity of experts across layers, ultimately providing guidance for future MoE architectures and implementations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization</title><link>https://arxiv.org/abs/2403.00067</link><description>https://arxiv.org/abs/2403.00067&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) models in large language contexts, revealing insights into neuron behavior, expert selection, and the dynamics of expert diversity across layers, while also providing practical recommendations for MoE practitioners.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Log Probabilities Are a Reliable Estimate of Semantic Plausibility in Base and Instruction-Tuned Language Models</title><link>https://arxiv.org/abs/2403.14859</link><description>https://arxiv.org/abs/2403.14859&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) architectures in large language models, revealing insights into expert behavior, router selection mechanisms, and the increase in expert diversity, which can guide future research and practical applications in MoE frameworks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>GPT-4 Understands Discourse at Least as Well as Humans Do</title><link>https://arxiv.org/abs/2403.17196</link><description>https://arxiv.org/abs/2403.17196&lt;br /&gt;This paper investigates the internal mechanisms of Mixture-of-Experts (MoE) in large language models, revealing how neuron activity resembles expert behavior, examining the router's selection dynamics, and suggesting design improvements based on observed expert diversity.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Bi-consolidating Model for Joint Relational Triple Extraction</title><link>https://arxiv.org/abs/2404.03881</link><description>https://arxiv.org/abs/2404.03881&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) in large language models, revealing key observations about neuron behavior, router performance, and expert diversity, while providing guidance for optimizing MoE architectures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Claim Check-Worthiness Detection: How Well do LLMs Grasp Annotation Guidelines?</title><link>https://arxiv.org/abs/2404.12174</link><description>https://arxiv.org/abs/2404.12174&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) in large language models, revealing findings about expert selection, diversity, and implications for future MoE research and architecture design.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Dependency-Aware Semi-Structured Sparsity of GLU Variants in Large Language Models</title><link>https://arxiv.org/abs/2405.01943</link><description>https://arxiv.org/abs/2405.01943&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) in large language models, revealing insights about expert selection, behavior, and the unique contributions of neurons within the architecture, and offering practical suggestions for MoE implementation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain</title><link>https://arxiv.org/abs/2405.02144</link><description>https://arxiv.org/abs/2405.02144&lt;br /&gt;This paper explores the inner workings of Mixture-of-Experts (MoE) in large language models, investigating their parametric and behavioral features, and providing insights into expert selection and diversity across model layers.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DOLOMITES: Domain-Specific Long-Form Methodical Tasks</title><link>https://arxiv.org/abs/2405.05938</link><description>https://arxiv.org/abs/2405.05938&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) architectures in large language models, revealing key behavioral and parametric features, including expert selection processes and the impact of layer depth on expert diversity.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys</title><link>https://arxiv.org/abs/2405.19323</link><description>https://arxiv.org/abs/2405.19323&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) architectures in large language models, revealing insights on expert selection, neuron behavior, and recommendations for future MoE implementations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Improving code-mixed hate detection by native sample mixing: A case study for Hindi-English code-mixed scenario</title><link>https://arxiv.org/abs/2405.20755</link><description>https://arxiv.org/abs/2405.20755&lt;br /&gt;This paper explores the inner workings of Mixture-of-Experts (MoE) in large language models, revealing behavioral features and providing insights into expert selection and diversity in neural architectures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Persian Homograph Disambiguation: Leveraging ParsBERT for Enhanced Sentence Understanding with a Novel Word Disambiguation Dataset</title><link>https://arxiv.org/abs/2406.00028</link><description>https://arxiv.org/abs/2406.00028&lt;br /&gt;This paper investigates the internal mechanisms of Mixture-of-Experts (MoE) architectures in large language models, revealing unique observations about neuron behavior, expert selection, and diversity across layers, while providing insights and suggestions for future practitioners in MoE design.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Analyzing Social Biases in Japanese Large Language Models</title><link>https://arxiv.org/abs/2406.02050</link><description>https://arxiv.org/abs/2406.02050&lt;br /&gt;This paper explores the mechanisms and characteristics of Mixture-of-Experts (MoE) in large language models, revealing insights into the behavior of neurons as experts, the routing processes, and implications for model design.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Deconstructing The Ethics of Large Language Models from Long-standing Issues to New-emerging Dilemmas: A Survey</title><link>https://arxiv.org/abs/2406.05392</link><description>https://arxiv.org/abs/2406.05392&lt;br /&gt;This paper investigates the inner workings of Mixture-of-Experts (MoE) in large language models, revealing insights into its parametric and behavioral features while offering guidelines for enhancing router design and expert allocation in MoE architecture.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Non-autoregressive Generation Framework for End-to-End Simultaneous Speech-to-Speech Translation</title><link>https://arxiv.org/abs/2406.06937</link><description>https://arxiv.org/abs/2406.06937&lt;br /&gt;This paper explores the inner workings of Mixture-of-Experts (MoE) architectures in large language models, revealing insights into their parametric behaviors and highlighting the modularization challenges and performance trade-offs associated with this design.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Concentrate Attention: Towards Domain-Generalizable Prompt Optimization for Language Models</title><link>https://arxiv.org/abs/2406.10584</link><description>https://arxiv.org/abs/2406.10584&lt;br /&gt;This paper explores the inner workings of Mixture-of-Experts (MoE) architecture in large language models, revealing key observations about parametric and behavioral features that highlight how neurons function as experts and how routing mechanisms operate within these models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>StrucText-Eval: Evaluating Large Language Model's Reasoning Ability in Structure-Rich Text</title><link>https://arxiv.org/abs/2406.10621</link><description>https://arxiv.org/abs/2406.10621&lt;br /&gt;This paper explores the inner workings of Mixture-of-Experts (MoE) architectures in large language models, revealing insights into parametric and behavioral features, including how neurons function as fine-grained experts and the selection process of the router for activating experts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in Sequence-Level Knowledge Distillation</title><link>https://arxiv.org/abs/2406.13114</link><description>https://arxiv.org/abs/2406.13114&lt;br /&gt;This paper investigates the mechanisms and performance of Mixture-of-Experts (MoE) architectures in large language models, revealing key behavioral features, the role of routers in selecting experts, and providing insights for optimizing MoE implementations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Gaussian-Noise-free Text-Image Corruption and Evaluation</title><link>https://arxiv.org/abs/2406.16320</link><description>https://arxiv.org/abs/2406.16320&lt;br /&gt;This paper investigates the internal mechanisms and effectiveness of Mixture-of-Experts (MoE) architectures in large language models, revealing insights into expert selection, the behavior of neurons as fine-grained experts, and suggestions for improving router designs and expert allocation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Closer Look into Mixture-of-Experts in Large Language Models</title><link>https://arxiv.org/abs/2406.18219</link><description>https://arxiv.org/abs/2406.18219&lt;br /&gt;This paper investigates the mechanisms of Mixture-of-Experts (MoE) architectures in large language models, revealing insights into their parametric and behavioral features, as well as offering practical guidance for their implementation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>The Illusion of Competence: Evaluating the Effect of Explanations on Users' Mental Models of Visual Question Answering Systems</title><link>https://arxiv.org/abs/2406.19170</link><description>https://arxiv.org/abs/2406.19170&lt;br /&gt;The CLC-UKET dataset is developed to benchmark case outcome prediction for the UK Employment Tribunal by utilizing large language models for automatic legal annotation and demonstrating that finetuned transformer models outperform zero-shot and few-shot models in predicting case outcomes.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees</title><link>https://arxiv.org/abs/2407.00499</link><description>https://arxiv.org/abs/2407.00499&lt;br /&gt;The CLC-UKET dataset facilitates the prediction of case outcomes in the UK Employment Tribunal by utilizing large language models for automatic annotation of approximately 19,000 cases, providing a benchmark for comparison with human predictions and enhancing access to justice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Language Model Alignment in Multilingual Trolley Problems</title><link>https://arxiv.org/abs/2407.02273</link><description>https://arxiv.org/abs/2407.02273&lt;br /&gt;The CLC-UKET dataset facilitates case outcome prediction for the UK Employment Tribunal by leveraging a large language model for automatic annotation of around 19,000 cases, resulting in superior performance from finetuned transformer models compared to zero-shot and few-shot approaches.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Data, Data Everywhere: A Guide for Pretraining Dataset Construction</title><link>https://arxiv.org/abs/2407.06380</link><description>https://arxiv.org/abs/2407.06380&lt;br /&gt;The CLC-UKET dataset introduces a benchmark for predicting case outcomes in the UK Employment Tribunal by leveraging a large language model for automatic annotation, encompassing approximately 19,000 cases and their comprehensive legal metadata to enhance access to justice and facilitate case outcome prediction tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts</title><link>https://arxiv.org/abs/2407.09447</link><description>https://arxiv.org/abs/2407.09447&lt;br /&gt;The CLC-UKET dataset establishes a benchmark for predicting case outcomes in the UK Employment Tribunal using a large language model for automatic annotation of 19,000 cases, facilitating comparison of model performance in legal predictions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Diversifying the Expert Knowledge for Task-Agnostic Pruning in Sparse Mixture-of-Experts</title><link>https://arxiv.org/abs/2407.09590</link><description>https://arxiv.org/abs/2407.09590&lt;br /&gt;The CLC-UKET dataset provides a benchmark for predicting case outcomes in the UK Employment Tribunal, utilizing a large language model for automated annotation of approximately 19,000 cases, which aids in enhancing access to justice through effective model comparisons.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions</title><link>https://arxiv.org/abs/2407.11417</link><description>https://arxiv.org/abs/2407.11417&lt;br /&gt;The CLC-UKET dataset is created to benchmark case outcome prediction in the UK Employment Tribunal by employing a large language model for automatic annotations, which includes 19,000 cases and aims to enhance the accessibility and efficiency of legal dispute resolution processes.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Truth is Universal: Robust Detection of Lies in LLMs</title><link>https://arxiv.org/abs/2407.12831</link><description>https://arxiv.org/abs/2407.12831&lt;br /&gt;The CLC-UKET dataset is developed to benchmark case outcome prediction in the UK Employment Tribunal using automatic annotation via large language models, consisting of approximately 19,000 cases with comprehensive legal annotations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?</title><link>https://arxiv.org/abs/2407.15711</link><description>https://arxiv.org/abs/2407.15711&lt;br /&gt;The CLC-UKET paper presents the CLC-UKET dataset for predicting case outcomes in the UK Employment Tribunal using a large language model for automatic annotation, evaluating multiple models to benchmark performance in legal prediction tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models</title><link>https://arxiv.org/abs/2407.16470</link><description>https://arxiv.org/abs/2407.16470&lt;br /&gt;The CLC-UKET dataset is developed to benchmark case outcome prediction in the UK Employment Tribunal by leveraging a large language model for automatic annotation, resulting in a dataset of approximately 19,000 cases and comprehensive legal metadata.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation</title><link>https://arxiv.org/abs/2407.18698</link><description>https://arxiv.org/abs/2407.18698&lt;br /&gt;The study introduces the CLC-UKET dataset, comprising approximately 19,000 UK Employment Tribunal cases and their metadata, to benchmark case outcome prediction using large language models, revealing that fine-tuned transformer models outperform zero-shot and few-shot approaches.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>mbrs: A Library for Minimum Bayes Risk Decoding</title><link>https://arxiv.org/abs/2408.04167</link><description>https://arxiv.org/abs/2408.04167&lt;br /&gt;The CLC-UKET dataset provides a benchmark for predicting case outcomes in the UK Employment Tribunal, utilizing a large language model for automatic annotation and facilitating comparison between human predictions and various model performances.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLM-DetectAIve: a Tool for Fine-Grained Machine-Generated Text Detection</title><link>https://arxiv.org/abs/2408.04284</link><description>https://arxiv.org/abs/2408.04284&lt;br /&gt;The CLC-UKET dataset is developed to benchmark case outcome prediction for the UK Employment Tribunal, employing a large language model for automatic annotation of approximately 19,000 cases and assessing the performance of various prediction models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Persona is a Double-edged Sword: Mitigating the Negative Impact of Role-playing Prompts in Zero-shot Reasoning Tasks</title><link>https://arxiv.org/abs/2408.08631</link><description>https://arxiv.org/abs/2408.08631&lt;br /&gt;The CLC-UKET dataset is created to benchmark case outcome prediction in the UK Employment Tribunal by utilizing a large language model for automatic annotation, comprising around 19,000 cases with comprehensive legal data, which facilitates the evaluation of various prediction models including fine-tuned and zero-shot approaches.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BnSentMix: A Diverse Bengali-English Code-Mixed Dataset for Sentiment Analysis</title><link>https://arxiv.org/abs/2408.08964</link><description>https://arxiv.org/abs/2408.08964&lt;br /&gt;The CLC-UKET dataset provides a benchmark for predicting case outcomes in the UK Employment Tribunal by employing large language models for automatic annotation of approximately 19,000 cases, and it demonstrates that finetuned transformer models outperform zero-shot and few-shot LLMs in this prediction task.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Crafting Tomorrow's Headlines: Neural News Generation and Detection in English, Turkish, Hungarian, and Persian</title><link>https://arxiv.org/abs/2408.10724</link><description>https://arxiv.org/abs/2408.10724&lt;br /&gt;The CLC-UKET dataset provides a benchmark for predicting case outcomes in the UK Employment Tribunal by employing a large language model for automatic annotation, resulting in approximately 19,000 cases with comprehensive legal metadata and annotations to facilitate multi-class outcome prediction tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>How Well Do LLMs Handle Cantonese? Benchmarking Cantonese Capabilities of Large Language Models</title><link>https://arxiv.org/abs/2408.16756</link><description>https://arxiv.org/abs/2408.16756&lt;br /&gt;The CLC-UKET dataset is developed to benchmark case outcome prediction in the UK Employment Tribunal by leveraging a large language model for automatic annotation of approximately 19,000 cases, ultimately facilitating improved performance in legal predictions based on empirical findings.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TinyAgent: Function Calling at the Edge</title><link>https://arxiv.org/abs/2409.00608</link><description>https://arxiv.org/abs/2409.00608&lt;br /&gt;The CLC-UKET dataset is developed to benchmark case outcome prediction in the UK Employment Tribunal by utilizing a large language model for automatic annotation of approximately 19,000 cases, enabling multi-class prediction tasks and indicating that finetuned transformer models outperform LLMs in this context.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A corpus-based investigation of pitch contours of monosyllabic words in conversational Taiwan Mandarin</title><link>https://arxiv.org/abs/2409.07891</link><description>https://arxiv.org/abs/2409.07891&lt;br /&gt;The CLC-UKET dataset introduces a benchmark for predicting case outcomes in the UK Employment Tribunal, utilizing a large language model for automatic annotation of around 19,000 cases and demonstrating that finetuned transformer models outperform LLMs in this task.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>The CLC-UKET Dataset: Benchmarking Case Outcome Prediction for the UK Employment Tribunal</title><link>https://arxiv.org/abs/2409.08098</link><description>https://arxiv.org/abs/2409.08098&lt;br /&gt;The CLC-UKET dataset facilitates the benchmarking of case outcome prediction in the UK Employment Tribunal by utilizing a large language model for automatic annotation, encompassing approximately 19,000 cases and comprehensive legal metadata to enhance access to justice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>On the Role of Context in Reading Time Prediction</title><link>https://arxiv.org/abs/2409.08160</link><description>https://arxiv.org/abs/2409.08160&lt;br /&gt;This paper investigates how well language models capture long-range contextual information using perturbation methods and demonstrates that different model architectures show varying capacities for encoding complex sequences over long contexts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented Generation</title><link>https://arxiv.org/abs/2409.12941</link><description>https://arxiv.org/abs/2409.12941&lt;br /&gt;This paper investigates how well contextualized representations in neural autoregressive language models encode long-range context, revealing that different architectures and training configurations significantly affect the ability to handle long-range dependencies, which impacts downstream task performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Do Large Language Models Need a Content Delivery Network?</title><link>https://arxiv.org/abs/2409.13761</link><description>https://arxiv.org/abs/2409.13761&lt;br /&gt;This paper investigates how well neural autoregressive language models encode long-range contextual information, highlighting differences in performance related to representation geometry and contextualization across various model architectures and training configurations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Rephrase and Contrast: Fine-Tuning Language Models for Enhanced Understanding of Communication and Computer Networks</title><link>https://arxiv.org/abs/2409.19007</link><description>https://arxiv.org/abs/2409.19007&lt;br /&gt;This paper investigates how contextual representations in neural autoregressive language models capture long-range context, showing that differing perplexity can lead to varied performance in downstream tasks and suggesting improvements for encoding high-complexity sequences.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>INC-Math: Integrating Natural Language and Code for Enhanced Mathematical Reasoning in Large Language Models</title><link>https://arxiv.org/abs/2409.19381</link><description>https://arxiv.org/abs/2409.19381&lt;br /&gt;This paper investigates the capability of various neural autoregressive language models to encode long-range context by analyzing contextual representations and their performance on downstream tasks, revealing significant differences in how models capture long-range dependencies.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Can Large Language Models Analyze Graphs like Professionals? A Benchmark, Datasets and Models</title><link>https://arxiv.org/abs/2409.19667</link><description>https://arxiv.org/abs/2409.19667&lt;br /&gt;This paper investigates how contextualized representations in neural autoregressive language models, particularly those spanning long-range contexts, affect downstream task performance, revealing significant differences based on representation geometry and model architectures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models</title><link>https://arxiv.org/abs/2410.02355</link><description>https://arxiv.org/abs/2410.02355&lt;br /&gt;This paper analyzes how effectively neural autoregressive language models, particularly decoder-only Transformers, encode long-range contexts by employing a perturbation setup and a metric to assess the contextual representation geometry, revealing insights about model performance differences driven by long-range context capacity.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Enhancing Short-Text Topic Modeling with LLM-Driven Context Expansion and Prefix-Tuned VAEs</title><link>https://arxiv.org/abs/2410.03071</link><description>https://arxiv.org/abs/2410.03071&lt;br /&gt;This paper investigates how well contextualized representations in neural autoregressive language models encode long-range context, revealing significant differences in task performance despite similar perplexity metrics depending on the degree of contextualization.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>One2set + Large Language Model: Best Partners for Keyphrase Generation</title><link>https://arxiv.org/abs/2410.03421</link><description>https://arxiv.org/abs/2410.03421&lt;br /&gt;This study investigates the ability of neural autoregressive language models to encode long-range contextual information, revealing that different architectures and training configurations significantly affect performance on downstream tasks related to this encoding.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Efficient Few-shot Learning for Multi-label Classification of Scientific Documents with Many Classes</title><link>https://arxiv.org/abs/2410.05770</link><description>https://arxiv.org/abs/2410.05770&lt;br /&gt;This paper investigates the ability of neural autoregressive language models to encode long-range contextual information, revealing that models with different architectures and training configurations exhibit varying capacities for representing complex sequences and contextual relationships across thousands of tokens.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context</title><link>https://arxiv.org/abs/2410.07567</link><description>https://arxiv.org/abs/2410.07567&lt;br /&gt;This paper examines the capability of neural autoregressive language models to encode long-range contextual information, demonstrating varying performance in downstream tasks based on the degree of contextualization achieved, particularly in reference to perplexity and representation geometry.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets</title><link>https://arxiv.org/abs/2410.07991</link><description>https://arxiv.org/abs/2410.07991&lt;br /&gt;This paper investigates how well neural autoregressive language models, particularly decoder-only Transformers, encode long-range contextual information over several thousand tokens, revealing substantial differences in performance based on representation geometry and model architecture.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>On the token distance modeling ability of higher RoPE attention dimension</title><link>https://arxiv.org/abs/2410.08703</link><description>https://arxiv.org/abs/2410.08703&lt;br /&gt;This paper investigates how well contextualized representations in neural autoregressive language models capture long-range context, revealing significant differences in downstream task performance based on the degree of contextualization and suggesting ways to improve language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Effi-Code: Unleashing Code Efficiency in Language Models</title><link>https://arxiv.org/abs/2410.10209</link><description>https://arxiv.org/abs/2410.10209&lt;br /&gt;This paper analyzes how contextual representations in neural autoregressive language models, particularly decoder-only Transformers, encode long-range contexts spanning thousands of tokens, revealing differences in downstream performance linked to the contextualization of such content and suggesting future directions for model improvement.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning</title><link>https://arxiv.org/abs/2410.10360</link><description>https://arxiv.org/abs/2410.10360&lt;br /&gt;This paper investigates how well different neural autoregressive language models encode long-range contexts, revealing that varying perplexity can result in significantly different downstream task performance due to differences in representation geometry and contextualization of long-range content.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Translation Canvas: An Explainable Interface to Pinpoint and Analyze Translation Systems</title><link>https://arxiv.org/abs/2410.10861</link><description>https://arxiv.org/abs/2410.10861&lt;br /&gt;This paper investigates how well contextualized representations in neural autoregressive language models, particularly decoder-only Transformers, encode long-range context, revealing significant differences in performance based on the degree of contextualization achieved by various architectures and training configurations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Improving the Language Understanding Capabilities of Large Language Models Using Reinforcement Learning</title><link>https://arxiv.org/abs/2410.11020</link><description>https://arxiv.org/abs/2410.11020&lt;br /&gt;This paper analyzes the capability of neural autoregressive language models to encode long-range contextual information, demonstrating that while models may achieve similar perplexity scores, their performance on downstream tasks can vary significantly based on their representation of long-range contexts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Multi-round jailbreak attack on large language models</title><link>https://arxiv.org/abs/2410.11533</link><description>https://arxiv.org/abs/2410.11533&lt;br /&gt;This paper investigates how contextualized representations in neural language models capture long-range context, revealing that different model architectures and training configurations can significantly influence the model's ability to encode complex sequences and long-range dependencies.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability</title><link>https://arxiv.org/abs/2410.11786</link><description>https://arxiv.org/abs/2410.11786&lt;br /&gt;This paper analyzes how contextual representations in neural autoregressive language models capture long-range contexts, revealing significant variations in downstream task performance based on the models' ability to contextualize complex sequences.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>How much do contextualized representations encode long-range context?</title><link>https://arxiv.org/abs/2410.12292</link><description>https://arxiv.org/abs/2410.12292&lt;br /&gt;This paper investigates how contextual representations in neural autoregressive language models encode long-range contexts, revealing that different architectures exhibit varying capacities to handle high-complexity sequences, which influences their performance on downstream tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying Real-World Claims</title><link>https://arxiv.org/abs/2410.12377</link><description>https://arxiv.org/abs/2410.12377&lt;br /&gt;RACCooN is a versatile instructional video editing framework that utilizes a two-stage process of Video-to-Paragraph and Paragraph-to-Video to automatically generate narratives and allow users to edit videos through descriptive prompts, enhancing flexibility and reducing the need for labor-intensive input.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce</title><link>https://arxiv.org/abs/2410.12691</link><description>https://arxiv.org/abs/2410.12691&lt;br /&gt;RACCooN is a versatile video editing framework that utilizes an instructional pipeline to automatically describe video scenes and allow users to modify videos through generated narratives, significantly enhancing the flexibility and ease of editing personal or raw video content.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>In-context KV-Cache Eviction for LLMs via Attention-Gate</title><link>https://arxiv.org/abs/2410.12876</link><description>https://arxiv.org/abs/2410.12876&lt;br /&gt;RACCooN is a versatile instructional video editing framework that enables users to edit videos by first generating well-structured natural language descriptions of scenes and then allowing modifications based on user-defined changes, enhancing flexibility in video content manipulation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>PromptExp: Multi-granularity Prompt Explanation of Large Language Models</title><link>https://arxiv.org/abs/2410.13073</link><description>https://arxiv.org/abs/2410.13073&lt;br /&gt;RACCooN is a versatile instructional video editing framework that automatically generates detailed narratives from input videos, allowing users to modify video content efficiently through a video-to-paragraph-to-video pipeline.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks</title><link>https://arxiv.org/abs/2410.13649</link><description>https://arxiv.org/abs/2410.13649&lt;br /&gt;RACCooN is a versatile video editing framework that leverages a two-stage process to automatically generate natural language descriptions from video content and then allows users to edit videos based on these descriptions, enhancing flexibility and precision in video modifications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Unconstrained Model Merging for Enhanced LLM Reasoning</title><link>https://arxiv.org/abs/2410.13699</link><description>https://arxiv.org/abs/2410.13699&lt;br /&gt;RACCooN is a versatile video editing framework that auto-generates narratives to simplify the editing process by converting videos into structured natural language descriptions, allowing users to modify content through a unified pipeline.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors</title><link>https://arxiv.org/abs/2410.13776</link><description>https://arxiv.org/abs/2410.13776&lt;br /&gt;RACCooN is a versatile instructional video editing framework that utilizes a two-stage process to automatically generate structured natural language descriptions of video content, allowing users to refine these descriptions for various modifications to the input video.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Paths-over-Graph: Knowledge Graph Empowered Large Language Model Reasoning</title><link>https://arxiv.org/abs/2410.14211</link><description>https://arxiv.org/abs/2410.14211&lt;br /&gt;RACCooN is a versatile instructional video editing framework that utilizes a two-stage pipeline to automatically generate narrations for videos and enable modifications based on user-customized texts, thus enhancing user interaction while simplifying video editing processes.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Institutional Grammar 2.0 Codebook</title><link>https://arxiv.org/abs/2008.08937</link><description>https://arxiv.org/abs/2008.08937&lt;br /&gt;RACCooN is a versatile instructional video editing framework that utilizes a two-stage process of automatically generating natural language descriptions from videos and then allowing users to refine these descriptions to guide modifications in the video, enhancing video editing capabilities without requiring labor-intensive textual prompts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Enhancing Robustness of AI Offensive Code Generators via Data Augmentation</title><link>https://arxiv.org/abs/2306.05079</link><description>https://arxiv.org/abs/2306.05079&lt;br /&gt;RACCooN is a versatile framework for instructional video editing that automates the generation of natural language descriptions from videos and allows users to modify videos based on these descriptions through a two-stage process of Video-to-Paragraph and Paragraph-to-Video.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Reverse Stable Diffusion: What prompt was used to generate this image?</title><link>https://arxiv.org/abs/2308.01472</link><description>https://arxiv.org/abs/2308.01472&lt;br /&gt;RACCooN is a versatile instructional video editing framework that automatically generates narratives to facilitate video editing by converting videos into structured descriptions and allowing users to modify the content through a unified pipeline.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Tandem Transformers for Inference Efficient LLMs</title><link>https://arxiv.org/abs/2402.08644</link><description>https://arxiv.org/abs/2402.08644&lt;br /&gt;RACCooN is a versatile instructional video editing framework that supports multiple editing capabilities through a unified pipeline consisting of video-to-paragraph and paragraph-to-video stages, enabling users to generate natural language descriptions of video scenes and modify videos based on these descriptions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines</title><link>https://arxiv.org/abs/2403.05846</link><description>https://arxiv.org/abs/2403.05846&lt;br /&gt;RACCooN is a versatile video-to-paragraph-to-video generative framework that automates video editing by generating natural language descriptions of video scenes and enabling users to refine these descriptions for modifications such as removal, addition, and alteration, enhancing flexibility and usability in video editing tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TraveLER: A Modular Multi-LMM Agent Framework for Video Question-Answering</title><link>https://arxiv.org/abs/2404.01476</link><description>https://arxiv.org/abs/2404.01476&lt;br /&gt;RACCooN is a versatile video editing framework that utilizes a two-stage process to automatically generate structured narratives from videos and enables users to refine these descriptions for various editing modifications, significantly improving the flexibility and ease of video content editing.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding</title><link>https://arxiv.org/abs/2404.07989</link><description>https://arxiv.org/abs/2404.07989&lt;br /&gt;RACCooN is a versatile instructional video editing framework that allows users to generate structured narratives from video content and edit videos through a unified video-to-paragraph-to-video workflow, enhancing flexibility and user adaptability in video editing.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Stepwise Alignment for Constrained Language Model Policy Optimization</title><link>https://arxiv.org/abs/2404.11049</link><description>https://arxiv.org/abs/2404.11049&lt;br /&gt;RACCooN is a user-friendly instructional video editing framework that automates the process of generating natural language descriptions for videos, enabling versatile modifications through a unified pipeline that includes video-to-paragraph and paragraph-to-video stages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments</title><link>https://arxiv.org/abs/2405.07960</link><description>https://arxiv.org/abs/2405.07960&lt;br /&gt;RACCooN is a versatile instructional video editing framework that streamlines the process of video editing by automatically generating textual narratives from videos, allowing for user-guided modifications and enhancements through a unified video-to-paragraph-to-video pipeline.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Du-IN: Discrete units-guided mask modeling for decoding speech from Intracranial Neural signals</title><link>https://arxiv.org/abs/2405.11459</link><description>https://arxiv.org/abs/2405.11459&lt;br /&gt;RACCooN is a versatile framework for video editing that uses a two-stage process—Video-to-Paragraph (V2P) for auto-generating natural language descriptions of videos and Paragraph-to-Video (P2V) for refining these descriptions to guide video modifications, thereby simplifying video content editing without requiring labor-intensive user input.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>RACCooN: A Versatile Instructional Video Editing Framework with Auto-Generated Narratives</title><link>https://arxiv.org/abs/2405.18406</link><description>https://arxiv.org/abs/2405.18406&lt;br /&gt;RACCooN is a versatile instructional video editing framework that automates video-to-paragraph generation and allows users to refine narratives for various video editing modifications, enhancing flexibility in adapting personal videos to user specifications.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision Models For Video Captioning and Summarization</title><link>https://arxiv.org/abs/2405.20648</link><description>https://arxiv.org/abs/2405.20648&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate attacker systems against voice anonymization, with participants training automatic speaker verification systems and measuring performance using equal error rate (EER) metrics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Verbalized Machine Learning: Revisiting Machine Learning with Language Models</title><link>https://arxiv.org/abs/2406.04344</link><description>https://arxiv.org/abs/2406.04344&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to establish a competitive evaluation for developing attacker systems against voice anonymization technologies, providing datasets and a baseline for participants to gauge their systems' effectiveness based on equal error rates.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient</title><link>https://arxiv.org/abs/2406.10576</link><description>https://arxiv.org/abs/2406.10576&lt;br /&gt;The First VoicePrivacy Attacker Challenge focuses on developing and evaluating attacker systems against voice anonymization, providing datasets and a baseline for participants to create automatic speaker verification systems to assess their effectiveness against anonymization methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Exploring the Zero-Shot Capabilities of LLMs Handling Multiple Problems at once</title><link>https://arxiv.org/abs/2406.10786</link><description>https://arxiv.org/abs/2406.10786&lt;br /&gt;The First VoicePrivacy Attacker Challenge is an initiative aimed at developing systems to evaluate the effectiveness of voice anonymization techniques by assessing attacker systems through automatic speaker verification against various anonymization systems.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards for Better Well-Being</title><link>https://arxiv.org/abs/2406.13791</link><description>https://arxiv.org/abs/2406.13791&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate systems that attack voice anonymization techniques by utilizing automatic speaker verification systems, with a focus on assessing their effectiveness against various anonymization systems.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TAGLAS: An atlas of text-attributed graph datasets in the era of large graph and language models</title><link>https://arxiv.org/abs/2406.14683</link><description>https://arxiv.org/abs/2406.14683&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate attacker systems against voice anonymization methods, providing training datasets and a baseline system for participants to enhance automatic speaker verification systems.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DaLPSR: Leverage Degradation-Aligned Language Prompt for Real-World Image Super-Resolution</title><link>https://arxiv.org/abs/2406.16477</link><description>https://arxiv.org/abs/2406.16477&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to evaluate systems designed to break voice anonymization techniques by developing automatic speaker verification systems and assessing their performance against a set of anonymization systems using a specified equal error rate metric.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Retrieval-Enhanced Machine Learning: Synthesis and Opportunities</title><link>https://arxiv.org/abs/2407.12982</link><description>https://arxiv.org/abs/2407.12982&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate automatic speaker verification systems that can assess the effectiveness of voice anonymization methods, with a focus on improving privacy and security in voice data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks</title><link>https://arxiv.org/abs/2408.03615</link><description>https://arxiv.org/abs/2408.03615&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop evaluation metrics and attacker systems for voice anonymization protections, culminating in an event at ICASSP 2025 where participants will showcase their systems against various anonymization methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LongVILA: Scaling Long-Context Visual Language Models for Long Videos</title><link>https://arxiv.org/abs/2408.10188</link><description>https://arxiv.org/abs/2408.10188&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate attacker systems against voice anonymization as part of the VoicePrivacy initiative, providing datasets and a baseline system for participants to test their models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities</title><link>https://arxiv.org/abs/2408.13296</link><description>https://arxiv.org/abs/2408.13296&lt;br /&gt;The First VoicePrivacy Attacker Challenge is organized to develop and evaluate systems that attack voice anonymization techniques, providing a framework for participants to test their systems against various anonymization methods and evaluate their performance using automatic speaker verification metrics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Exploring the Potential of Large Language Models for Heterophilic Graphs</title><link>https://arxiv.org/abs/2408.14134</link><description>https://arxiv.org/abs/2408.14134&lt;br /&gt;The First VoicePrivacy Attacker Challenge focuses on developing and evaluating attacker systems against voice anonymization, providing datasets and a baseline attacker system for participants to enhance their automatic speaker verification systems.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Planning In Natural Language Improves LLM Search For Code Generation</title><link>https://arxiv.org/abs/2409.03733</link><description>https://arxiv.org/abs/2409.03733&lt;br /&gt;The First VoicePrivacy Attacker Challenge is an initiative aimed at developing automatic speaker verification systems to challenge voice anonymization methods, with participants evaluated based on their systems' performance against provided anonymization systems using specified datasets and metrics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CSKV: Training-Efficient Channel Shrinking for KV Cache in Long-Context Scenarios</title><link>https://arxiv.org/abs/2409.10593</link><description>https://arxiv.org/abs/2409.10593&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to evaluate systems designed to attack voice anonymization methods by comparing attacker systems against submissions from the VoicePrivacy 2024 Challenge, utilizing provided datasets and a baseline system to assess performance based on equal error rate (EER).</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A New Perspective on ADHD Research: Knowledge Graph Construction with LLMs and Network Based Insights</title><link>https://arxiv.org/abs/2409.12853</link><description>https://arxiv.org/abs/2409.12853&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate systems that attack voice anonymization techniques, assessing their effectiveness against anonymization systems in a competitive format supported by ICASSP 2025.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching</title><link>https://arxiv.org/abs/2409.14038</link><description>https://arxiv.org/abs/2409.14038&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate attacker systems against voice anonymization using automatic speaker verification methodologies, providing necessary datasets and a baseline system for participants to refine their approaches.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Show and Guide: Instructional-Plan Grounded Vision and Language Model</title><link>https://arxiv.org/abs/2409.19074</link><description>https://arxiv.org/abs/2409.19074&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate attacker systems against voice anonymization techniques, providing datasets and baseline systems for participants to improve upon and compete in measuring equal error rates during ICASSP 2025.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>From Text to Multimodality: Exploring the Evolution and Impact of Large Language Models in Medical Practice</title><link>https://arxiv.org/abs/2410.01812</link><description>https://arxiv.org/abs/2410.01812&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate automatic speaker verification systems against voice anonymization techniques, providing datasets and a baseline for participants to create effective attack systems which will be evaluated based on equal error rate.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DEPT: Decoupled Embeddings for Pre-training Language Models</title><link>https://arxiv.org/abs/2410.05021</link><description>https://arxiv.org/abs/2410.05021&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate systems that can effectively attack voice anonymization methods, with participants creating automatic speaker verification systems to assess their performance against existing anonymization technologies.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>The First VoicePrivacy Attacker Challenge Evaluation Plan</title><link>https://arxiv.org/abs/2410.07428</link><description>https://arxiv.org/abs/2410.07428&lt;br /&gt;The First VoicePrivacy Attacker Challenge aims to develop and evaluate automatic speaker verification systems against various voice anonymization methods, providing datasets and metrics for participants to assess their effectiveness.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SPORTU: A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models</title><link>https://arxiv.org/abs/2410.08474</link><description>https://arxiv.org/abs/2410.08474&lt;br /&gt;MathGAP is a framework for evaluating the generalization ability of large language models (LLMs) on complex arithmetic proofs, revealing that most models struggle significantly with deeper and more intricate proof structures despite the use of in-context learning.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective</title><link>https://arxiv.org/abs/2410.08985</link><description>https://arxiv.org/abs/2410.08985&lt;br /&gt;MathGAP is a framework introduced to evaluate Large Language Models (LLMs) on arithmetic problems with complex proofs, addressing issues of contamination in evaluation data and the arbitrary complexity of proof structures by generating systematic test problems.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>$\alpha$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs</title><link>https://arxiv.org/abs/2410.10148</link><description>https://arxiv.org/abs/2410.10148&lt;br /&gt;MathGAP is a framework designed for evaluating Large Language Models (LLMs) on arithmetic problems with arbitrarily complex proofs, revealing that most models exhibit decreased performance on deeper and wider proof structures, highlighting challenges in generalization.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>FLARE: Faithful Logic-Aided Reasoning and Exploration</title><link>https://arxiv.org/abs/2410.11900</link><description>https://arxiv.org/abs/2410.11900&lt;br /&gt;MathGAP introduces a framework for evaluating large language models (LLMs) on arithmetic problems with complex proofs, revealing that LLM performance significantly declines as proof complexity increases, particularly in nonlinear structures while also challenging existing evaluation methods due to contaminated data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting</title><link>https://arxiv.org/abs/2410.12284</link><description>https://arxiv.org/abs/2410.12284&lt;br /&gt;MathGAP is a new evaluation framework designed to assess the generalization capabilities of Large Language Models (LLMs) on arithmetic problems with arbitrarily complex proofs, revealing significant drops in performance as proof complexity increases.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Chain of Ideas: Revolutionizing Research in Novel Idea Development with LLM Agents</title><link>https://arxiv.org/abs/2410.13185</link><description>https://arxiv.org/abs/2410.13185&lt;br /&gt;MathGAP is a novel evaluation framework designed to assess how well large language models (LLMs) generalize to arithmetic problems with arbitrarily complex proofs, revealing a significant performance decrease as proof complexity increases.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs</title><link>https://arxiv.org/abs/2410.13502</link><description>https://arxiv.org/abs/2410.13502&lt;br /&gt;MathGAP is a framework designed to evaluate large language models' generalization capabilities on problems involving arbitrarily complex arithmetic proofs, revealing significant performance drops with increasing proof complexity and challenging nonlinear structures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Ichigo: Mixed-Modal Early-Fusion Realtime Voice Assistant</title><link>https://arxiv.org/abs/2410.15316</link><description>https://arxiv.org/abs/2410.15316&lt;br /&gt;The paper investigates the impact of scaling inference compute in large language models (LLMs) through repeated sampling on problem-solving coverage, revealing that a baseline approach based on answer prevalence can outperform repeated sampling in certain contexts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Neural Search Space in Gboard Decoder</title><link>https://arxiv.org/abs/2410.15575</link><description>https://arxiv.org/abs/2410.15575&lt;br /&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in the field of chemistry, specifically their ability to be exploited for harmful instructions via techniques such as SMILES-prompting, which can bypass current safety mechanisms, highlighting the need for improved safety protocols.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BrainTransformers: SNN-LLM</title><link>https://arxiv.org/abs/2410.14687</link><description>https://arxiv.org/abs/2410.14687&lt;br /&gt;ChitroJera is a large-scale Visual Question Answering dataset specifically designed for the Bangla language, featuring over 15,000 culturally relevant samples to enhance the performance of multimodal models and address the gap in low-resource VQA datasets for Bangla.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Polymath: A Challenging Multi-modal Mathematical Reasoning Benchmark</title><link>https://arxiv.org/abs/2410.14702</link><description>https://arxiv.org/abs/2410.14702&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering (VQA) dataset for Bangla that contains over 15k samples and aims to improve the performance of various models in addressing culturally relevant VQA tasks in this low-resource language.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>QuAILoRA: Quantization-Aware Initialization for LoRA</title><link>https://arxiv.org/abs/2410.14713</link><description>https://arxiv.org/abs/2410.14713&lt;br /&gt;ChitroJera is a novel Bangla Visual Question Answering (VQA) dataset comprising over 15,000 locally relevant samples designed to improve the performance of models in the VQA domain for the Bangla language, addressing existing dataset limitations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Rethinking Token Reduction for State Space Models</title><link>https://arxiv.org/abs/2410.14725</link><description>https://arxiv.org/abs/2410.14725&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering (VQA) dataset for the Bangla language that addresses the lack of culturally relevant resources by providing over 15,000 samples from diverse local sources, enabling better performance assessment of various models including dual-encoder and large language models in VQA tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Tokens on Demand: Token Condensation as Training-free Test-time Adaptation</title><link>https://arxiv.org/abs/2410.14729</link><description>https://arxiv.org/abs/2410.14729&lt;br /&gt;ChitroJera is a newly introduced Bangla Visual Question Answering dataset comprising over 15k samples, aiming to enhance model performance by providing regionally relevant data and addressing the lack of cultural context in existing low-resource datasets.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection</title><link>https://arxiv.org/abs/2410.14731</link><description>https://arxiv.org/abs/2410.14731&lt;br /&gt;ChitroJera is a large-scale Visual Question Answering dataset for Bangla, consisting of over 15,000 samples that address the lack of culturally relevant resources, thereby enhancing the performance of multimodal models and large language models in this language.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Knowledge Graph Embeddings: A Comprehensive Survey on Capturing Relation Properties</title><link>https://arxiv.org/abs/2410.14733</link><description>https://arxiv.org/abs/2410.14733&lt;br /&gt;ChitroJera is a large-scale Visual Question Answering (VQA) dataset designed for the Bangla language, addressing the lack of culturally relevant and comprehensive datasets in this domain and showcasing the superiority of dual-encoder models and large language models in performance evaluation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries</title><link>https://arxiv.org/abs/2410.14748</link><description>https://arxiv.org/abs/2410.14748&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering dataset for the Bangla language, consisting of over 15,000 samples derived from diverse local sources, aimed at improving the performance of models in culturally relevant contexts compared to existing low-resource datasets.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TimeSeriesExam: A time series understanding exam</title><link>https://arxiv.org/abs/2410.14752</link><description>https://arxiv.org/abs/2410.14752&lt;br /&gt;ChitroJera introduces a large-scale, culturally relevant Visual Question Answering dataset for the Bangla language, designed to improve performance in multimodal models and evaluation of text and image encoders.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Collaboratively adding new knowledge to an LLM</title><link>https://arxiv.org/abs/2410.14753</link><description>https://arxiv.org/abs/2410.14753&lt;br /&gt;ChitroJera is a large-scale Visual Question Answering dataset for Bangla, consisting of over 15k samples, designed to provide culturally relevant data for improving model performance in the low-resource VQA space of the Bangla language.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>What's New in My Data? Novelty Exploration via Contrastive Generation</title><link>https://arxiv.org/abs/2410.14765</link><description>https://arxiv.org/abs/2410.14765&lt;br /&gt;ChitroJera is a new large-scale Visual Question Answering (VQA) dataset specifically designed for the Bangla language, consisting of over 15,000 culturally relevant samples aimed at improving the performance of multimodal models in VQA tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Making LLMs Vulnerable to Prompt Injection via Poisoning Alignment</title><link>https://arxiv.org/abs/2410.14827</link><description>https://arxiv.org/abs/2410.14827&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering (VQA) dataset for the Bangla language, comprising over 15,000 samples specifically designed to enhance cultural relevance and support the development of Vision-Language tasks in Bangla by evaluating various multimodal models, including pre-trained dual-encoders and large language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Class-RAG: Content Moderation with Retrieval Augmented Generation</title><link>https://arxiv.org/abs/2410.14881</link><description>https://arxiv.org/abs/2410.14881&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering (VQA) dataset for the Bangla language, comprising over 15,000 samples and designed to enhance cultural relevance and support the performance of text and image encoders, as well as multimodal models in VQA tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Hybrid Defense Strategy for Boosting Adversarial Robustness in Vision-Language Models</title><link>https://arxiv.org/abs/2410.14911</link><description>https://arxiv.org/abs/2410.14911&lt;br /&gt;ChitroJera introduces a large-scale Visual Question Answering dataset specifically for the Bangla language, addressing the lack of culturally relevant resources and demonstrating improved performance with dual-encoder models and large language models for VQA tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Baichuan Alignment Technical Report</title><link>https://arxiv.org/abs/2410.14940</link><description>https://arxiv.org/abs/2410.14940&lt;br /&gt;ChitroJera is a new large-scale Visual Question Answering dataset tailored for the Bangla language, comprising over 15,000 samples from diverse local sources and designed to address cultural relevance in VQA while evaluating various models, including novel dual-encoders and large language models with prompt-based techniques.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation</title><link>https://arxiv.org/abs/2410.14971</link><description>https://arxiv.org/abs/2410.14971&lt;br /&gt;ChitroJera is a newly introduced visual question answering dataset tailored for the Bangla language, addressing the lack of culturally relevant and adequately benchmarked datasets in this area by comprising over 15,000 diverse samples and enabling improved performance of both traditional models and large language models through prompt-based techniques.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Do Large Language Models Truly Grasp Mathematics? An Empirical Exploration</title><link>https://arxiv.org/abs/2410.14979</link><description>https://arxiv.org/abs/2410.14979&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering dataset tailored for the Bangla language, comprising over 15,000 samples from culturally relevant sources, aimed at improving performance in VQA tasks among models that traditionally struggle with low-resource languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ChitroJera: A Regionally Relevant Visual Question Answering Dataset for Bangla</title><link>https://arxiv.org/abs/2410.14991</link><description>https://arxiv.org/abs/2410.14991&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering (VQA) dataset for Bangla, designed to address the lack of culturally relevant benchmarks and improve the performance of VQA models in the region by providing over 15,000 samples collected from diverse local sources.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Spirit LM: Interleaved Spoken and Written Language Model</title><link>https://arxiv.org/abs/2402.05755</link><description>https://arxiv.org/abs/2402.05755&lt;br /&gt;This paper presents the Counterfactual Augmented Calibration Network (FACTUAL), a novel approach developed to mitigate biases in stance detection performed by Large Language Models (LLMs), enhancing their performance by addressing biases from sentiment-stance correlations and improving generalizability through counterfactual augmented data.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SouLLMate: An Application Enhancing Diverse Mental Health Support with Adaptive LLMs, Prompt Engineering, and RAG Techniques</title><link>https://arxiv.org/abs/2410.16322</link><description>https://arxiv.org/abs/2410.16322&lt;br /&gt;This paper introduces Bayesian scaling laws for in-context learning (ICL) in language models, demonstrating that ICL approximates a Bayesian learner, thereby providing interpretable scaling laws that can explain the correlation between the number of in-context examples and prediction accuracy, and applying these insights to analyze safety alignment in language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>This Candidate is [MASK]. Letters of Reference and Job Market Outcomes using LLMs</title><link>https://arxiv.org/abs/2410.16325</link><description>https://arxiv.org/abs/2410.16325&lt;br /&gt;This paper introduces Bayesian scaling laws for in-context learning in language models, demonstrating that ICL approximates a Bayesian learner and provides insights into model performance and safety alignment when manipulating existing capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>KatzBot: Revolutionizing Academic Chatbot for Enhanced Communication</title><link>https://arxiv.org/abs/2410.16385</link><description>https://arxiv.org/abs/2410.16385&lt;br /&gt;This paper introduces Bayesian scaling laws for in-context learning (ICL) in language models, demonstrating how ICL approximates a Bayesian learner and providing insights into model behavior and safety alignment through empirical experiments.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLM-based Optimization of Compound AI Systems: A Survey</title><link>https://arxiv.org/abs/2410.16392</link><description>https://arxiv.org/abs/2410.16392&lt;br /&gt;This paper introduces Bayesian scaling laws for in-context learning (ICL) in language models, establishing that ICL approximates a Bayesian learner, and demonstrates that these laws can predict and improve model performance and safety alignment in varying scenarios.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>VipAct: Visual-Perception Enhancement via Specialized VLM Agent Collaboration and Tool-use</title><link>https://arxiv.org/abs/2410.16400</link><description>https://arxiv.org/abs/2410.16400&lt;br /&gt;This paper explores in-context learning (ICL) as an approximation of a Bayesian learner, developing novel Bayesian scaling laws that predict the correlation between the number of in-context examples and model accuracy, while showcasing its implications for safety alignment in language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Enhancing Multimodal Affective Analysis with Learned Live Comment Features</title><link>https://arxiv.org/abs/2410.16407</link><description>https://arxiv.org/abs/2410.16407&lt;br /&gt;This paper explores Bayesian scaling laws for in-context learning in language models, demonstrating that ICL approximates a Bayesian learner and providing interpretable insights into learning efficiency and safety alignment by analyzing its effects on suppressed model behaviors.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Improving Neuron-level Interpretability with White-box Language Models</title><link>https://arxiv.org/abs/2410.16443</link><description>https://arxiv.org/abs/2410.16443&lt;br /&gt;This paper presents Bayesian scaling laws for in-context learning (ICL) in language models, demonstrating how ICL approximates a Bayesian learner and providing insights into model safety alignment through controlled experiments and synthetic datasets.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the U.S</title><link>https://arxiv.org/abs/2410.16451</link><description>https://arxiv.org/abs/2410.16451&lt;br /&gt;This paper introduces Bayesian scaling laws for in-context learning in language models, demonstrating how in-context learning approximates a Bayesian learner and showing that these scaling laws can provide insights into performance and safety alignment in large language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Does your LLM truly unlearn? An embarrassingly simple approach to recover unlearned knowledge</title><link>https://arxiv.org/abs/2410.16454</link><description>https://arxiv.org/abs/2410.16454&lt;br /&gt;This paper presents Bayesian scaling laws for in-context learning (ICL) by demonstrating that ICL approximates a Bayesian learner, providing novel insights into model accuracy, learning efficiency, and safety alignment through controlled experiments.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>To the Globe (TTG): Towards Language-Driven Guaranteed Travel Planning</title><link>https://arxiv.org/abs/2410.16456</link><description>https://arxiv.org/abs/2410.16456&lt;br /&gt;The paper introduces Bayesian scaling laws for in-context learning (ICL) in language models, demonstrating that ICL behaves like a Bayesian learner and providing new insights into how the number of in-context examples affects model accuracy, with implications for safety alignment in real-world scenarios.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Comparative Study of Multilingual Idioms and Similes in Large Language Models</title><link>https://arxiv.org/abs/2410.16461</link><description>https://arxiv.org/abs/2410.16461&lt;br /&gt;This paper investigates in-context learning (ICL) in language models, establishing Bayesian scaling laws that correlate the number of in-context examples with model accuracy, while also providing insights into safety alignment and the dynamics of suppressed model capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Beyond Browsing: API-Based Web Agents</title><link>https://arxiv.org/abs/2410.16464</link><description>https://arxiv.org/abs/2410.16464&lt;br /&gt;This paper introduces Bayesian scaling laws for in-context learning (ICL) in language models, explaining how ICL approximates a Bayesian learner, and provides novel scaling laws that enhance accuracy and interpretability while also investigating the implications for safety alignment in real-world models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DocEdit-v2: Document Structure Editing Via Multimodal LLM Grounding</title><link>https://arxiv.org/abs/2410.16472</link><description>https://arxiv.org/abs/2410.16472&lt;br /&gt;This paper presents novel Bayesian scaling laws for in-context learning (ICL) in language models, demonstrating that ICL approximates a Bayesian learner and providing insights into safety alignment through experiments that show how ICL can reintroduce suppressed model capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Multi-head Sequence Tagging Model for Grammatical Error Correction</title><link>https://arxiv.org/abs/2410.16473</link><description>https://arxiv.org/abs/2410.16473&lt;br /&gt;This paper presents Bayesian scaling laws for in-context learning (ICL) in language models, demonstrating how ICL can approximate a Bayesian learner and providing insights into its accuracy and application for safety alignment in real-world models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data</title><link>https://arxiv.org/abs/2410.16491</link><description>https://arxiv.org/abs/2410.16491&lt;br /&gt;This paper presents Bayesian scaling laws for in-context learning in language models, explaining the correlation between the number of in-context examples and model accuracy while exploring the implications for safety alignment and predicting re-emergence of suppressed model behaviors.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Natural Language Processing for Human Resources: A Survey</title><link>https://arxiv.org/abs/2410.16498</link><description>https://arxiv.org/abs/2410.16498&lt;br /&gt;This paper develops Bayesian scaling laws for in-context learning (ICL) in language models, demonstrating how ICL approximates a Bayesian learner and improves model accuracy while providing insights into safety alignment and model behavior suppression.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Rulebreakers Challenge: Revealing a Blind Spot in Large Language Models' Reasoning with Formal Logic</title><link>https://arxiv.org/abs/2410.16502</link><description>https://arxiv.org/abs/2410.16502&lt;br /&gt;This paper introduces Bayesian scaling laws for in-context learning (ICL), demonstrating how ICL approximates a Bayesian learner and providing insights into the correlation between the number of in-context examples and model accuracy, ultimately enhancing understanding of safety alignment in language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Learning from others' mistakes: Finetuning machine translation models with span-level error annotations</title><link>https://arxiv.org/abs/2410.16509</link><description>https://arxiv.org/abs/2410.16509&lt;br /&gt;This paper presents Bayesian scaling laws for in-context learning (ICL) in language models, demonstrating that ICL acts similarly to a Bayesian learner, and reveals insights into model performance and safety alignment through novel analytical methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context</title><link>https://arxiv.org/abs/2410.16520</link><description>https://arxiv.org/abs/2410.16520&lt;br /&gt;This paper introduces Bayesian scaling laws that explain the correlation between the number of in-context examples and the accuracy of language models' predictions, offering insights into in-context learning and its implications for model safety alignment based on controlled experiments.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration</title><link>https://arxiv.org/abs/2410.16540</link><description>https://arxiv.org/abs/2410.16540&lt;br /&gt;This paper analyzes and evaluates the effectiveness of various correlation measures used in natural language generation (NLG) meta-evaluation, demonstrating how different methods impact evaluation results and identifying the optimal approach for assessing evaluation metrics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Dynamic Adaptive Rank Space Exploration for Efficient Sentiment Analysis with Large Language Models</title><link>https://arxiv.org/abs/2410.16589</link><description>https://arxiv.org/abs/2410.16589&lt;br /&gt;This paper analyzes and evaluates various correlation measures used in natural language generation (NLG) meta-evaluation, demonstrating how different measures impact the results and identifying the most effective measure for assessing evaluation metrics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Distill-SynthKG: Distilling Knowledge Graph Synthesis Workflow for Improved Coverage and Efficiency</title><link>https://arxiv.org/abs/2410.16597</link><description>https://arxiv.org/abs/2410.16597&lt;br /&gt;This paper analyzes the impact of various correlation measures on the meta-evaluation of Natural Language Generation (NLG) metrics, identifying that different measures significantly affect the evaluation results and proposing that Pearson correlation with global grouping performs best overall.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Graph-Structured Trajectory Extraction from Travelogues</title><link>https://arxiv.org/abs/2410.16633</link><description>https://arxiv.org/abs/2410.16633&lt;br /&gt;This paper analyzes and evaluates the impact of different correlation measures in NLG meta-evaluation, revealing that various methods lead to differing results and proposing that the best performance is achieved using global grouping and Pearson correlation measures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Statistical Analysis of LLMs' Self-Evaluation Using Proverbs</title><link>https://arxiv.org/abs/2410.16640</link><description>https://arxiv.org/abs/2410.16640&lt;br /&gt;This paper analyzes 12 common correlation measures in the context of natural language generation (NLG) meta-evaluation, revealing how different measures impact evaluation results, and proposes that the measure using global grouping and Pearson correlation offers the best overall performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Chatting with Bots: AI, Speech Acts, and the Edge of Assertion</title><link>https://arxiv.org/abs/2410.16645</link><description>https://arxiv.org/abs/2410.16645&lt;br /&gt;This paper analyzes and evaluates 12 common correlation measures in NLG meta-evaluation, revealing how different measures impact evaluation results and proposing an optimal approach based on global grouping and Pearson correlation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Adsorb-Agent: Autonomous Identification of Stable Adsorption Configurations via Large Language Model Agent</title><link>https://arxiv.org/abs/2410.16658</link><description>https://arxiv.org/abs/2410.16658&lt;br /&gt;This paper analyzes various correlation measures used in natural language generation (NLG) meta-evaluation to assess their impact on measuring the agreement between automatic and human evaluation metrics, ultimately identifying the most effective approaches.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>RKadiyala at SemEval-2024 Task 8: Black-Box Word-Level Text Boundary Detection in Partially Machine Generated Texts</title><link>https://arxiv.org/abs/2410.16659</link><description>https://arxiv.org/abs/2410.16659&lt;br /&gt;This paper analyzes various correlation measures used in the meta-evaluation of Natural Language Generation (NLG) metrics, demonstrating the impact of these measures on evaluation results and identifying the optimal correlation method for accurate meta-evaluation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SafetyAnalyst: Interpretable, transparent, and steerable LLM safety moderation</title><link>https://arxiv.org/abs/2410.16665</link><description>https://arxiv.org/abs/2410.16665&lt;br /&gt;This paper analyzes and evaluates 12 correlation measures in natural language generation (NLG) meta-evaluation, finding that the choice of measure significantly impacts the results and proposing that a measure using global grouping and Pearson correlation performs best overall.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Methods of improving LLM training stability</title><link>https://arxiv.org/abs/2410.16682</link><description>https://arxiv.org/abs/2410.16682&lt;br /&gt;This paper analyzes various correlation measures used in the meta-evaluation of natural language generation (NLG) metrics, revealing how different measures affect the evaluation results and proposing an optimal measure for assessing performance consistency and discriminative power.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>PLDR-LLM: Large Language Model from Power Law Decoder Representations</title><link>https://arxiv.org/abs/2410.16703</link><description>https://arxiv.org/abs/2410.16703&lt;br /&gt;This paper analyzes twelve common correlation measures used in natural language generation (NLG) meta-evaluation to reveal their impacts on assessment results and proposes a preferred method for evaluating automatic metrics against human assessments.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Atomic Fact Decomposition Helps Attributed Question Answering</title><link>https://arxiv.org/abs/2410.16708</link><description>https://arxiv.org/abs/2410.16708&lt;br /&gt;This paper analyzes the effectiveness of various correlation measures in natural language generation (NLG) meta-evaluation by examining how different metrics influence the correlation between automatic and human evaluations across multiple datasets, ultimately recommending the use of global grouping with Pearson correlation for optimal results.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Magnetic Preference Optimization: Achieving Last-iterate Convergence for Language Models Alignment</title><link>https://arxiv.org/abs/2410.16714</link><description>https://arxiv.org/abs/2410.16714&lt;br /&gt;This paper analyzes 12 common correlation measures used in natural language generation (NLG) meta-evaluation and reveals how different measures affect meta-evaluation results, proposing that global grouping with Pearson correlation provides the best performance overall.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Forewarned is Forearmed: Leveraging LLMs for Data Synthesis through Failure-Inducing Exploration</title><link>https://arxiv.org/abs/2410.16736</link><description>https://arxiv.org/abs/2410.16736&lt;br /&gt;This paper analyzes the impact of various correlation measures in natural language generation (NLG) meta-evaluation, revealing that different measures significantly affect evaluation results and proposing that a global grouping with Pearson correlation yields the best performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Context-Aware LLM Translation System Using Conversation Summarization and Dialogue History</title><link>https://arxiv.org/abs/2410.16775</link><description>https://arxiv.org/abs/2410.16775&lt;br /&gt;This paper analyzes twelve common correlation measures in Natural Language Generation (NLG) meta-evaluation, revealing their impact on evaluation results and proposing that measures using global grouping and Pearson correlation provide the best overall performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Beyond Retrieval: Generating Narratives in Conversational Recommender Systems</title><link>https://arxiv.org/abs/2410.16780</link><description>https://arxiv.org/abs/2410.16780&lt;br /&gt;This paper analyzes 12 common correlation measures in Natural Language Generation (NLG) meta-evaluation, highlighting how different measures can impact the results and proposing that the measure using global grouping and Pearson correlation performs best overall.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Correct after Answer: Enhancing Multi-Span Question Answering with Post-Processing Method</title><link>https://arxiv.org/abs/2410.16788</link><description>https://arxiv.org/abs/2410.16788&lt;br /&gt;This paper analyzes twelve common correlation measures in natural language generation (NLG) meta-evaluation, demonstrating that different measures significantly affect the evaluation outcomes and identifying the Pearson correlation with global grouping as the most effective approach.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models</title><link>https://arxiv.org/abs/2410.16801</link><description>https://arxiv.org/abs/2410.16801&lt;br /&gt;This paper analyzes 12 correlation measures used in the meta-evaluation of natural language generation (NLG) metrics, revealing their impact on evaluation results and proposing that a global grouping with Pearson correlation achieves the best overall performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Optimizing Chain-of-Thought Reasoning: Tackling Arranging Bottleneck via Plan Augmentation</title><link>https://arxiv.org/abs/2410.16812</link><description>https://arxiv.org/abs/2410.16812&lt;br /&gt;This paper analyzes the impact of different correlation measures on the meta-evaluation of Natural Language Generation (NLG) metrics, revealing that various measures lead to different results in assessing the correlation with human evaluations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Analyzing and Evaluating Correlation Measures in NLG Meta-Evaluation</title><link>https://arxiv.org/abs/2410.16834</link><description>https://arxiv.org/abs/2410.16834&lt;br /&gt;This paper analyzes various correlation measures used in the meta-evaluation of natural language generation (NLG) metrics, identifying their impacts on evaluation results and proposing that a specific method using global grouping and Pearson correlation yields the best overall performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Assessment of Transformer-Based Encoder-Decoder Model for Human-Like Summarization</title><link>https://arxiv.org/abs/2410.16842</link><description>https://arxiv.org/abs/2410.16842&lt;br /&gt;This paper introduces a dual-part embedding approach for learning interchangeable tokens in language models, aiming to achieve an extendable vocabulary that preserves semantics while allowing distinguishability, particularly for formal languages like temporal logics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Trustworthy Alignment of Retrieval-Augmented Large Language Models via Reinforcement Learning</title><link>https://arxiv.org/abs/2410.16843</link><description>https://arxiv.org/abs/2410.16843&lt;br /&gt;This paper introduces a novel method for learning interchangeable token embeddings in language models to create an extendable vocabulary that adheres to the principle of alpha-equivalence, enabling improved generalization when dealing with formal languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ETHIC: Evaluating Large Language Models on Long-Context Tasks with High Information Coverage</title><link>https://arxiv.org/abs/2410.16848</link><description>https://arxiv.org/abs/2410.16848&lt;br /&gt;This paper introduces a novel dual-part embedding approach for learning interchangeable tokens in language models, allowing for an extendable vocabulary and generalization to new tokens while maintaining the principles of alpha-equivalence in formal languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Tracing the Development of the Virtual Particle Concept Using Semantic Change Detection</title><link>https://arxiv.org/abs/2410.16855</link><description>https://arxiv.org/abs/2410.16855&lt;br /&gt;This paper introduces a dual-part embedding approach for learning interchangeable token embeddings in language models, facilitating an extendable vocabulary that retains semantic consistency according to the principle of alpha-equivalence, particularly applied in formal languages like temporal logics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Math Neurosurgery: Isolating Language Models' Math Reasoning Abilities Using Only Forward Passes</title><link>https://arxiv.org/abs/2410.16930</link><description>https://arxiv.org/abs/2410.16930&lt;br /&gt;The paper presents a novel approach for learning interchangeable token embeddings in language models, enabling an extendable vocabulary that can generalize to new tokens while preserving the semantics of interchangeable tokens based on the principle of alpha-equivalence.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Learning Mathematical Rules with Large Language Models</title><link>https://arxiv.org/abs/2410.16973</link><description>https://arxiv.org/abs/2410.16973&lt;br /&gt;This paper presents a novel approach for learning interchangeable token embeddings in language models to create an extendable vocabulary that addresses alpha-equivalence, allowing generalization to new tokens while preserving semantics across distinguishable tokens.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>IPL: Leveraging Multimodal Large Language Models for Intelligent Product Listing</title><link>https://arxiv.org/abs/2410.16977</link><description>https://arxiv.org/abs/2410.16977&lt;br /&gt;This paper presents a dual-part embedding approach for learning interchangeable tokens in language models that allows for an extendable vocabulary and preserves the semantics of bound variables in formal languages, specifically targeting alpha-equivalence.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Exploring Forgetting in Large Language Model Pre-Training</title><link>https://arxiv.org/abs/2410.17018</link><description>https://arxiv.org/abs/2410.17018&lt;br /&gt;The paper presents a method for learning interchangeable token embeddings in language models to develop an extendable vocabulary and handle alpha-equivalence in formal languages by using a dual-part embedding approach.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SG-FSM: A Self-Guiding Zero-Shot Prompting Paradigm for Multi-Hop Question Answering Based on Finite State Machine</title><link>https://arxiv.org/abs/2410.17021</link><description>https://arxiv.org/abs/2410.17021&lt;br /&gt;The paper proposes a dual-part embedding approach to learn interchangeable tokens in language models, facilitating an extendable vocabulary that maintains semantics through alpha-equivalence and demonstrates effectiveness on tasks involving linear temporal logic and token distinguishability.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DIRI: Adversarial Patient Reidentification with Large Language Models for Evaluating Clinical Text Anonymization</title><link>https://arxiv.org/abs/2410.17035</link><description>https://arxiv.org/abs/2410.17035&lt;br /&gt;The paper presents a method for learning interchangeable token embeddings in language models to create an extendable vocabulary that addresses the concept of alpha-equivalence in formal languages, utilizing a dual-part embedding approach to maintain concept consistency while allowing for distinction between tokens.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Arabic Dataset for LLM Safeguard Evaluation</title><link>https://arxiv.org/abs/2410.17040</link><description>https://arxiv.org/abs/2410.17040&lt;br /&gt;This paper presents a dual-part embedding approach for learning interchangeable tokens in language models, enabling an extendable vocabulary that generalizes to new tokens while adhering to the principle of alpha-equivalence, particularly in formal languages like linear temporal logics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Data-driven Coreference-based Ontology Building</title><link>https://arxiv.org/abs/2410.17051</link><description>https://arxiv.org/abs/2410.17051&lt;br /&gt;The paper presents a dual-part embedding approach for learning interchangeable tokens in language models, enabling an extendable vocabulary that respects alpha-equivalence, enhancing generalization for tasks in formal languages like temporal logics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Science Out of Its Ivory Tower: Improving Accessibility with Reinforcement Learning</title><link>https://arxiv.org/abs/2410.17088</link><description>https://arxiv.org/abs/2410.17088&lt;br /&gt;The paper introduces a novel approach for creating interchangeable token embeddings in language models that allows for an extendable vocabulary while preserving semantics through alpha-equivalence, utilizing a dual-part embedding strategy evaluated on tasks related to temporal logic and vocabulary extension.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Team Ryu's Submission to SIGMORPHON 2024 Shared Task on Subword Tokenization</title><link>https://arxiv.org/abs/2410.17094</link><description>https://arxiv.org/abs/2410.17094&lt;br /&gt;The paper introduces a dual-part embedding approach for learning interchangeable token embeddings in language models, enabling an extendable vocabulary that maintains semantic equivalence for bound variables while allowing distinguishability, with promising results in tasks related to linear temporal logic and vocabulary extension.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations</title><link>https://arxiv.org/abs/2410.17099</link><description>https://arxiv.org/abs/2410.17099&lt;br /&gt;This paper presents a novel dual-part embedding method for language models that enables the use of interchangeable tokens to create an extendable vocabulary, effectively addressing the concept of alpha-equivalence in formal languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Enhancing Answer Attribution for Faithful Text Generation with Large Language Models</title><link>https://arxiv.org/abs/2410.17112</link><description>https://arxiv.org/abs/2410.17112&lt;br /&gt;This paper introduces a novel method for learning interchangeable token embeddings in language models to create an extendable vocabulary while preserving the semantics of interchangeable tokens, evaluated through tasks involving linear temporal logic and vocabulary extension.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Exploring RL-based LLM Training for Formal Language Tasks with Programmed Rewards</title><link>https://arxiv.org/abs/2410.17126</link><description>https://arxiv.org/abs/2410.17126&lt;br /&gt;This paper presents a novel method for learning interchangeable token embeddings in language models to create an extendable vocabulary while maintaining the principle of alpha-equivalence in formal languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Aligning Large Language Models via Self-Steering Optimization</title><link>https://arxiv.org/abs/2410.17131</link><description>https://arxiv.org/abs/2410.17131&lt;br /&gt;This paper presents a novel approach for learning interchangeable tokens in language models to create an extendable vocabulary that maintains semantics across renamed variables, utilizing a dual-part embedding method for distinguishability and evaluated on tasks related to linear temporal logic and vocabulary extension.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Can General-Purpose Large Language Models Generalize to English-Thai Machine Translation ?</title><link>https://arxiv.org/abs/2410.17145</link><description>https://arxiv.org/abs/2410.17145&lt;br /&gt;This paper presents a novel approach for learning interchangeable token embeddings in language models to create an extendable vocabulary, addressing the concept of alpha-equivalence, and demonstrating its effectiveness in solving linear temporal logic and vocabulary extension tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Interchangeable Token Embeddings for Extendable Vocabulary and Alpha-Equivalence</title><link>https://arxiv.org/abs/2410.17161</link><description>https://arxiv.org/abs/2410.17161&lt;br /&gt;The paper introduces a dual-part embedding method for learning interchangeable tokens in language models, facilitating an extendable vocabulary that maintains semantic consistency across bound variables, especially in formal languages like temporal logics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Self-calibration for Language Model Quantization and Pruning</title><link>https://arxiv.org/abs/2410.17170</link><description>https://arxiv.org/abs/2410.17170&lt;br /&gt;This study explores how performance pressure influences the reliance on AI advice during decision-making tasks, revealing that higher stakes lead to more appropriate use of AI recommendations and better discounting of incorrect advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>From Attention to Activation: Unravelling the Enigmas of Large Language Models</title><link>https://arxiv.org/abs/2410.17174</link><description>https://arxiv.org/abs/2410.17174&lt;br /&gt;This research demonstrates that increasing performance pressure enhances the appropriate use of AI advice in decision-making tasks, suggesting that humans rely on AI assistance more effectively under higher stakes, regardless of the AI's explanatory presence.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>VoiceBench: Benchmarking LLM-Based Voice Assistants</title><link>https://arxiv.org/abs/2410.17196</link><description>https://arxiv.org/abs/2410.17196&lt;br /&gt;This study explores how performance pressure impacts the reliance on AI advice in decision-making tasks, revealing that higher stakes enhance appropriate use of AI assistance and improve the ability to discount poor AI advice during tasks like fake review detection.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Exploring Possibilities of AI-Powered Legal Assistance in Bangladesh through Large Language Modeling</title><link>https://arxiv.org/abs/2410.17210</link><description>https://arxiv.org/abs/2410.17210&lt;br /&gt;This paper investigates how performance pressure influences the reliance on AI advice during decision-making tasks, demonstrating that higher stakes lead to more appropriate use of AI recommendations despite the presence of incorrect advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MiniPLM: Knowledge Distillation for Pre-Training Language Models</title><link>https://arxiv.org/abs/2410.17215</link><description>https://arxiv.org/abs/2410.17215&lt;br /&gt;This study explores how performance pressure affects the reliance on AI advice in decision-making scenarios, demonstrating that higher stakes lead to more appropriate use of AI recommendations and improved ability to discount incorrect AI advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Context-aware Prompt Tuning: Advancing In-Context Learning with Adversarial Methods</title><link>https://arxiv.org/abs/2410.17222</link><description>https://arxiv.org/abs/2410.17222&lt;br /&gt;This study investigates the influence of performance pressure on the reliance of laypeople on AI advice during decision-making tasks, finding that higher stakes improve the appropriate use of AI assistance and the discounting of incorrect AI advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Dhoroni: Exploring Bengali Climate Change and Environmental Views with a Multi-Perspective News Dataset and Natural Language Processing</title><link>https://arxiv.org/abs/2410.17225</link><description>https://arxiv.org/abs/2410.17225&lt;br /&gt;This paper investigates the impact of performance pressure on how effectively people rely on AI advice for decision making, finding that higher stakes enhance the appropriate use of AI assistance, particularly in tasks involving fake review detection.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fine-Tuning Large Language Models to Appropriately Abstain with Semantic Entropy</title><link>https://arxiv.org/abs/2410.17234</link><description>https://arxiv.org/abs/2410.17234&lt;br /&gt;This paper investigates how performance pressure affects the reliance on AI advice in decision-making tasks, demonstrating that higher stakes lead to more appropriate use of AI assistance in detecting fake reviews, regardless of whether AI explanations are provided.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Large Language Models Empowered Personalized Web Agents</title><link>https://arxiv.org/abs/2410.17236</link><description>https://arxiv.org/abs/2410.17236&lt;br /&gt;This paper explores how performance pressure affects the reliability and effectiveness of AI-assisted decision making, revealing that higher stakes lead to better utilization of AI advice and improved ability to discount poor advice in AI systems.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark for Culture-aware Evaluation</title><link>https://arxiv.org/abs/2410.17250</link><description>https://arxiv.org/abs/2410.17250&lt;br /&gt;This paper explores how performance pressure influences human reliance on AI advice, finding that higher stakes improve the appropriate use of AI assistance and the ability to discount incorrect AI advice during decision-making tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Learning Machines: In Search of a Concept Oriented Language</title><link>https://arxiv.org/abs/2409.01968</link><description>https://arxiv.org/abs/2409.01968&lt;br /&gt;This paper investigates how performance pressure affects human reliance on AI advice during decision-making tasks, demonstrating that higher stakes lead to more appropriate use of AI guidance and better discrimination of incorrect advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>GenAI Assisting Medical Training</title><link>https://arxiv.org/abs/2410.16164</link><description>https://arxiv.org/abs/2410.16164&lt;br /&gt;This paper investigates how performance pressure affects human-AI collaboration in decision making, finding that increased stakes lead to more appropriate reliance on AI advice, particularly in a task involving fake review detection.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Understanding the Effect of Algorithm Transparency of Model Explanations in Text-to-SQL Semantic Parsing</title><link>https://arxiv.org/abs/2410.16283</link><description>https://arxiv.org/abs/2410.16283&lt;br /&gt;This paper investigates how performance pressure affects human-AI decision-making, finding that higher stakes lead users to rely on AI advice more appropriately and better discount incorrect AI guidance in AI-assisted tasks like fake review detection.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Assessing the Performance of Human-Capable LLMs -- Are LLMs Coming for Your Job?</title><link>https://arxiv.org/abs/2410.16285</link><description>https://arxiv.org/abs/2410.16285&lt;br /&gt;This research investigates the impact of performance pressure on human reliance on AI advice in decision-making tasks, revealing that higher stakes lead to more appropriate use of AI suggestions and better discounting of incorrect advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>An evaluation of LLM code generation capabilities through graded exercises</title><link>https://arxiv.org/abs/2410.16292</link><description>https://arxiv.org/abs/2410.16292&lt;br /&gt;This paper examines how performance pressure affects the appropriateness of reliance on AI advice in decision-making tasks, revealing that higher stakes lead to more appropriate usage of AI recommendations and better discounting of incorrect advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Feint and Attack: Attention-Based Strategies for Jailbreaking and Protecting LLMs</title><link>https://arxiv.org/abs/2410.16327</link><description>https://arxiv.org/abs/2410.16327&lt;br /&gt;This study explores how performance pressure affects the reliance on AI advice in decision-making tasks, showing that higher stakes improve the appropriate use of AI recommendations and enhance users' ability to discount poor advice under pressure.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>End-to-End Transformer-based Automatic Speech Recognition for Northern Kurdish: A Pioneering Approach</title><link>https://arxiv.org/abs/2410.16330</link><description>https://arxiv.org/abs/2410.16330&lt;br /&gt;This study investigates how performance pressure affects human reliance on AI advice in decision-making tasks, revealing that higher stakes lead to more appropriate use of AI assistance and better discounting of poor advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Allo-AVA: A Large-Scale Multimodal Conversational AI Dataset for Allocentric Avatar Gesture Animation</title><link>https://arxiv.org/abs/2410.16503</link><description>https://arxiv.org/abs/2410.16503&lt;br /&gt;This paper investigates how performance pressure enhances the use of AI advice in decision-making tasks, revealing that higher stakes lead to more appropriate reliance on AI assistance and better discounting of incorrect advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Large Body Language Models</title><link>https://arxiv.org/abs/2410.16533</link><description>https://arxiv.org/abs/2410.16533&lt;br /&gt;This study investigates how performance pressure influences reliance on AI advice during decision-making tasks, revealing that higher stakes lead to more appropriate use of AI recommendations and better discounting of incorrect advice.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Raising the Stakes: Performance Pressure Improves AI-Assisted Decision Making</title><link>https://arxiv.org/abs/2410.16560</link><description>https://arxiv.org/abs/2410.16560&lt;br /&gt;This paper investigates how performance pressure influences the reliance on AI advice in decision-making tasks, revealing that higher stakes improve the appropriate use of AI assistance and lead to better discounting of incorrect advice in the context of common AI tasks like fake review detection.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ViMGuard: A Novel Multi-Modal System for Video Misinformation Guarding</title><link>https://arxiv.org/abs/2410.16592</link><description>https://arxiv.org/abs/2410.16592&lt;br /&gt;PyramidDrop is a proposed strategy for reducing visual redundancy in large vision-language models (LVLMs), achieving significant efficiency improvements in training and inference while maintaining comparable performance by selectively dropping image tokens based on their importance across model layers.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLMScan: Causal Scan for LLM Misbehavior Detection</title><link>https://arxiv.org/abs/2410.16638</link><description>https://arxiv.org/abs/2410.16638&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy for large vision-language models that accelerates training and inference while preserving model performance by intelligently dropping image tokens based on their redundancy.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Improving Causal Reasoning in Large Language Models: A Survey</title><link>https://arxiv.org/abs/2410.16676</link><description>https://arxiv.org/abs/2410.16676&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy for Large Vision-Language Models (LVLMs) that improves computational efficiency during training and inference by intelligently dropping redundant image tokens while maintaining comparable performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Influential Language Data Selection via Gradient Trajectory Pursuit</title><link>https://arxiv.org/abs/2410.16710</link><description>https://arxiv.org/abs/2410.16710&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy for large vision-language models (LVLMs) that significantly accelerates training and inference efficiency while maintaining comparable performance by strategically dropping redundant image tokens across model layers.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DENOASR: Debiasing ASRs through Selective Denoising</title><link>https://arxiv.org/abs/2410.16712</link><description>https://arxiv.org/abs/2410.16712&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy for large vision-language models that enhances efficiency during training and inference by intelligently dropping redundant image tokens, leading to significant reductions in computational costs with negligible performance loss.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Enhancing Low-Resource ASR through Versatile TTS: Bridging the Data Gap</title><link>https://arxiv.org/abs/2410.16726</link><description>https://arxiv.org/abs/2410.16726&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy for large vision-language models (LVLMs) that enhances training and inference efficiency by selectively dropping image tokens based on their redundancy across model layers, achieving significant performance acceleration with minimal loss in model effectiveness.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Context-aware Inductive Knowledge Graph Completion with Latent Type Constraints and Subgraph Reasoning</title><link>https://arxiv.org/abs/2410.16803</link><description>https://arxiv.org/abs/2410.16803&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy designed for large vision-language models (LVLMs) that accelerates training and inference by dropping redundant image tokens in a pyramid-like manner, achieving significant computational efficiency with negligible performance loss.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>EnvBridge: Bridging Diverse Environments with Cross-Environment Knowledge Transfer for Embodied AI</title><link>https://arxiv.org/abs/2410.16919</link><description>https://arxiv.org/abs/2410.16919&lt;br /&gt;PyramidDrop is a strategy designed to reduce visual redundancy in large vision-language models (LVLMs) by strategically dropping image tokens during training and inference, which results in significant acceleration in computational efficiency without compromising model performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Can a Machine Distinguish High and Low Amount of Social Creak in Speech?</title><link>https://arxiv.org/abs/2410.17028</link><description>https://arxiv.org/abs/2410.17028&lt;br /&gt;PyramidDrop is a novel strategy for reducing visual redundancy in large vision-language models (LVLMs), significantly improving training efficiency and inference speed by intelligently dropping image tokens while preserving model performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs</title><link>https://arxiv.org/abs/2410.17050</link><description>https://arxiv.org/abs/2410.17050&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy for large vision-language models (LVLMs) that optimizes efficiency during training and inference by selectively dropping image tokens, resulting in significant reductions in computational cost while maintaining comparable performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Continuous Speech Tokenizer in Text To Speech</title><link>https://arxiv.org/abs/2410.17081</link><description>https://arxiv.org/abs/2410.17081&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy designed for large vision-language models (LVLMs) that enhances efficiency in training and inference by selectively dropping redundant image tokens based on a similarity calculation, achieving significant reductions in computational costs with minimal performance loss.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>PAPILLON: PrivAcy Preservation from Internet-based and Local Language MOdel ENsembles</title><link>https://arxiv.org/abs/2410.17127</link><description>https://arxiv.org/abs/2410.17127&lt;br /&gt;PyramidDrop is a strategy for reducing visual redundancy in large vision-language models that accelerates training and inference while maintaining performance by selectively dropping image tokens based on their redundancy across model layers.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Improving Pinterest Search Relevance Using Large Language Models</title><link>https://arxiv.org/abs/2410.17152</link><description>https://arxiv.org/abs/2410.17152&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy for large vision-language models that enhances efficiency during training and inference by intelligently dropping image tokens in a way that retains necessary information, achieving significant acceleration in computational costs without compromising performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Language Model Non-myopic Generation for Reasoning and Planning</title><link>https://arxiv.org/abs/2410.17195</link><description>https://arxiv.org/abs/2410.17195&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy designed to enhance the efficiency of large vision-language models (LVLMs) by selectively dropping image tokens in later stages of the model, resulting in significant reductions in training time and computational costs while maintaining comparable performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Audio-to-Score Conversion Model Based on Whisper methodology</title><link>https://arxiv.org/abs/2410.17209</link><description>https://arxiv.org/abs/2410.17209&lt;br /&gt;PyramidDrop is a strategy designed to accelerate large vision-language models by reducing visual token redundancy without significant loss of performance, achieving substantial improvements in training time and inference efficiency.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Creativity in AI: Progresses and Challenges</title><link>https://arxiv.org/abs/2410.17218</link><description>https://arxiv.org/abs/2410.17218&lt;br /&gt;PyramidDrop introduces a visual redundancy reduction strategy for large vision-language models (LVLMs) that enhances efficiency in training and inference by selectively dropping image tokens based on similarity, achieving significant reductions in computational costs with minimal performance loss.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Automated Spinal MRI Labelling from Reports Using a Large Language Model</title><link>https://arxiv.org/abs/2410.17235</link><description>https://arxiv.org/abs/2410.17235&lt;br /&gt;PyramidDrop is a proposed visual redundancy reduction strategy for large vision-language models (LVLMs) that enhances training and inference efficiency by selectively dropping redundant image tokens, achieving significant acceleration in computational costs without sacrificing model performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning</title><link>https://arxiv.org/abs/2410.17238</link><description>https://arxiv.org/abs/2410.17238&lt;br /&gt;PyramidDrop is a visual redundancy reduction strategy for large vision-language models (LVLMs) that improves training and inference efficiency by selectively dropping redundant image tokens while maintaining model performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Towards Reliable Evaluation of Behavior Steering Interventions in LLMs</title><link>https://arxiv.org/abs/2410.17245</link><description>https://arxiv.org/abs/2410.17245&lt;br /&gt;PyramidDrop introduces a visual redundancy reduction strategy for large vision-language models (LVLMs) that accelerates training and inference by intelligently dropping less crucial image tokens, achieving significant computational savings without substantial performance loss.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction</title><link>https://arxiv.org/abs/2410.17247</link><description>https://arxiv.org/abs/2410.17247&lt;br /&gt;PyramidDrop is a novel strategy designed to enhance the efficiency of large vision-language models (LVLMs) by reducing visual token redundancy without significantly compromising performance, resulting in considerable acceleration in both training time and inference operations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Altogether: Image Captioning via Re-aligning Alt-text</title><link>https://arxiv.org/abs/2410.17251</link><description>https://arxiv.org/abs/2410.17251&lt;br /&gt;This paper presents a novel zero-shot cross-lingual Named Entity Recognition (NER) approach that utilizes phonemic representations based on the International Phonetic Alphabet (IPA) to enhance recognition performance for low-resource languages, outpacing traditional methods significantly.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Lex2Sent: A bagging approach to unsupervised sentiment analysis</title><link>https://arxiv.org/abs/2209.13023</link><description>https://arxiv.org/abs/2209.13023&lt;br /&gt;This paper presents a novel zero-shot cross-lingual named entity recognition (NER) approach that uses phonemic representations based on the International Phonetic Alphabet (IPA) to improve performance in low-resource languages, achieving significant improvements over baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Interactive Concept Learning for Uncovering Latent Themes in Large Text Collections</title><link>https://arxiv.org/abs/2305.05094</link><description>https://arxiv.org/abs/2305.05094&lt;br /&gt;This paper presents a novel approach to zero-shot cross-lingual named entity recognition (NER) for low-resource languages by utilizing phonemic representations based on the International Phonetic Alphabet (IPA), which significantly enhances performance over baseline models, especially for non-Latin scripts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fine-grained and Explainable Factuality Evaluation for Multimodal Summarization</title><link>https://arxiv.org/abs/2402.11414</link><description>https://arxiv.org/abs/2402.11414&lt;br /&gt;This paper presents a novel zero-shot cross-lingual Named Entity Recognition (NER) approach using phonemic representations based on the International Phonetic Alphabet (IPA) to effectively operate in low-resource languages, significantly outperforming baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>PHAnToM: Persona-based Prompting Has An Effect on Theory-of-Mind Reasoning in Large Language Models</title><link>https://arxiv.org/abs/2403.02246</link><description>https://arxiv.org/abs/2403.02246&lt;br /&gt;This paper presents a novel approach to zero-shot cross-lingual named entity recognition (NER) using phonemic representations based on the International Phonetic Alphabet (IPA) to improve NER performance for extremely low-resource languages, showing significant advancements over baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Can Large Language Models Identify Authorship?</title><link>https://arxiv.org/abs/2403.08213</link><description>https://arxiv.org/abs/2403.08213&lt;br /&gt;This paper presents a novel approach for zero-shot cross-lingual named entity recognition (NER) using phonemic representations based on the International Phonetic Alphabet (IPA), which significantly improves performance in low-resource languages compared to baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>F-MALLOC: Feed-forward Memory Allocation for Continual Learning in Neural Machine Translation</title><link>https://arxiv.org/abs/2404.04846</link><description>https://arxiv.org/abs/2404.04846&lt;br /&gt;The paper presents a novel approach to zero-shot cross-lingual Named Entity Recognition (NER) for low-resource languages by utilizing phonemic representations based on the International Phonetic Alphabet (IPA), achieving significant improvements over baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Position Engineering: Boosting Large Language Models through Positional Information Manipulation</title><link>https://arxiv.org/abs/2404.11216</link><description>https://arxiv.org/abs/2404.11216&lt;br /&gt;This paper presents a novel approach to zero-shot cross-lingual Named Entity Recognition (NER) using phonemic representations based on the International Phonetic Alphabet (IPA) to improve performance for low-resource languages, significantly outperforming baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations</title><link>https://arxiv.org/abs/2404.13948</link><description>https://arxiv.org/abs/2404.13948&lt;br /&gt;This paper introduces a novel zero-shot cross-lingual named entity recognition (NER) approach using phonemic representations based on the International Phonetic Alphabet (IPA), which significantly improves performance in low-resource languages compared to existing methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Holmes: A Benchmark to Assess the Linguistic Competence of Language Models</title><link>https://arxiv.org/abs/2404.18923</link><description>https://arxiv.org/abs/2404.18923&lt;br /&gt;This paper introduces a novel method for zero-shot cross-lingual Named Entity Recognition (NER) using phonemic representations based on the International Phonetic Alphabet (IPA) to enhance performance on low-resource languages, achieving significantly improved accuracy over baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Levels of AI Agents: from Rules to Large Language Models</title><link>https://arxiv.org/abs/2405.06643</link><description>https://arxiv.org/abs/2405.06643&lt;br /&gt;The paper presents a novel approach to zero-shot cross-lingual named entity recognition (NER) using phonemic representations based on the International Phonetic Alphabet (IPA), outperforming baseline models in low-resource languages, especially those with non-Latin scripts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Adaptable and Reliable Text Classification using Large Language Models</title><link>https://arxiv.org/abs/2405.10523</link><description>https://arxiv.org/abs/2405.10523&lt;br /&gt;This paper presents a novel zero-shot cross-lingual named entity recognition (NER) approach using phonemic representations based on the International Phonetic Alphabet (IPA) to effectively handle low-resource languages, significantly improving performance on such languages compared to baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DiffNorm: Self-Supervised Normalization for Non-autoregressive Speech-to-speech Translation</title><link>https://arxiv.org/abs/2405.13274</link><description>https://arxiv.org/abs/2405.13274&lt;br /&gt;This paper presents a novel approach for zero-shot cross-lingual named entity recognition (NER) using phonemic representations based on the International Phonetic Alphabet (IPA) to enhance performance in low-resource languages.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training</title><link>https://arxiv.org/abs/2405.15319</link><description>https://arxiv.org/abs/2405.15319&lt;br /&gt;The paper presents a novel zero-shot cross-lingual named entity recognition (NER) method utilizing phonemic representations based on the International Phonetic Alphabet (IPA) to improve performance in low-resource languages, achieving notable results compared to baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Superposed Decoding: Multiple Generations from a Single Autoregressive Inference Pass</title><link>https://arxiv.org/abs/2405.18400</link><description>https://arxiv.org/abs/2405.18400&lt;br /&gt;This paper presents a zero-shot cross-lingual Named Entity Recognition (NER) method that utilizes phonemic representations based on the International Phonetic Alphabet (IPA) to effectively handle low-resource languages, significantly improving performance compared to baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Faster Cascades via Speculative Decoding</title><link>https://arxiv.org/abs/2405.19261</link><description>https://arxiv.org/abs/2405.19261&lt;br /&gt;This paper presents a novel zero-shot cross-lingual named entity recognition (NER) approach utilizing phonemic representations based on the International Phonetic Alphabet (IPA), which shows significant improvements in performance for low-resource languages, especially those with non-Latin scripts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Language Model Council: Democratically Benchmarking Foundation Models on Highly Subjective Tasks</title><link>https://arxiv.org/abs/2406.08598</link><description>https://arxiv.org/abs/2406.08598&lt;br /&gt;This paper proposes a zero-shot cross-lingual Named Entity Recognition (NER) method utilizing phonemic representations based on the International Phonetic Alphabet (IPA) to improve performance in low-resource languages, showcasing superior results compared to baseline models, especially with non-Latin scripts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Learning Language Structures through Grounding</title><link>https://arxiv.org/abs/2406.09662</link><description>https://arxiv.org/abs/2406.09662&lt;br /&gt;This paper presents a zero-shot cross-lingual named entity recognition (NER) approach using phonemic representations based on the International Phonetic Alphabet (IPA), demonstrating significant improvements in performance for low-resource languages compared to baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities</title><link>https://arxiv.org/abs/2406.12074</link><description>https://arxiv.org/abs/2406.12074&lt;br /&gt;This paper presents a novel approach to zero-shot cross-lingual named entity recognition (NER) that utilizes phonemic representations based on the International Phonetic Alphabet (IPA) to enhance performance for low-resource languages, showing significant improvements over baseline models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages</title><link>https://arxiv.org/abs/2406.16030</link><description>https://arxiv.org/abs/2406.16030&lt;br /&gt;The paper introduces a novel approach for zero-shot cross-lingual named entity recognition (NER) using phonemic representations based on the International Phonetic Alphabet (IPA), significantly improving performance in low-resource languages compared to existing methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>One Thousand and One Pairs: A "novel" challenge for long-context language models</title><link>https://arxiv.org/abs/2406.16264</link><description>https://arxiv.org/abs/2406.16264&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning steps in Multimodal Chain of Thought (MCoT) prompts for multimodal large language models (MLLMs), assessing both image descriptions and the correctness of conditional reasoning steps.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens</title><link>https://arxiv.org/abs/2406.17378</link><description>https://arxiv.org/abs/2406.17378&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning steps in Multimodal Chain of Thought (MCoT) prompting for multimodal large language models, assessing both image description accuracy and the correctness of generated reasoning steps against human judgments.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Evaluating Human Alignment and Model Faithfulness of LLM Rationale</title><link>https://arxiv.org/abs/2407.00219</link><description>https://arxiv.org/abs/2407.00219&lt;br /&gt;MiCEval is a framework designed to evaluate the quality of reasoning chains in Multimodal Chain of Thought (MCoT) prompting strategies for multimodal large language models (MLLMs), focusing on the accuracy of image descriptions and the correctness of reasoning steps.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>HAF-RM: A Hybrid Alignment Framework for Reward Model Training</title><link>https://arxiv.org/abs/2407.04185</link><description>https://arxiv.org/abs/2407.04185&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning steps in Multimodal Chain of Thought (MCoT) prompting for multimodal large language models (MLLMs), addressing the need for automated correctness assessments of reasoning chains and descriptions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>An Empirical Comparison of Vocabulary Expansion and Initialization Approaches for Language Models</title><link>https://arxiv.org/abs/2407.05841</link><description>https://arxiv.org/abs/2407.05841&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning in Multimodal Chain of Thought prompted large language models by assessing both the accuracy of image descriptions and the correctness of generated reasoning steps.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval</title><link>https://arxiv.org/abs/2407.12883</link><description>https://arxiv.org/abs/2407.12883&lt;br /&gt;MiCEval introduces a framework for assessing the quality of reasoning steps in Multimodal Chain of Thought (MCoT) prompting strategies for multimodal large language models (MLLMs), focusing on evaluating the accuracy of image descriptions and the correctness of reasoning steps through a fine-grained annotated dataset.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLMs left, right, and center: Assessing GPT's capabilities to label political bias from web domains</title><link>https://arxiv.org/abs/2407.14344</link><description>https://arxiv.org/abs/2407.14344&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning steps in Multimodal Chain of Thought prompting strategies for large language models (MLLMs), focusing on assessing the accuracy of image descriptions and the correctness of reasoning chains in a fine-grained manner.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Large Language Models for Biomedical Text Simplification: Promising But Not There Yet</title><link>https://arxiv.org/abs/2408.03871</link><description>https://arxiv.org/abs/2408.03871&lt;br /&gt;MiCEval introduces a framework for assessing the quality of reasoning steps in Multimodal Chain of Thought (MCoT) prompting strategies, providing automated evaluation metrics for image descriptions and reasoning chains in multimodal large language models (MLLMs).</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SysBench: Can Large Language Models Follow System Messages?</title><link>https://arxiv.org/abs/2408.10943</link><description>https://arxiv.org/abs/2408.10943&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning steps in Multimodal Chain of Thought (MCoT) prompting strategies for multimodal large language models, focusing on both the accuracy of image descriptions and the correctness of reasoning steps.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TempoFormer: A Transformer for Temporally-aware Representations in Change Detection</title><link>https://arxiv.org/abs/2408.15689</link><description>https://arxiv.org/abs/2408.15689&lt;br /&gt;MiCEval is a proposed framework for evaluating the quality of reasoning steps in Multimodal Chain of Thought (MCoT) prompting for multimodal large language models, focusing on the correctness of image descriptions and the quality of reasoning steps through a fine-grained annotation dataset.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>The Impact of Large Language Models in Academia: from Writing to Speaking</title><link>https://arxiv.org/abs/2409.13686</link><description>https://arxiv.org/abs/2409.13686&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning steps in Multimodal Chain of Thought (MCoT) prompting strategies used in multimodal large language models, assessing both image description accuracy and reasoning process correctness through a fine-grained annotated dataset.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Debiasing Text Safety Classifiers through a Fairness-Aware Ensemble</title><link>https://arxiv.org/abs/2409.13705</link><description>https://arxiv.org/abs/2409.13705&lt;br /&gt;MiCEval is a framework developed to evaluate the quality of reasoning steps in Multimodal Chain of Thought (MCoT) for multimodal large language models by assessing both the accuracy of image descriptions and the correctness of reasoning steps.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning</title><link>https://arxiv.org/abs/2409.14710</link><description>https://arxiv.org/abs/2409.14710&lt;br /&gt;MiCEval is a framework for evaluating the quality of reasoning steps in Multimodal Chain of Thought (MCoT) prompting for multimodal large language models (MLLMs), focusing on the accuracy of image descriptions and the correctness of each reasoning step, demonstrated to align more closely with human judgments than existing evaluation methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>PLaMo-100B: A Ground-Up Language Model Designed for Japanese Proficiency</title><link>https://arxiv.org/abs/2410.07563</link><description>https://arxiv.org/abs/2410.07563&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning steps in Multimodal Chain of Thought prompting strategies for multimodal large language models, focusing on both image descriptions and reasoning accuracy.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Tokenization and Morphology in Multilingual Language Models: A Comparative Analysis of mT5 and ByT5</title><link>https://arxiv.org/abs/2410.11627</link><description>https://arxiv.org/abs/2410.11627&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning in Multimodal Chain of Thought (MCoT) by assessing both image descriptions and individual reasoning steps, demonstrating superior alignment with human judgments compared to prior evaluation methods.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Improving Reinforcement Learning from Human Feedback with Efficient Reward Model Ensemble</title><link>https://arxiv.org/abs/2401.16635</link><description>https://arxiv.org/abs/2401.16635&lt;br /&gt;The paper introduces the Entity Tracing Framework (ETF) to detect hallucinations in code summarization outputs of large language models (LLMs) by leveraging static program analysis and mapping code entities, achieving a 0.73 F1 score for detection accuracy.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>DNABERT-S: Pioneering Species Differentiation with Species-Aware DNA Embeddings</title><link>https://arxiv.org/abs/2402.08777</link><description>https://arxiv.org/abs/2402.08777&lt;br /&gt;The ETF framework introduces a novel approach for detecting hallucinations in code summaries by utilizing static program analysis and large language models to verify code entities and their intents, achieving a notable success rate in accuracy evaluation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLM4Decompile: Decompiling Binary Code with Large Language Models</title><link>https://arxiv.org/abs/2403.05286</link><description>https://arxiv.org/abs/2403.05286&lt;br /&gt;The ETF paper introduces a novel Entity Tracing Framework designed to detect hallucinations in code summaries generated by large language models (LLMs), utilizing static program analysis and a curated dataset to improve the accuracy of code summarization outputs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Are Large Language Models Moral Hypocrites? A Study Based on Moral Foundations</title><link>https://arxiv.org/abs/2405.11100</link><description>https://arxiv.org/abs/2405.11100&lt;br /&gt;The study introduces the Entity Tracing Framework (ETF) for detecting hallucinations in code summarization by mapping and verifying code entities through static program analysis and large language models, utilizing a curated dataset of approximately 10,000 samples to enhance accuracy in identifying misleading outputs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>BPO: Staying Close to the Behavior LLM Creates Better Online LLM Alignment</title><link>https://arxiv.org/abs/2406.12168</link><description>https://arxiv.org/abs/2406.12168&lt;br /&gt;The paper presents ETF, an Entity Tracing Framework designed to detect hallucinations in code summaries generated by large language models (LLMs), utilizing static program analysis and a novel dataset of approximately 10,000 samples for effective verification of code entities and their intents.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>GLBench: A Comprehensive Benchmark for Graph with Large Language Models</title><link>https://arxiv.org/abs/2407.07457</link><description>https://arxiv.org/abs/2407.07457&lt;br /&gt;The paper presents the Entity Tracing Framework (ETF) designed for detecting hallucinations in code summaries generated by large language models, using a new dataset of approximately 10,000 samples and static program analysis to verify code entities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Pairing Analogy-Augmented Generation with Procedural Memory for Procedural Q&amp;A</title><link>https://arxiv.org/abs/2409.01344</link><description>https://arxiv.org/abs/2409.01344&lt;br /&gt;This paper introduces the Entity Tracing Framework (ETF) to detect hallucinations in code summaries generated by large language models, utilizing a dataset of ~10K samples and static program analysis to verify code entities and their intents, achieving a notable F1 score of 0.73.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Merging LoRAs like Playing LEGO: Pushing the Modularity of LoRA to Extremes Through Rank-Wise Clustering</title><link>https://arxiv.org/abs/2409.16167</link><description>https://arxiv.org/abs/2409.16167&lt;br /&gt;The study introduces the Entity Tracing Framework (ETF) for detecting hallucinations in code summaries generated by large language models (LLMs), utilizing a dataset of 10,000 samples and static program analysis to verify code entities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance</title><link>https://arxiv.org/abs/2410.10796</link><description>https://arxiv.org/abs/2410.10796&lt;br /&gt;The ETF framework introduces a novel approach for detecting hallucinations in code summarization by utilizing static program analysis and large language models to trace code entities and verify their intents, resulting in an interpretable method for improving summary accuracy.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLM Gesticulator: Leveraging Large Language Models for Scalable and Controllable Co-Speech Gesture Synthesis</title><link>https://arxiv.org/abs/2410.10851</link><description>https://arxiv.org/abs/2410.10851&lt;br /&gt;The paper introduces the Entity Tracing Framework (ETF) for detecting hallucinations in code summaries generated by large language models, emphasizing a novel dataset and static program analysis to enhance the accuracy of code summarization tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Do LLMs "know" internally when they follow instructions?</title><link>https://arxiv.org/abs/2410.14516</link><description>https://arxiv.org/abs/2410.14516&lt;br /&gt;The paper introduces an Entity Tracing Framework (ETF) designed for detecting hallucinations in code summarization by leveraging static program analysis and large language models to verify code entities and their intents, achieving a 0.73 F1 score for accuracy evaluation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Moonshine: Speech Recognition for Live Transcription and Voice Commands</title><link>https://arxiv.org/abs/2410.15608</link><description>https://arxiv.org/abs/2410.15608&lt;br /&gt;CartesianMoE introduces a new Mixture-of-Experts model that enhances knowledge sharing among experts through Cartesian Product Routing, improving performance while managing computational complexity in large language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>On-Device LLMs for SMEs: Challenges and Opportunities</title><link>https://arxiv.org/abs/2410.16070</link><description>https://arxiv.org/abs/2410.16070&lt;br /&gt;CartesianMoE is a novel approach to enhance knowledge sharing among experts in Mixture-of-Experts models by implementing a Cartesian product routing mechanism, improving both scalability and performance in large language models.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian Product Routing in Mixture-of-Experts</title><link>https://arxiv.org/abs/2410.16077</link><description>https://arxiv.org/abs/2410.16077&lt;br /&gt;CartesianMoE introduces a novel method for improving knowledge sharing among experts in Mixture-of-Experts models by utilizing a Cartesian product routing approach, leading to enhanced performance in large language models without significantly increasing computational complexity.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Bayesian scaling laws for in-context learning</title><link>https://arxiv.org/abs/2410.16531</link><description>https://arxiv.org/abs/2410.16531&lt;br /&gt;This paper presents Bayesian scaling laws that explain in-context learning (ICL) in language models, illustrating their correlation with model accuracy and predicting conditions under which suppressed capabilities may reemerge, thereby advancing understanding of model safety alignment.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Captions Speak Louder than Images (CASLIE): Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data</title><link>https://arxiv.org/abs/2410.17337</link><description>https://arxiv.org/abs/2410.17337&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory to quantitatively assess distinct personality traits reflected in their outputs, thus enhancing understanding of LLMs in conversational contexts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>All Entities are Not Created Equal: Examining the Long Tail for Fine-Grained Entity Typing</title><link>https://arxiv.org/abs/2410.17355</link><description>https://arxiv.org/abs/2410.17355&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the distinct personality traits of Large Language Models (LLMs) through a modified version of the Big Five Inventory, enabling quantitative assessment of LLMs' linguistic outputs and contributing to human-computer interaction research.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>AMUSD: Asynchronous Multi-Device Speculative Decoding for LLM Acceleration</title><link>https://arxiv.org/abs/2410.17375</link><description>https://arxiv.org/abs/2410.17375&lt;br /&gt;LMLPA introduces a system for quantitatively assessing the linguistic personalities of Large Language Models (LLMs) using an adapted Big Five Inventory, providing insights into their personality traits and contributing to the fields of Human-Computer Interaction and Human-Centered AI.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities</title><link>https://arxiv.org/abs/2410.17385</link><description>https://arxiv.org/abs/2410.17385&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system to quantitatively evaluate the linguistic personalities of Large Language Models (LLMs) by adapting a personality assessment questionnaire based on the Big Five Inventory and analyzing their language outputs to identify distinct personality traits.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Scalable Influence and Fact Tracing for Large Language Model Pretraining</title><link>https://arxiv.org/abs/2410.17413</link><description>https://arxiv.org/abs/2410.17413&lt;br /&gt;LMLPA is a system developed to evaluate the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory for assessing their language generation capabilities, demonstrating that LLMs possess distinct personality traits that can be quantified.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Artificial Intelligence in Brazilian News: A Mixed-Methods Analysis</title><link>https://arxiv.org/abs/2410.17423</link><description>https://arxiv.org/abs/2410.17423&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system for evaluating the linguistic personalities of Large Language Models (LLMs) by adapting a personality assessment questionnaire to understand and quantify their language generation capabilities through distinct personality traits reflected in their outputs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Evaluating AI-Generated Essays with GRE Analytical Writing Assessment</title><link>https://arxiv.org/abs/2410.17439</link><description>https://arxiv.org/abs/2410.17439&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) is introduced to evaluate the linguistic personalities of Large Language Models (LLMs), adapting the Big Five Inventory for AI, allowing for the quantification of distinct personality traits in LLMs based on their language generation outputs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>In Context Learning and Reasoning for Symbolic Regression with Large Language Models</title><link>https://arxiv.org/abs/2410.17448</link><description>https://arxiv.org/abs/2410.17448&lt;br /&gt;LMLPA introduces a system for assessing the linguistic personalities of Large Language Models (LLMs) through the adaptation of the Big Five Inventory, enabling a quantitative evaluation of LLMs' language generation capabilities based on distinct personality traits reflected in their outputs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination</title><link>https://arxiv.org/abs/2410.17477</link><description>https://arxiv.org/abs/2410.17477&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system to quantitatively evaluate the linguistic personalities of Large Language Models (LLMs) using an adapted Big Five personality inventory, facilitating insights into their language generation capabilities and enhancing Human-Computer Interaction.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don't mimic the full human distribution</title><link>https://arxiv.org/abs/2410.17482</link><description>https://arxiv.org/abs/2410.17482&lt;br /&gt;LMLPA introduces a novel system for assessing the linguistic personality traits of Large Language Models (LLMs) using an adapted Big Five Inventory questionnaire, facilitating a quantitative understanding of LLMs' language generation capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning</title><link>https://arxiv.org/abs/2410.17485</link><description>https://arxiv.org/abs/2410.17485&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) is a system developed to quantitatively evaluate the distinct personality traits of Large Language Models (LLMs) through an adapted version of the Big Five Inventory in an open-ended format, enabling the assessment of LLMs' language generation and personality capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Large Language Models Still Exhibit Bias in Long Text</title><link>https://arxiv.org/abs/2410.17519</link><description>https://arxiv.org/abs/2410.17519&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) is a system that evaluates the linguistic personality traits of Large Language Models (LLMs) using a modified Big Five Inventory questionnaire tailored for their text generation capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Navigate Complex Physical Worlds via Geometrically Constrained LLM</title><link>https://arxiv.org/abs/2410.17529</link><description>https://arxiv.org/abs/2410.17529&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) is a system designed to evaluate the distinct personality traits of Large Language Models (LLMs) through a modified Big Five Inventory, enabling quantitative assessments of their linguistic outputs in conversational contexts.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification</title><link>https://arxiv.org/abs/2410.17546</link><description>https://arxiv.org/abs/2410.17546&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) is a system developed to evaluate the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory for personality assessment, demonstrating that LLMs exhibit distinct personality traits that can be quantified to enhance understanding and application in Human-Computer Interaction.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ESpeW: Robust Copyright Protection for LLM-based EaaS via Embedding-Specific Watermark</title><link>https://arxiv.org/abs/2410.17552</link><description>https://arxiv.org/abs/2410.17552&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system to quantitatively assess the linguistic personalities of Large Language Models (LLMs) based on the Big Five personality traits, highlighting how LLMs exhibit distinct personality traits in their language generation capabilities.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MM-Eval: A Multilingual Meta-Evaluation Benchmark for LLM-as-a-Judge and Reward Models</title><link>https://arxiv.org/abs/2410.17578</link><description>https://arxiv.org/abs/2410.17578&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system to quantitatively evaluate the distinct personality traits of Large Language Models (LLMs) through text-based responses, adapting traditional human personality assessments to better understand LLMs' language generation capabilities and their implications in Human-Computer Interaction.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Cross-model Control: Improving Multiple Large Language Models in One-time Training</title><link>https://arxiv.org/abs/2410.17599</link><description>https://arxiv.org/abs/2410.17599&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system to quantitatively evaluate the linguistic personalities of Large Language Models (LLMs) through an adapted personality assessment questionnaire, enabling a better understanding of their language generation capabilities and distinct personality traits.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective</title><link>https://arxiv.org/abs/2410.17600</link><description>https://arxiv.org/abs/2410.17600&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system for quantitatively evaluating the distinct personality traits of Large Language Models (LLMs) based on their linguistic outputs, using an adapted version of the Big Five Inventory for personality assessment.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents</title><link>https://arxiv.org/abs/2410.17657</link><description>https://arxiv.org/abs/2410.17657&lt;br /&gt;The paper 'Zeitenwenden' analyzes the evolution of German political discourse from historical contexts by utilizing a time series variant of LDA topic modeling on digitized Bundestag records to understand how political topics and key discussion points have changed over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Quantifying the Risks of Tool-assisted Rephrasing to Linguistic Diversity</title><link>https://arxiv.org/abs/2410.17670</link><description>https://arxiv.org/abs/2410.17670&lt;br /&gt;The paper analyzes the changing German political discourse from 1871 to the present using a time series variant of the topic model LDA to identify events that have had a lasting impact on political topics and discussions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Towards a Similarity-adjusted Surprisal Theory</title><link>https://arxiv.org/abs/2410.17676</link><description>https://arxiv.org/abs/2410.17676&lt;br /&gt;The paper analyzes the evolution of political discourse in Germany since the establishment of the Federal Republic in 1949 by applying a time series variant of the LDA topic model to the digitized plenary session records of the Bundestag, aiming to identify significant events that influenced political topics over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&amp;A Platforms</title><link>https://arxiv.org/abs/2410.17694</link><description>https://arxiv.org/abs/2410.17694&lt;br /&gt;The study analyzes the evolution of German political discourse from 1871 to the present using a time series variant of the LDA topic model to identify significant events and changes in political topics reflected in digitized records of Bundestag sessions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Beware of Calibration Data for Pruning Large Language Models</title><link>https://arxiv.org/abs/2410.17711</link><description>https://arxiv.org/abs/2410.17711&lt;br /&gt;This paper analyzes the historical changes in the German political discourse from 1871 to the present by utilizing a time series variant of the topic model LDA to study digitized transcripts of plenary sessions from the German Bundestag, allowing for the detection of shifts in key discussion points and word frequency over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CogSteer: Cognition-Inspired Selective Layer Intervention for Efficient Semantic Steering in Large Language Models</title><link>https://arxiv.org/abs/2410.17714</link><description>https://arxiv.org/abs/2410.17714&lt;br /&gt;The paper explores the evolution of German political discourse from monarchy to democracy through a time series analysis of digitized plenary session records of the Bundestag, utilizing a topic modeling approach to identify significant changes in political topics over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Dialectal and Low Resource Machine Translation for Aromanian</title><link>https://arxiv.org/abs/2410.17728</link><description>https://arxiv.org/abs/2410.17728&lt;br /&gt;The paper 'Zeitenwenden' analyzes the evolution of political discourse in Germany from the establishment of the German national state in 1871 to the present, using a time series variant of the topic model LDA on digitized plenary session texts from the Bundestag to identify significant events and shifts in political topics over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MojoBench: Language Modeling and Benchmarks for Mojo</title><link>https://arxiv.org/abs/2410.17736</link><description>https://arxiv.org/abs/2410.17736&lt;br /&gt;The paper presents an analysis of German political discourse over time using a time series variant of the LDA topic model to uncover how key discussion points and political topics have evolved in response to significant historical events since the formation of the Federal Republic of Germany in 1949.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Local Contrastive Editing of Gender Stereotypes</title><link>https://arxiv.org/abs/2410.17739</link><description>https://arxiv.org/abs/2410.17739&lt;br /&gt;The paper presents an analysis of the historical shifts in German political discourse using a time series variant of the topic model LDA to identify the effects of significant events on discussion points over time, based on digitally logged plenary sessions of the German Bundestag since 1949.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Latent Structures of Intertextuality in French Fiction</title><link>https://arxiv.org/abs/2410.17759</link><description>https://arxiv.org/abs/2410.17759&lt;br /&gt;The paper analyzes the changes in political discourse in Germany from 1871 to the present using a time series variant of the topic model LDA, revealing how significant events have influenced key discussion points in the German Bundestag over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Leveraging the Domain Adaptation of Retrieval Augmented Generation Models for Question Answering and Reducing Hallucination</title><link>https://arxiv.org/abs/2410.17783</link><description>https://arxiv.org/abs/2410.17783&lt;br /&gt;The paper explores changes in the German political discourse from 1871 to the present by analyzing digitized texts from the Bundestag using a time series variant of the topic model LDA, identifying how significant historical events have influenced political topics and word frequency over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation</title><link>https://arxiv.org/abs/2410.17799</link><description>https://arxiv.org/abs/2410.17799&lt;br /&gt;The paper analyzes the evolution of German political discourse from the establishment of the first national state in 1871 to the present, utilizing a time series variant of the topic model LDA to track changes in key discussion points over time based on digitized records of Bundestag plenary sessions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Understanding When Tree of Thoughts Succeeds: Larger Models Excel in Generation, Not Discrimination</title><link>https://arxiv.org/abs/2410.17820</link><description>https://arxiv.org/abs/2410.17820&lt;br /&gt;The paper 'Zeitenwenden' analyzes the evolution of German political discourse using a time series variant of topic modeling to detect changes in discussion points and word frequency in the context of historical political events.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Understanding Layer Significance in LLM Alignment</title><link>https://arxiv.org/abs/2410.17875</link><description>https://arxiv.org/abs/2410.17875&lt;br /&gt;The paper analyzes the evolution of political discourse in Germany from 1871 to present using a time series variant of the LDA topic model to detect changes in key discussion points over time based on digitized records of Bundestag plenary sessions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SpeakGer: A meta-data enriched speech corpus of German state and federal parliaments</title><link>https://arxiv.org/abs/2410.17886</link><description>https://arxiv.org/abs/2410.17886&lt;br /&gt;The paper analyzes historical texts from the German Bundestag using a time series variant of topic modeling to identify changes in political discourse and the lasting effects of significant events on political topics in Germany from 1871 to the present.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Scaling Diffusion Language Models via Adaptation from Autoregressive Models</title><link>https://arxiv.org/abs/2410.17891</link><description>https://arxiv.org/abs/2410.17891&lt;br /&gt;The paper investigates the evolution of German political discourse by analyzing digitized records of Bundestag plenary sessions using a time series version of the LDA topic model to identify lasting impacts of historical events on political topics over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Value Residual Learning For Alleviating Attention Concentration In Transformers</title><link>https://arxiv.org/abs/2410.17897</link><description>https://arxiv.org/abs/2410.17897&lt;br /&gt;This paper analyzes the evolution of the German political discourse from 1871 to the present by applying a time series variant of the topic model LDA to digitized transcripts of the Bundestag sessions, aiming to identify key events that have shaped political discussions over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and Low-frequency Character Bigrams</title><link>https://arxiv.org/abs/2410.17901</link><description>https://arxiv.org/abs/2410.17901&lt;br /&gt;The paper explores the evolution of the German political discourse by analyzing digitized plenary session texts from the Bundestag using a time series variant of the topic model LDA, enabling the detection of changes in discussion topics and word frequencies over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains</title><link>https://arxiv.org/abs/2410.17952</link><description>https://arxiv.org/abs/2410.17952&lt;br /&gt;The paper explores changes in the German political discourse from 1871 to the present by analyzing digitized plenary session texts of the Bundestag using a time series variant of the topic model LDA to identify lasting effects of significant events on political topics over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Zeitenwenden: Detecting changes in the German political discourse</title><link>https://arxiv.org/abs/2410.17960</link><description>https://arxiv.org/abs/2410.17960&lt;br /&gt;The paper analyzes changes in the German political discourse from the formation of the first German national state in 1871 to the present, utilizing a time series variant of the topic model LDA to identify key discussion points and shifts in political topics over time.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Are Large Language Models Ready for Travel Planning?</title><link>https://arxiv.org/abs/2410.17333</link><description>https://arxiv.org/abs/2410.17333&lt;br /&gt;The paper presents a time-aware approach for the early detection of anorexia, incorporating precision and speed in the learning process to enhance risk detection on the Web, resulting in excellent performance metrics.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents</title><link>https://arxiv.org/abs/2410.17401</link><description>https://arxiv.org/abs/2410.17401&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, utilizing a CPI+DMC methodology and integrating temporal metrics into the learning process to enhance precision and speed, resulting in strong performance metrics in the eRisk 2024 Task 2 competition.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Intera\c{c}\~ao entre rob\^os humanoides: desenvolvendo a colabora\c{c}\~ao e comunica\c{c}\~ao aut\^onoma</title><link>https://arxiv.org/abs/2410.17450</link><description>https://arxiv.org/abs/2410.17450&lt;br /&gt;The paper presents a time-aware approach for early detection of anorexia in the context of the eRisk competition, utilizing a combined metric for precision and speed in risk detection, demonstrating effective model performance through temporal integration during the learning process.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation</title><link>https://arxiv.org/abs/2410.17462</link><description>https://arxiv.org/abs/2410.17462&lt;br /&gt;This paper presents a time-aware methodology for the early detection of anorexia using a combined approach that optimizes both precision and speed by integrating temporal metrics into the learning process, leading to effective results in early risk detection.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Which Client is Reliable?: A Reliable and Personalized Prompt-based Federated Learning for Medical Image Question Answering</title><link>https://arxiv.org/abs/2410.17484</link><description>https://arxiv.org/abs/2410.17484&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, achieving significant results by incorporating time into the learning process and optimizing for both precision and speed in risk detection tasks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks</title><link>https://arxiv.org/abs/2410.17498</link><description>https://arxiv.org/abs/2410.17498&lt;br /&gt;This research paper presents a time-aware methodology for the early detection of anorexia, designed to optimize both precision and speed in addressing early risk detection using a CPI+DMC approach and temporal metrics for model validation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference</title><link>https://arxiv.org/abs/2410.17954</link><description>https://arxiv.org/abs/2410.17954&lt;br /&gt;This paper introduces a time-aware approach for the early detection of anorexia, utilizing a combined precision-speed metric and integrating temporal metrics into a learning process to improve outcomes within the eRisk 2024 competition.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration</title><link>https://arxiv.org/abs/2410.18032</link><description>https://arxiv.org/abs/2410.18032&lt;br /&gt;This paper introduces the Fast and Slow Generating (FS-GEN) framework, which empirically studies collaborative decoding between Large Language Models (LLMs) and Small Language Models (SLMs) to address issues like inference latency and hallucinations, categorizing their interactions based on dual-process cognitive theory and exploring the conditions for effective collaboration.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CLEAR: Character Unlearning in Textual and Visual Modalities</title><link>https://arxiv.org/abs/2410.18057</link><description>https://arxiv.org/abs/2410.18057&lt;br /&gt;The paper presents a unified framework called Fast and Slow Generating (FS-GEN) that explores collaborative decoding between Large Language Models (LLMs) and Small Language Models (SLMs), drawing insights from dual-process cognitive theory to improve inference latency and reduce hallucinations in language generation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts</title><link>https://arxiv.org/abs/2410.18071</link><description>https://arxiv.org/abs/2410.18071&lt;br /&gt;The paper proposes a unified framework, Fast and Slow Generating (FS-GEN), analyzing collaborative decoding strategies between large and small language models, inspired by dual-process cognitive theory, to mitigate issues like inference latency and hallucinations, while revealing the importance of systematic interactions based on uncertainty in next token predictions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>ALTA: Compiler-Based Analysis of Transformers</title><link>https://arxiv.org/abs/2410.18077</link><description>https://arxiv.org/abs/2410.18077&lt;br /&gt;This paper introduces the Fast and Slow Generating (FS-GEN) framework, which analyzes collaborative decoding methods between large and small language models to address challenges like latency and generation errors, finding that only a small proportion of interactions are necessary for effective collaboration and highlighting the importance of uncertainty in token prediction.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>GPT-SW3: An Autoregressive Language Model for the Nordic Languages</title><link>https://arxiv.org/abs/2305.12987</link><description>https://arxiv.org/abs/2305.12987&lt;br /&gt;This paper introduces the Fast and Slow Generating (FS-GEN) framework, which categorizes Large Language Models (System 2) and Small Language Models (System 1) to analyze their collaborative decoding methodologies, revealing insights on their interaction, efficiency, and the impact of uncertainty on performance.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Let Me Teach You: Pedagogical Foundations of Feedback for Language Models</title><link>https://arxiv.org/abs/2307.00279</link><description>https://arxiv.org/abs/2307.00279&lt;br /&gt;The paper introduces a unified framework called Fast and Slow Generating (FS-GEN) to analyze collaborative decoding between large and small language models, illustrating how their interactions can mitigate issues like inference latency and hallucinations by leveraging their distinct cognitive capabilities based on dual-process theory.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications</title><link>https://arxiv.org/abs/2311.05876</link><description>https://arxiv.org/abs/2311.05876&lt;br /&gt;This paper presents a unified framework called Fast and Slow Generating (FS-GEN) for collaborative decoding between Large Language Models (LLMs) and Small Language Models (SLMs), analyzing how they can work together to improve inference latency, reduce hallucinations, and enhance overall model performance based on insights from dual-process cognitive theory.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>The Causal Influence of Grammatical Gender on Distributional Semantics</title><link>https://arxiv.org/abs/2311.18567</link><description>https://arxiv.org/abs/2311.18567&lt;br /&gt;The paper introduces the Fast and Slow Generating (FS-GEN) framework for collaborative decoding between large and small language models, inspired by dual-process cognitive theory, and analyzes their interactions to mitigate issues of inference latency and hallucinations in language model generation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TravelPlanner: A Benchmark for Real-World Planning with Language Agents</title><link>https://arxiv.org/abs/2402.01622</link><description>https://arxiv.org/abs/2402.01622&lt;br /&gt;The paper introduces the Fast and Slow Generating (FS-GEN) framework, which examines the collaboration between large and small language models to improve inference latency and reduce hallucinations by categorizing them as System 2 (slow and deliberate) and System 1 (fast and intuitive), respectively, while providing insights on effective collaboration conditions and uncertainty in token predictions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Reconfidencing LLMs from the Grouping Loss Perspective</title><link>https://arxiv.org/abs/2402.04957</link><description>https://arxiv.org/abs/2402.04957&lt;br /&gt;The paper presents a unified framework called Fast and Slow Generating (FS-GEN) that examines collaborative decoding between large and small language models, inspired by dual-process cognitive theory, and explores the efficiency and effectiveness of such interactions based on uncertainty in predictions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>When "Competency" in Reasoning Opens the Door to Vulnerability: Jailbreaking LLMs via Novel Complex Ciphers</title><link>https://arxiv.org/abs/2402.10601</link><description>https://arxiv.org/abs/2402.10601&lt;br /&gt;The paper presents the Fast and Slow Generating (FS-GEN) framework, which explores collaborative decoding between large language models (LLMs) and small language models (SLMs) inspired by dual-process cognitive theory, aiming to optimize performance and reduce issues like hallucinations and inference latency in language generation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Reinforcement Learning with Dynamic Multi-Reward Weighting for Multi-Style Controllable Generation</title><link>https://arxiv.org/abs/2402.14146</link><description>https://arxiv.org/abs/2402.14146&lt;br /&gt;This paper introduces the Fast and Slow Generating (FS-GEN) framework for collaborative decoding between Large Language Models (LLMs) and Small Language Models (SLMs), drawing on dual-process cognitive theory to analyze interactions between slow, deliberate systems and fast, intuitive systems, and establishes conditions for effective collaboration while highlighting the role of uncertainty in next-token predictions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions</title><link>https://arxiv.org/abs/2402.15055</link><description>https://arxiv.org/abs/2402.15055&lt;br /&gt;The paper proposes a unified framework called Fast and Slow Generating (FS-GEN) to analyze collaborative decoding between large and small language models, categorizing them based on dual-process cognitive theory and revealing optimal collaboration conditions to improve efficiency in generating language outputs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Mind's Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models</title><link>https://arxiv.org/abs/2404.03622</link><description>https://arxiv.org/abs/2404.03622&lt;br /&gt;This paper introduces the Fast and Slow Generating (FS-GEN) framework, which analyzes the collaborative decoding of large and small language models based on dual-process cognitive theory, highlighting the conditions under which their interactions can be optimized for improved performance in generating text while addressing issues like inference latency and hallucinations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Annotator-Centric Active Learning for Subjective NLP Tasks</title><link>https://arxiv.org/abs/2404.15720</link><description>https://arxiv.org/abs/2404.15720&lt;br /&gt;The paper proposes a unified framework called Fast and Slow Generating (FS-GEN) to analyze collaborative decoding methods between large and small language models, inspired by dual-process cognitive theory, highlighting the effectiveness of such collaborations while addressing challenges like inference latency and hallucinations.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Does Generative AI speak Nigerian-Pidgin?: Issues about Representativeness and Bias for Multilingualism in LLMs</title><link>https://arxiv.org/abs/2404.19442</link><description>https://arxiv.org/abs/2404.19442&lt;br /&gt;This paper presents the Fast and Slow Generating (FS-GEN) framework that analyzes collaborative decoding between Large Language Models (LLMs) and Small Language Models (SLMs), inspired by dual-process cognitive theory, highlighting their roles in mitigating issues like inference latency and hallucination generation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Token-wise Influential Training Data Retrieval for Large Language Models</title><link>https://arxiv.org/abs/2405.11724</link><description>https://arxiv.org/abs/2405.11724&lt;br /&gt;The paper presents a unified framework called Fast and Slow Generating (FS-GEN) for analyzing collaborative decoding between large and small language models (LLMs and SLMs), inspired by dual-process cognitive theory, which explores effective collaboration methods to mitigate issues like inference latency and hallucinations in LLMs.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Regularizing Hidden States Enables Learning Generalizable Reward Model for LLMs</title><link>https://arxiv.org/abs/2406.10216</link><description>https://arxiv.org/abs/2406.10216&lt;br /&gt;The paper presents the Fast and Slow Generating framework (FS-GEN), which analyzes the collaboration between large and small language models to mitigate issues like inference latency and hallucinations, drawing parallels to dual-process cognitive theory and identifying effective collaboration strategies based on uncertainty in predictions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding</title><link>https://arxiv.org/abs/2406.12295</link><description>https://arxiv.org/abs/2406.12295&lt;br /&gt;This paper explores the framework 'Fast and Slow Generating' (FS-GEN) for collaborative decoding between large and small language models, analyzing how these models can work together to reduce inference latency and improve generation accuracy by leveraging their respective strengths.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>RaTEScore: A Metric for Radiology Report Generation</title><link>https://arxiv.org/abs/2406.16845</link><description>https://arxiv.org/abs/2406.16845&lt;br /&gt;This paper explores the distinct security challenges introduced by Generative AI across various industries and suggests research directions for addressing these risks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding</title><link>https://arxiv.org/abs/2406.18925</link><description>https://arxiv.org/abs/2406.18925&lt;br /&gt;This paper examines the security challenges associated with the growing presence of Generative AI in various industries and proposes potential research avenues to address these risks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Attribute or Abstain: Large Language Models as Long Document Assistants</title><link>https://arxiv.org/abs/2407.07799</link><description>https://arxiv.org/abs/2407.07799&lt;br /&gt;This paper explores the unique security challenges posed by Generative AI across various industries and proposes potential research directions for addressing these risks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>NutriBench: A Dataset for Evaluating Large Language Models in Carbohydrate Estimation from Meal Descriptions</title><link>https://arxiv.org/abs/2407.12843</link><description>https://arxiv.org/abs/2407.12843&lt;br /&gt;This paper explores the unique security challenges posed by Generative AI across various industries and suggests potential research directions for mitigating these risks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer</title><link>https://arxiv.org/abs/2408.01119</link><description>https://arxiv.org/abs/2408.01119&lt;br /&gt;This paper explores the various security challenges associated with the increasing adoption of Generative AI across different industries and suggests potential research avenues to mitigate these risks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation</title><link>https://arxiv.org/abs/2409.15240</link><description>https://arxiv.org/abs/2409.15240&lt;br /&gt;This paper examines the unique security challenges posed by Generative AI across various industries and proposes potential research directions to manage these risks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Linear Adversarial Concept Erasure</title><link>https://arxiv.org/abs/2201.12091</link><description>https://arxiv.org/abs/2201.12091&lt;br /&gt;This paper examines the security challenges associated with the rise of Generative AI across various industries and proposes potential research directions for addressing these risks.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Learning to Poison Large Language Models During Instruction Tuning</title><link>https://arxiv.org/abs/2402.13459</link><description>https://arxiv.org/abs/2402.13459&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to represent and evaluate the origins of protein structures, distinguishing between experimentally resolved and computationally predicted structures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>From Keywords to Structured Summaries: Streamlining Scholarly Information Access</title><link>https://arxiv.org/abs/2402.14622</link><description>https://arxiv.org/abs/2402.14622&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model for protein representation and origin evaluation, designed to distinguish between experimentally resolved and computationally predicted protein structures by capturing inter-structural differences and enhancing structural representations based on encoded 'structure-sequences'.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Few-Shot Adversarial Prompt Learning on Vision-Language Models</title><link>https://arxiv.org/abs/2403.14774</link><description>https://arxiv.org/abs/2403.14774&lt;br /&gt;CPE-Pro is a structure-sensitive supervised deep learning method designed to accurately represent and evaluate the origins of protein structures, enhancing the ability to distinguish between experimentally resolved and computationally predicted structures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach</title><link>https://arxiv.org/abs/2404.15993</link><description>https://arxiv.org/abs/2404.15993&lt;br /&gt;CPE-Pro introduces a structure-sensitive deep learning model for accurate representation and origin evaluation of protein structures, significantly enhancing the understanding of protein functions and interactions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Characterizing the Accuracy -- Efficiency Trade-off of Low-rank Decomposition in Language Models</title><link>https://arxiv.org/abs/2405.06626</link><description>https://arxiv.org/abs/2405.06626&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to represent and evaluate the origins of protein structures by capturing inter-structural differences and enhancing structural representations through 'structure-sequences'.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language</title><link>https://arxiv.org/abs/2405.12856</link><description>https://arxiv.org/abs/2405.12856&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model that accurately represents and discriminates the origin of protein structures, enhancing the evaluation of prediction methods and biological studies using a novel 'structure-sequence' representation.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning</title><link>https://arxiv.org/abs/2406.05804</link><description>https://arxiv.org/abs/2406.05804&lt;br /&gt;CPE-Pro introduces a structure-sensitive deep learning model to accurately represent and evaluate the origins of protein structures, enhancing the discrimination between experimentally resolved and computationally predicted structures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>STAR: SocioTechnical Approach to Red Teaming Language Models</title><link>https://arxiv.org/abs/2406.11757</link><description>https://arxiv.org/abs/2406.11757&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to evaluate protein representations and distinguish between experimentally resolved and computationally predicted protein structures, improving the reliability of protein structure analysis.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CDQuant: Greedy Coordinate Descent for Accurate LLM Quantization</title><link>https://arxiv.org/abs/2406.17542</link><description>https://arxiv.org/abs/2406.17542&lt;br /&gt;CPE-Pro is a structure-sensitive supervised deep learning method designed to accurately represent and evaluate the origins of protein structures, distinguishing between experimentally resolved and computationally predicted structures to improve biological studies.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>I've Got 99 Problems But FLOPS Ain't One</title><link>https://arxiv.org/abs/2407.12819</link><description>https://arxiv.org/abs/2407.12819&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning method designed to represent and evaluate the origin of protein structures, improving the discrimination between experimentally resolved and computationally predicted structures and enhancing protein representation through 'structure-sequences'.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning</title><link>https://arxiv.org/abs/2407.15762</link><description>https://arxiv.org/abs/2407.15762&lt;br /&gt;CPE-Pro is a deep learning model designed to effectively represent and evaluate the origins of protein structures by distinguishing between experimentally resolved and computationally predicted structures, thereby enhancing structural representation in protein analysis.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning</title><link>https://arxiv.org/abs/2409.17270</link><description>https://arxiv.org/abs/2409.17270&lt;br /&gt;CPE-Pro is a structure-sensitive supervised deep learning model designed to accurately represent and discriminate the origin of protein structures, enhancing the understanding of their functions and interactions.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>FLAG: Financial Long Document Classification via AMR-based GNN</title><link>https://arxiv.org/abs/2410.02024</link><description>https://arxiv.org/abs/2410.02024&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed for protein representation and origin evaluation, which effectively discriminates between experimentally resolved and computationally predicted protein structures by learning structural information.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>TSDS: Data Selection for Task-Specific Model Finetuning</title><link>https://arxiv.org/abs/2410.11303</link><description>https://arxiv.org/abs/2410.11303&lt;br /&gt;CPE-Pro is a supervised deep learning model designed to accurately represent and evaluate the origins of protein structures by capturing inter-structural differences, thus improving upon current protein language models through 'structure-sequences'.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LocoMotion: Learning Motion-Focused Video-Language Representations</title><link>https://arxiv.org/abs/2410.12018</link><description>https://arxiv.org/abs/2410.12018&lt;br /&gt;CPE-Pro is a deep learning model designed to effectively represent and evaluate the origin of protein structures, enhancing the distinction between experimentally resolved and computationally predicted structures using structured information.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>CPE-Pro: A Structure-Sensitive Deep Learning Method for Protein Representation and Origin Evaluation</title><link>https://arxiv.org/abs/2410.15592</link><description>https://arxiv.org/abs/2410.15592&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to represent and evaluate the origin of protein structures, aiming to enhance the accuracy of differentiating between experimentally resolved and computationally predicted structures.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact</title><link>https://arxiv.org/abs/2410.17532</link><description>https://arxiv.org/abs/2410.17532&lt;br&gt;The study introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory to measure personality traits in LLM-generated text, enhancing understanding in Human-Computer Interaction and Human-Centered AI.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item><item><title>LMLPA: Language Model Linguistic Personality Assessment</title><link>https://arxiv.org/abs/2410.17632</link><description>https://arxiv.org/abs/2410.17632&lt;br&gt;LMLPA is a system designed to evaluate the linguistic personalities of Large Language Models (LLMs) using an adapted Big Five Inventory to quantitatively assess their personality traits based on linguistic outputs, contributing to the understanding of LLMs in Human-Computer Interaction.</description><pubDate>Thu, 24 Oct 2024 11:15:41 GMT</pubDate></item></channel></rss>