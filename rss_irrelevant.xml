<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Irrelevant arXiv Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss_irrelevant.xml</link><description>Irrelevant arXiv Papers</description><lastBuildDate>Fri, 08 Nov 2024 09:35:26 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Captions Speak Louder than Images (CASLIE): Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data</title><link>https://arxiv.org/abs/2410.17337</link><description>https://arxiv.org/abs/2410.17337&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) is a system that evaluates the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory for assessing distinct personality traits in their outputs, contributing to improved understanding and application of LLMs in conversational interactions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>AMUSD: Asynchronous Multi-Device Speculative Decoding for LLM Acceleration</title><link>https://arxiv.org/abs/2410.17375</link><description>https://arxiv.org/abs/2410.17375&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system for evaluating the linguistic personalities of Large Language Models (LLMs) through an adapted personality assessment questionnaire and AI rating methods, highlighting the distinct personality traits reflected in LLM outputs.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities</title><link>https://arxiv.org/abs/2410.17385</link><description>https://arxiv.org/abs/2410.17385&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) is introduced as a system to quantitatively evaluate the personality traits of Large Language Models (LLMs) using an adapted version of the Big Five Inventory, contributing to better understanding and integration of LLMs in various applications.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Scalable Influence and Fact Tracing for Large Language Model Pretraining</title><link>https://arxiv.org/abs/2410.17413</link><description>https://arxiv.org/abs/2410.17413&lt;br /&gt;The LMLPA (Language Model Linguistic Personality Assessment) introduces a system for quantifying the personality traits of Large Language Models (LLMs) based on their linguistic outputs, using an adapted version of the Big Five Inventory to measure distinct personality traits and contributing to the fields of Human-Computer Interaction and Human-Centered AI.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Evaluating AI-Generated Essays with GRE Analytical Writing Assessment</title><link>https://arxiv.org/abs/2410.17439</link><description>https://arxiv.org/abs/2410.17439&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system that quantitatively evaluates the distinct personality traits of Large Language Models (LLMs) by adapting the Big Five Inventory for their operational capabilities, facilitating a better understanding of their language generation capabilities in conversational interactions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>In Context Learning and Reasoning for Symbolic Regression with Large Language Models</title><link>https://arxiv.org/abs/2410.17448</link><description>https://arxiv.org/abs/2410.17448&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) is a system designed to evaluate the distinct personality traits of Large Language Models (LLMs) based on their linguistic outputs, adapting traditional psychometric assessments to effectively quantify these traits in an open-ended format.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination</title><link>https://arxiv.org/abs/2410.17477</link><description>https://arxiv.org/abs/2410.17477&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system for quantitatively evaluating the linguistic personality traits of Large Language Models (LLMs) based on their language outputs, adapting the Big Five Inventory for AI capabilities and providing insights into Human-Computer Interaction.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don't mimic the full human distribution</title><link>https://arxiv.org/abs/2410.17482</link><description>https://arxiv.org/abs/2410.17482&lt;br /&gt;LMLPA introduces a novel system for evaluating the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory for AI, allowing for the quantification of distinct personality traits reflected in their language generation outputs.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning</title><link>https://arxiv.org/abs/2410.17485</link><description>https://arxiv.org/abs/2410.17485&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a quantitative system for evaluating the linguistic personalities of Large Language Models (LLMs), adapting the Big Five Inventory to assess distinct personality traits based on LLM-generated outputs, which can enhance understanding in fields such as Human-Computer Interaction and Human-Centered AI.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Large Language Models Still Exhibit Bias in Long Text</title><link>https://arxiv.org/abs/2410.17519</link><description>https://arxiv.org/abs/2410.17519&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system for quantitatively assessing the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory into an open-ended questionnaire format, enabling evaluation of distinct personality traits reflected in LLM outputs and enhancing understanding of their conversational capabilities.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact</title><link>https://arxiv.org/abs/2410.17532</link><description>https://arxiv.org/abs/2410.17532&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system to evaluate the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory questionnaire to quantify distinct personality traits in their outputs, enhancing understanding of LLM conversational interactions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification</title><link>https://arxiv.org/abs/2410.17546</link><description>https://arxiv.org/abs/2410.17546&lt;br /&gt;The LMLPA is a system that quantitatively assesses the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory for evaluating their language generation capabilities, thereby enhancing understanding of their personality traits in conversational interactions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ESpeW: Robust Copyright Protection for LLM-based EaaS via Embedding-Specific Watermark</title><link>https://arxiv.org/abs/2410.17552</link><description>https://arxiv.org/abs/2410.17552&lt;br /&gt;LMLPA is a system that quantitatively assesses the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory for personality measurement, enabling a clearer understanding of LLMs' language generation capabilities through a novel framework that incorporates AI assessment methods.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective</title><link>https://arxiv.org/abs/2410.17600</link><description>https://arxiv.org/abs/2410.17600&lt;br /&gt;LMLPA introduces a system for assessing the linguistic personality traits of Large Language Models (LLMs) using a modified Big Five Inventory to evaluate their language generation capabilities in conversational interactions, contributing to fields like Human-Computer Interaction and Human-Centered AI.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LMLPA: Language Model Linguistic Personality Assessment</title><link>https://arxiv.org/abs/2410.17632</link><description>https://arxiv.org/abs/2410.17632&lt;br /&gt;The paper presents the Language Model Linguistic Personality Assessment (LMLPA), a system designed to evaluate the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory to quantitatively assess distinct personality traits in their outputs, thereby enhancing understanding in Human-Computer Interaction and Human-Centered AI.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents</title><link>https://arxiv.org/abs/2410.17657</link><description>https://arxiv.org/abs/2410.17657&lt;br /&gt;The paper analyzes historical texts from the German Bundestag using a time series variant of the topic model LDA to investigate the impact of significant events on the evolution of political discourse in Germany since the formation of the Federal Republic in 1949.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Quantifying the Risks of Tool-assisted Rephrasing to Linguistic Diversity</title><link>https://arxiv.org/abs/2410.17670</link><description>https://arxiv.org/abs/2410.17670&lt;br /&gt;The paper discusses an analysis of changes in the German political discourse from 1871 to the present using a time series variant of the topic model LDA applied to digitized transcripts of plenary sessions of the German Bundestag, highlighting key events that influenced the evolution of political discussions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Towards a Similarity-adjusted Surprisal Theory</title><link>https://arxiv.org/abs/2410.17676</link><description>https://arxiv.org/abs/2410.17676&lt;br /&gt;The paper analyzes the evolution of political discourse in Germany from historical events using a time series variant of the topic model LDA, examining changes in word frequency and key discussion points in the Bundestag sessions logged since 1949.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&amp;A Platforms</title><link>https://arxiv.org/abs/2410.17694</link><description>https://arxiv.org/abs/2410.17694&lt;br /&gt;The paper analyzes the evolution of political discourse in Germany from 1871 to the present using a time series variant of the topic model LDA on digitized records of Bundestag plenary sessions to identify significant events and changes in discussion points.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Beware of Calibration Data for Pruning Large Language Models</title><link>https://arxiv.org/abs/2410.17711</link><description>https://arxiv.org/abs/2410.17711&lt;br /&gt;The paper explores changes in German political discourse by analyzing digitized texts from Bundestag plenary sessions using a time series variant of LDA topic modeling to identify significant events and shifts in discussion topics over time.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>CogSteer: Cognition-Inspired Selective Layer Intervention for Efficient Semantic Steering in Large Language Models</title><link>https://arxiv.org/abs/2410.17714</link><description>https://arxiv.org/abs/2410.17714&lt;br /&gt;The paper 'Zeitenwenden' analyzes digitized transcripts of German Bundestag plenary sessions using a time series variant of the topic model LDA to identify significant events and changes in political discourse over time.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Dialectal and Low Resource Machine Translation for Aromanian</title><link>https://arxiv.org/abs/2410.17728</link><description>https://arxiv.org/abs/2410.17728&lt;br /&gt;The paper analyzes changes in German political discourse over time through a time series variant of the topic model LDA, using digitized records of plenary sessions from the Bundestag to identify events that have significantly affected political discussions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>MojoBench: Language Modeling and Benchmarks for Mojo</title><link>https://arxiv.org/abs/2410.17736</link><description>https://arxiv.org/abs/2410.17736&lt;br /&gt;The paper presents an analysis of the evolution of political discourse in Germany using a time series variant of the LDA topic model to detect changes in word frequency and key discussion points since the establishment of the Federal Republic of Germany in 1949.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Local Contrastive Editing of Gender Stereotypes</title><link>https://arxiv.org/abs/2410.17739</link><description>https://arxiv.org/abs/2410.17739&lt;br /&gt;The paper investigates the evolution of German political discourse from 1871 to the present by analyzing digitized transcripts of Bundestag sessions using a time series variant of topic modeling to identify significant changes in key discussion points over time.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Latent Structures of Intertextuality in French Fiction</title><link>https://arxiv.org/abs/2410.17759</link><description>https://arxiv.org/abs/2410.17759&lt;br /&gt;The paper analyzes digitized transcripts of German Bundestag plenary sessions using a time series variant of the topic model LDA to detect changes in political discourse and identify key discussion points influenced by historical events since 1949.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Leveraging the Domain Adaptation of Retrieval Augmented Generation Models for Question Answering and Reducing Hallucination</title><link>https://arxiv.org/abs/2410.17783</link><description>https://arxiv.org/abs/2410.17783&lt;br /&gt;The paper analyzes historical German political discourse from 1949 to the present by employing a time series variant of the topic model LDA to detect changes in key discussion points and word frequency in response to significant political events.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation</title><link>https://arxiv.org/abs/2410.17799</link><description>https://arxiv.org/abs/2410.17799&lt;br /&gt;The paper presents a time series analysis of political discourse in Germany using a topic model to investigate how key discussion points and word frequencies have changed over time in the German Bundestag, reflecting shifts from monarchy to democracy and other political transformations.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Understanding When Tree of Thoughts Succeeds: Larger Models Excel in Generation, Not Discrimination</title><link>https://arxiv.org/abs/2410.17820</link><description>https://arxiv.org/abs/2410.17820&lt;br /&gt;The paper analyzes the evolution of German political discourse since 1871 by employing a time series variant of topic modeling on digitized plenary session texts of the Bundestag to detect significant changes in political topics and key discussion points over time.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Understanding Layer Significance in LLM Alignment</title><link>https://arxiv.org/abs/2410.17875</link><description>https://arxiv.org/abs/2410.17875&lt;br /&gt;The paper analyzes the evolution of the German political discourse since the establishment of the Federal Republic of Germany in 1949 by employing a time series variant of the LDA topic model to detect significant changes in political topics and key discussion points over time, using digitized records of plenary sessions from the Bundestag.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>SpeakGer: A meta-data enriched speech corpus of German state and federal parliaments</title><link>https://arxiv.org/abs/2410.17886</link><description>https://arxiv.org/abs/2410.17886&lt;br /&gt;The paper analyzes historical texts from the German Bundestag using a time series variant of the LDA topic model to detect changes in political discourse and key discussion points over time in response to significant events.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Scaling Diffusion Language Models via Adaptation from Autoregressive Models</title><link>https://arxiv.org/abs/2410.17891</link><description>https://arxiv.org/abs/2410.17891&lt;br /&gt;The paper analyzes digitized plenary session texts from the German Bundestag since 1949 using a time series variant of topic modeling to detect changes in political discourse and the impact of historical events on political topics over time.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Value Residual Learning For Alleviating Attention Concentration In Transformers</title><link>https://arxiv.org/abs/2410.17897</link><description>https://arxiv.org/abs/2410.17897&lt;br /&gt;The paper analyzes changes in the German political discourse from 1871 to the present by employing a time series variant of the topic model LDA to examine digitized texts from every plenary session of the German Bundestag, focusing on how key political topics have evolved over time.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ELAICHI: Enhancing Low-resource TTS by Addressing Infrequent and Low-frequency Character Bigrams</title><link>https://arxiv.org/abs/2410.17901</link><description>https://arxiv.org/abs/2410.17901&lt;br /&gt;The paper presents an analysis of the German political discourse from 1871 to the present, leveraging a time series variant of the topic model LDA to identify how significant historical events have influenced changes in political discussions as reflected in the digitized texts of the German Bundestag.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>SimRAG: Self-Improving Retrieval-Augmented Generation for Adapting Large Language Models to Specialized Domains</title><link>https://arxiv.org/abs/2410.17952</link><description>https://arxiv.org/abs/2410.17952&lt;br /&gt;The paper investigates changes in the German political discourse from 1871 to the present by analyzing digitized plenary session texts of the Bundestag using a time series version of the LDA topic model to identify lasting effects of historical events on political discussions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Zeitenwenden: Detecting changes in the German political discourse</title><link>https://arxiv.org/abs/2410.17960</link><description>https://arxiv.org/abs/2410.17960&lt;br /&gt;The paper analyzes historical political discourse in Germany from 1871 to the present using a time series variant of topic modeling to detect changes in discussions and key topics influenced by significant political events.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Dependency Graph Parsing as Sequence Labeling</title><link>https://arxiv.org/abs/2410.17972</link><description>https://arxiv.org/abs/2410.17972&lt;br /&gt;This paper presents a time-aware approach, involving a CPI+DMC strategy, for the early detection of signs of anorexia, which emphasizes the integration of temporal metrics during the training process to enhance precision and speed in risk detection tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning</title><link>https://arxiv.org/abs/2410.18035</link><description>https://arxiv.org/abs/2410.18035&lt;br /&gt;The study presents a time-aware approach for the early detection of anorexia, focusing on both precision and speed through a CPI+DMC methodology and the integration of temporal metrics during the learning process.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Literature Meets Data: A Synergistic Approach to Hypothesis Generation</title><link>https://arxiv.org/abs/2410.17309</link><description>https://arxiv.org/abs/2410.17309&lt;br /&gt;This paper presents a time-aware approach for early detection of anorexia that emphasizes both precision and speed, utilizing a CPI+DMC method and integrating temporal factors during the learning process to improve risk detection metrics in the eRisk 2024 competition.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents</title><link>https://arxiv.org/abs/2410.17401</link><description>https://arxiv.org/abs/2410.17401&lt;br /&gt;The paper presents a time-aware method for the early detection of anorexia, utilizing a CPI+DMC approach and integrating time during the learning process to enhance precision and speed for risk detection on the web.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers</title><link>https://arxiv.org/abs/2410.17492</link><description>https://arxiv.org/abs/2410.17492&lt;br /&gt;This paper presents a time-aware approach for early detection of anorexia in the context of the eRisk 2024 competition, where the research group uses a CPI+DMC methodology to optimize both precision and speed in identifying risks online, successfully integrating temporal considerations into their model training and evaluation processes.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference</title><link>https://arxiv.org/abs/2410.17954</link><description>https://arxiv.org/abs/2410.17954&lt;br /&gt;This study proposes a time-aware approach for the early detection of anorexia that integrates precision and speed as a combined objective during the learning process, achieving significant results in the eRisk 2024 competition.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration</title><link>https://arxiv.org/abs/2410.18032</link><description>https://arxiv.org/abs/2410.18032&lt;br /&gt;The paper presents a unified framework called Fast and Slow Generating (FS-GEN) to analyze collaborative decoding between Large Language Models (LLMs) and Small Language Models (SLMs), offering insights into their distinct roles in improving inference speed and mitigating issues like hallucinations in language generation tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>CLEAR: Character Unlearning in Textual and Visual Modalities</title><link>https://arxiv.org/abs/2410.18057</link><description>https://arxiv.org/abs/2410.18057&lt;br /&gt;The paper presents a unified framework, Fast and Slow Generating (FS-GEN), analyzing collaborative decoding between large and small language models to address inference latency and hallucination issues, demonstrating that minimal interactions are necessary for effective collaboration while highlighting the distinct roles of 'slow' and 'fast' models in this process.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>TP-Eval: Tap Multimodal LLMs' Potential in Evaluation by Customizing Prompts</title><link>https://arxiv.org/abs/2410.18071</link><description>https://arxiv.org/abs/2410.18071&lt;br /&gt;The paper presents a unified framework called Fast and Slow Generating (FS-GEN) for collaborative decoding between Large Language Models (LLMs) and Small Language Models (SLMs), analyzing their respective roles in generating responses with a focus on optimizing performance and minimizing hallucinations through effective collaboration.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ALTA: Compiler-Based Analysis of Transformers</title><link>https://arxiv.org/abs/2410.18077</link><description>https://arxiv.org/abs/2410.18077&lt;br /&gt;This paper introduces the Fast and Slow Generating (FS-GEN) framework to analyze collaborative decoding strategies between large and small language models, categorizing them into Systems 1 and 2 based on their speed and cognitive approach, and providing insights into their interactions and effectiveness under uncertainty.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>GPT-SW3: An Autoregressive Language Model for the Nordic Languages</title><link>https://arxiv.org/abs/2305.12987</link><description>https://arxiv.org/abs/2305.12987&lt;br /&gt;The paper introduces the Fast and Slow Generating (FS-GEN) framework, which analyzes the collaborative decoding of large and small language models, identifying their roles and interactions under the dual-process cognitive theory while exploring the conditions that maximize their effective collaboration.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Let Me Teach You: Pedagogical Foundations of Feedback for Language Models</title><link>https://arxiv.org/abs/2307.00279</link><description>https://arxiv.org/abs/2307.00279&lt;br /&gt;The paper presents a unified framework, Fast and Slow Generating (FS-GEN), that analyzes collaborative decoding strategies between large and small language models, shedding light on their interaction dynamics and conditions for effectiveness based on dual-process cognitive theory.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications</title><link>https://arxiv.org/abs/2311.05876</link><description>https://arxiv.org/abs/2311.05876&lt;br /&gt;This paper introduces the Fast and Slow Generating (FS-GEN) framework to analyze and optimize collaborative decoding between Large Language Models (LLMs) and Small Language Models (SLMs), providing insights into their differential knowledge capabilities and the conditions for effective collaboration.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>The Causal Influence of Grammatical Gender on Distributional Semantics</title><link>https://arxiv.org/abs/2311.18567</link><description>https://arxiv.org/abs/2311.18567&lt;br /&gt;The paper proposes a unified framework called Fast and Slow Generating (FS-GEN) that explores the collaborative decoding between large and small language models to mitigate challenges such as inference latency and hallucinations, drawing inspiration from dual-process cognitive theory to categorize model interactions and analyze their effectiveness across various methodologies.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>TravelPlanner: A Benchmark for Real-World Planning with Language Agents</title><link>https://arxiv.org/abs/2402.01622</link><description>https://arxiv.org/abs/2402.01622&lt;br /&gt;The paper presents a unified framework called Fast and Slow Generating (FS-GEN) to analyze and optimize collaborative decoding between large and small language models, highlighting their respective roles and the conditions that enhance their cooperation in reducing issues like inference latency and hallucinations.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Reconfidencing LLMs from the Grouping Loss Perspective</title><link>https://arxiv.org/abs/2402.04957</link><description>https://arxiv.org/abs/2402.04957&lt;br /&gt;The paper introduces the Fast and Slow Generating (FS-GEN) framework to explore collaborative decoding between Large Language Models (LLMs) and small language models (SLMs), inspired by dual-process cognitive theory, and emphasizes how varying levels of collaboration can effectively reduce inference latency and enhance performance while managing the complexities of model interactions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>When "Competency" in Reasoning Opens the Door to Vulnerability: Jailbreaking LLMs via Novel Complex Ciphers</title><link>https://arxiv.org/abs/2402.10601</link><description>https://arxiv.org/abs/2402.10601&lt;br /&gt;The paper presents a unified framework called Fast and Slow Generating (FS-GEN) for understanding collaborative decoding between Large Language Models (LLMs) and small language models (SLMs), highlighting the dynamics of their interaction, particularly in managing uncertainty in token prediction.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Reinforcement Learning with Dynamic Multi-Reward Weighting for Multi-Style Controllable Generation</title><link>https://arxiv.org/abs/2402.14146</link><description>https://arxiv.org/abs/2402.14146&lt;br /&gt;This paper presents the Fast and Slow Generating (FS-GEN) framework, analyzing the collaborative decoding between Large Language Models (LLMs) and Small Language Models (SLMs) inspired by dual-process cognitive theory, and reveals effective conditions for their interaction to optimize performance amidst challenges like inference latency and hallucination generation.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions</title><link>https://arxiv.org/abs/2402.15055</link><description>https://arxiv.org/abs/2402.15055&lt;br /&gt;This paper presents the Fast and Slow Generating (FS-GEN) framework for collaborative decoding between large and small language models, inspired by dual-process cognitive theory, to mitigate issues such as inference latency and hallucinations by analyzing their differential knowledge capabilities.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Mind's Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models</title><link>https://arxiv.org/abs/2404.03622</link><description>https://arxiv.org/abs/2404.03622&lt;br /&gt;This paper presents the Fast and Slow Generating (FS-GEN) framework for collaborative decoding between large and small language models, highlighting their interactions and effectiveness in overcoming challenges like inference latency and hallucinations by categorizing them based on dual-process cognitive theory.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Bi-consolidating Model for Joint Relational Triple Extraction</title><link>https://arxiv.org/abs/2404.03881</link><description>https://arxiv.org/abs/2404.03881&lt;br /&gt;This paper introduces the Fast and Slow Generating (FS-GEN) framework, which analyzes collaborative decoding strategies between large and small language models to address challenges like inference latency and hallucinations, revealing that only a small fraction of interactions are needed for effective collaboration.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Annotator-Centric Active Learning for Subjective NLP Tasks</title><link>https://arxiv.org/abs/2404.15720</link><description>https://arxiv.org/abs/2404.15720&lt;br /&gt;The paper proposes the Fast and Slow Generating (FS-GEN) framework for collaborative decoding between large and small language models to address challenges in inference latency and hallucination generation, drawing on dual-process cognitive theory and exploring the effectiveness of such collaborations under various conditions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Does Generative AI speak Nigerian-Pidgin?: Issues about Representativeness and Bias for Multilingualism in LLMs</title><link>https://arxiv.org/abs/2404.19442</link><description>https://arxiv.org/abs/2404.19442&lt;br /&gt;The paper introduces a unified framework called Fast and Slow Generating (FS-GEN) that analyzes collaborative decoding between large language models (LLMs) and small language models (SLMs), informed by dual-process cognitive theory, to optimize performance by delineating their distinct roles in generating responses.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Token-wise Influential Training Data Retrieval for Large Language Models</title><link>https://arxiv.org/abs/2405.11724</link><description>https://arxiv.org/abs/2405.11724&lt;br /&gt;The paper introduces the Fast and Slow Generating (FS-GEN) framework, which analyzes collaborative decoding between large and small language models to address challenges like high inference latency and hallucinations, highlighting the effective interaction needed between the two systems.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Regularizing Hidden States Enables Learning Generalizable Reward Model for LLMs</title><link>https://arxiv.org/abs/2406.10216</link><description>https://arxiv.org/abs/2406.10216&lt;br /&gt;This paper presents the Fast and Slow Generating (FS-GEN) framework, which explores the collaborative decoding between large and small language models to mitigate issues like inference latency and hallucinations by drawing on dual-process cognitive theory to classify their interactions as either methodical or intuitive.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Fast and Slow Generating: An Empirical Study on Large and Small Language Models Collaborative Decoding</title><link>https://arxiv.org/abs/2406.12295</link><description>https://arxiv.org/abs/2406.12295&lt;br /&gt;The paper proposes a unified framework called Fast and Slow Generating (FS-GEN) to analyze the collaborative decoding between large and small language models, inspired by dual-process cognitive theory, wherein LLMs are seen as System 2 (slow and deliberate) and independent small language models as System 1 (fast and intuitive), assessing their interactions and the conditions for effective collaboration.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs</title><link>https://arxiv.org/abs/2406.14282</link><description>https://arxiv.org/abs/2406.14282&lt;br /&gt;The paper discusses the unique security challenges posed by Generative AI as it becomes more prevalent across various industries and outlines potential research directions to manage these risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics</title><link>https://arxiv.org/abs/2406.14703</link><description>https://arxiv.org/abs/2406.14703&lt;br /&gt;This paper explores the security challenges posed by Generative AI as its use expands across various industries, suggesting potential research directions for mitigating these risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>AlleNoise: large-scale text classification benchmark dataset with real-world label noise</title><link>https://arxiv.org/abs/2407.10992</link><description>https://arxiv.org/abs/2407.10992&lt;br /&gt;This paper discusses the unique security challenges associated with the rise of Generative AI in various industries and suggests potential research avenues to mitigate these risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>NutriBench: A Dataset for Evaluating Large Language Models in Carbohydrate Estimation from Meal Descriptions</title><link>https://arxiv.org/abs/2407.12843</link><description>https://arxiv.org/abs/2407.12843&lt;br /&gt;This paper addresses the unique security challenges posed by Generative AI and outlines potential research directions for managing these risks in various industries.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer</title><link>https://arxiv.org/abs/2408.01119</link><description>https://arxiv.org/abs/2408.01119&lt;br /&gt;The paper explores the security challenges associated with the rise of Generative AI across various industries and suggests potential research directions for addressing these risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Can Language Models Induce Grammatical Knowledge from Indirect Evidence?</title><link>https://arxiv.org/abs/2410.06022</link><description>https://arxiv.org/abs/2410.06022&lt;br /&gt;This paper explores the unique security challenges introduced by Generative AI across various industries and suggests potential research directions to manage these risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems</title><link>https://arxiv.org/abs/2410.13334</link><description>https://arxiv.org/abs/2410.13334&lt;br /&gt;This paper explores the security challenges associated with Generative AI and suggests potential research directions to mitigate these risks as its usage expands across various industries.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>On the Diversity of Synthetic Data and its Impact on Training Large Language Models</title><link>https://arxiv.org/abs/2410.15226</link><description>https://arxiv.org/abs/2410.15226&lt;br /&gt;This paper discusses the security challenges presented by Generative AI across various industries and suggests potential research directions for addressing these risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs</title><link>https://arxiv.org/abs/2410.15956</link><description>https://arxiv.org/abs/2410.15956&lt;br /&gt;This paper discusses the unique security challenges associated with Generative AI and proposes potential research directions to address these risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the U.S</title><link>https://arxiv.org/abs/2410.16451</link><description>https://arxiv.org/abs/2410.16451&lt;br /&gt;This paper explores the unique security challenges presented by Generative AI across various industries and suggests potential research directions to manage these risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Generative AI Security: Challenges and Countermeasures</title><link>https://arxiv.org/abs/2402.12617</link><description>https://arxiv.org/abs/2402.12617&lt;br /&gt;The paper discusses the unique security challenges posed by Generative AI as it becomes more prevalent across industries and outlines potential research directions for addressing these risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Learning to Poison Large Language Models During Instruction Tuning</title><link>https://arxiv.org/abs/2402.13459</link><description>https://arxiv.org/abs/2402.13459&lt;br /&gt;CPE-Pro is a structure-sensitive supervised deep learning model designed to accurately represent and evaluate the origins of protein structures, distinguishing between experimentally resolved and computationally predicted structures while enhancing protein feature learning through a newly developed 'structure-sequence'.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>From Keywords to Structured Summaries: Streamlining Scholarly Information Access</title><link>https://arxiv.org/abs/2402.14622</link><description>https://arxiv.org/abs/2402.14622&lt;br /&gt;CPE-Pro is a deep learning model designed to accurately evaluate and differentiate the origins of protein structures by learning structural information and inter-structural differences, thus enhancing the reliability of protein structure predictions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Few-Shot Adversarial Prompt Learning on Vision-Language Models</title><link>https://arxiv.org/abs/2403.14774</link><description>https://arxiv.org/abs/2403.14774&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to represent and evaluate the origins of protein structures, leveraging structural information to enhance discrimination between experimentally resolved and computationally predicted structures.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach</title><link>https://arxiv.org/abs/2404.15993</link><description>https://arxiv.org/abs/2404.15993&lt;br /&gt;CPE-Pro is a structure-sensitive supervised deep learning model designed to represent and evaluate the origin of protein structures, enhancing the traceability and reliability of protein structure predictions by utilizing structural sequence information.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Characterizing the Accuracy -- Efficiency Trade-off of Low-rank Decomposition in Language Models</title><link>https://arxiv.org/abs/2405.06626</link><description>https://arxiv.org/abs/2405.06626&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning method developed for accurately representing and evaluating the origin of protein structures, enhancing the distinction between experimentally resolved and computationally predicted structures through a supervised approach.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language</title><link>https://arxiv.org/abs/2405.12856</link><description>https://arxiv.org/abs/2405.12856&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to evaluate and represent protein structures, distinguishing between experimentally resolved and computationally predicted structures to enhance the understanding of their functions and interactions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Review of Prominent Paradigms for LLM-Based Agents: Tool Use (Including RAG), Planning, and Feedback Learning</title><link>https://arxiv.org/abs/2406.05804</link><description>https://arxiv.org/abs/2406.05804&lt;br /&gt;CPE-Pro introduces a structure-sensitive deep learning model for representing and evaluating protein structures, enhancing the discrimination of their origins and improving representation through the use of structural sequences.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>STAR: SocioTechnical Approach to Red Teaming Language Models</title><link>https://arxiv.org/abs/2406.11757</link><description>https://arxiv.org/abs/2406.11757&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to accurately represent and evaluate the origins of protein structures, improving upon existing methods by capturing inter-structural differences and incorporating structural information into its training.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>CDQuant: Greedy Coordinate Descent for Accurate LLM Quantization</title><link>https://arxiv.org/abs/2406.17542</link><description>https://arxiv.org/abs/2406.17542&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to accurately represent and evaluate the origin of protein structures, distinguishing between experimentally resolved and computationally predicted structures by learning structural information and inter-structural differences.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>I've Got 99 Problems But FLOPS Ain't One</title><link>https://arxiv.org/abs/2407.12819</link><description>https://arxiv.org/abs/2407.12819&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to accurately represent and discriminate the origins of protein structures, enhancing structural representations by utilizing 'structure-sequences' for improved learning of protein features.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning</title><link>https://arxiv.org/abs/2407.15762</link><description>https://arxiv.org/abs/2407.15762&lt;br /&gt;CPE-Pro is a structure-sensitive supervised deep learning model designed to evaluate and represent protein structures by discriminating their origins, improving the reliability of protein structure predictions and enhancing structural representations through 'structure-sequences'.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Proof of Thought : Neurosymbolic Program Synthesis allows Robust and Interpretable Reasoning</title><link>https://arxiv.org/abs/2409.17270</link><description>https://arxiv.org/abs/2409.17270&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to represent and evaluate the origin of protein structures, utilizing structure-sequences to enhance the learning of informative protein features compared to traditional language models focused on amino acid sequences.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>FLAG: Financial Long Document Classification via AMR-based GNN</title><link>https://arxiv.org/abs/2410.02024</link><description>https://arxiv.org/abs/2410.02024&lt;br /&gt;CPE-Pro is a deep learning method designed to accurately evaluate and represent protein structures, distinguishing between experimentally resolved and computationally predicted ones through a structure-sensitive approach that enhances the learning of informative features from protein structures.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>TSDS: Data Selection for Task-Specific Model Finetuning</title><link>https://arxiv.org/abs/2410.11303</link><description>https://arxiv.org/abs/2410.11303&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to accurately represent and evaluate the origins of protein structures, distinguishing between experimentally resolved and computationally predicted structures, thereby enhancing reliability in biological studies.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LocoMotion: Learning Motion-Focused Video-Language Representations</title><link>https://arxiv.org/abs/2410.12018</link><description>https://arxiv.org/abs/2410.12018&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to accurately represent and evaluate the origins of protein structures, enhancing the differentiation between experimentally resolved and computationally predicted structures and capturing inter-structural differences for improved traceability.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>BrainTransformers: SNN-LLM</title><link>https://arxiv.org/abs/2410.14687</link><description>https://arxiv.org/abs/2410.14687&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to accurately represent and evaluate the origin of protein structures, distinguishing between experimentally resolved and computationally predicted structures through enhanced structural information encoding.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>How to Evaluate Reward Models for RLHF</title><link>https://arxiv.org/abs/2410.14872</link><description>https://arxiv.org/abs/2410.14872&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to represent and evaluate the origin of protein structures, enhancing the accuracy of differentiating between experimentally resolved and computationally predicted structures using a new 'structure-sequence' approach.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Do Large Language Models Truly Grasp Mathematics? An Empirical Exploration</title><link>https://arxiv.org/abs/2410.14979</link><description>https://arxiv.org/abs/2410.14979&lt;br /&gt;CPE-Pro presents a structure-sensitive deep learning model for evaluating the origins of protein structures, enhancing the representation of structural information and improving the traceability of experimentally resolved versus computationally predicted structures.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>OpenMU: Your Swiss Army Knife for Music Understanding</title><link>https://arxiv.org/abs/2410.15573</link><description>https://arxiv.org/abs/2410.15573&lt;br /&gt;CPE-Pro is a structure-sensitive deep learning model designed to accurately represent and evaluate the origins of protein structures, enhancing the traceability between experimentally resolved and computationally predicted structures.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>CPE-Pro: A Structure-Sensitive Deep Learning Method for Protein Representation and Origin Evaluation</title><link>https://arxiv.org/abs/2410.15592</link><description>https://arxiv.org/abs/2410.15592&lt;br /&gt;CPE-Pro introduces a structure-sensitive deep learning model for evaluating and representing protein structures, enabling accurate discrimination between experimentally resolved and computationally predicted structures while enhancing protein feature learning through 'structure-sequences.'</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LLMScan: Causal Scan for LLM Misbehavior Detection</title><link>https://arxiv.org/abs/2410.16638</link><description>https://arxiv.org/abs/2410.16638&lt;br /&gt;This paper presents Predictive-Decoding, a novel method that enhances the planning accuracy of Large Language Models (LLMs) by applying Model Predictive Control to enable non-myopic reasoning and reduce early errors in task performance across various domains such as math and coding.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Non-myopic Generation of Language Model for Reasoning and Planning</title><link>https://arxiv.org/abs/2410.17195</link><description>https://arxiv.org/abs/2410.17195&lt;br /&gt;The paper presents Predictive-Decoding, a method that enhances the planning accuracy of Large Language Models by using Model Predictive Control to mitigate early errors and promote non-myopic reasoning in various tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Are Large Language Models Ready for Travel Planning?</title><link>https://arxiv.org/abs/2410.17333</link><description>https://arxiv.org/abs/2410.17333&lt;br /&gt;The paper presents a time-aware approach for early detection of anorexia by integrating temporal metrics during the learning process to improve precision and speed, achieving notable results in ERDE50 metrics at the eRisk 2024 challenge.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Intera\c{c}\~ao entre rob\^os humanoides: desenvolvendo a colabora\c{c}\~ao e comunica\c{c}\~ao aut\^onoma</title><link>https://arxiv.org/abs/2410.17450</link><description>https://arxiv.org/abs/2410.17450&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia using integrated time metrics and ERDE as a training objective, achieving high performance in precision and speed metrics in the eRisk 2024 competition.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Differentially Private Learning Needs Better Model Initialization and Self-Distillation</title><link>https://arxiv.org/abs/2410.17566</link><description>https://arxiv.org/abs/2410.17566&lt;br /&gt;The paper presents a time-aware approach using a CPI+DMC methodology for the early detection of anorexia, optimizing both precision and speed, and achieving outstanding results in the eRisk 2024 competition.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Large Language Models Reflect the Ideology of their Creators</title><link>https://arxiv.org/abs/2410.18417</link><description>https://arxiv.org/abs/2410.18417&lt;br /&gt;The paper introduces SPEED, a framework using small open-source models for efficient large-scale synthetic text embedding data generation, providing high-quality outputs with minimal reliance on expensive proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Can Code-Switched Texts Activate a Knowledge Switch in LLMs? A Case Study on English-Korean Code-Switching</title><link>https://arxiv.org/abs/2410.18436</link><description>https://arxiv.org/abs/2410.18436&lt;br /&gt;This paper introduces SPEED, a framework that uses small open-source models to efficiently generate large-scale synthetic embedding data, reducing reliance on expensive proprietary models like GPT-4 while outperforming state-of-the-art models such as E5_mistral.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Evaluating and Improving Automatic Speech Recognition Systems for Korean Meteorological Experts</title><link>https://arxiv.org/abs/2410.18444</link><description>https://arxiv.org/abs/2410.18444&lt;br /&gt;This paper presents SPEED, a framework for efficiently generating high-quality synthetic text embedding data using open-source small models, which reduces cost compared to proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities</title><link>https://arxiv.org/abs/2410.18469</link><description>https://arxiv.org/abs/2410.18469&lt;br /&gt;The paper introduces SPEED, a framework that enables small open-source models to efficiently generate high-quality synthetic embedding data at scale, significantly reducing reliance on expensive, proprietary systems.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Dialog2Flow: Pre-training Soft-Contrastive Action-Driven Sentence Embeddings for Automatic Dialog Flow Extraction</title><link>https://arxiv.org/abs/2410.18481</link><description>https://arxiv.org/abs/2410.18481&lt;br /&gt;The paper introduces SPEED, a framework designed to enable small open-source models to generate large-scale synthetic embedding data efficiently, reducing reliance on expensive proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ChineseSafe: A Chinese Benchmark for Evaluating Safety in Large Language Models</title><link>https://arxiv.org/abs/2410.18491</link><description>https://arxiv.org/abs/2410.18491&lt;br /&gt;The paper introduces SPEED, a framework to efficiently generate high-quality synthetic embedding data at scale using small open-source models, significantly reducing the need for costly proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>CCI3.0-HQ: a large-scale Chinese dataset of high quality designed for pre-training large language models</title><link>https://arxiv.org/abs/2410.18505</link><description>https://arxiv.org/abs/2410.18505&lt;br /&gt;The paper introduces SPEED, a framework that utilizes small open-source models to efficiently generate high-quality synthetic embedding data, reducing reliance on expensive proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Systematic Survey on Instructional Text: From Representation and Downstream NLP Tasks</title><link>https://arxiv.org/abs/2410.18529</link><description>https://arxiv.org/abs/2410.18529&lt;br /&gt;The paper introduces SPEED, a framework for synthesizing high-quality embedding data using small open-source models, significantly reducing costs compared to large proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>On Explaining with Attention Matrices</title><link>https://arxiv.org/abs/2410.18541</link><description>https://arxiv.org/abs/2410.18541&lt;br /&gt;The paper introduces SPEED, a framework for generating high-quality synthetic embedding data using small open-source models, reducing dependency on costly proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Infinity-MM: Scaling Multimodal Performance with Large-Scale and High-Quality Instruction Data</title><link>https://arxiv.org/abs/2410.18558</link><description>https://arxiv.org/abs/2410.18558&lt;br /&gt;The paper introduces SPEED, a framework using small open-source models to efficiently generate large-scale synthetic embedding data, reducing reliance on expensive proprietary models while still achieving high-quality outputs.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Bielik 7B v0.1: A Polish Language Model -- Development, Insights, and Evaluation</title><link>https://arxiv.org/abs/2410.18565</link><description>https://arxiv.org/abs/2410.18565&lt;br /&gt;The paper introduces SPEED, a framework for generating high-quality synthetic embedding data using open-source models for efficient model training, reducing reliance on expensive proprietary models.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Difficult for Whom? A Study of Japanese Lexical Complexity</title><link>https://arxiv.org/abs/2410.18567</link><description>https://arxiv.org/abs/2410.18567&lt;br /&gt;The paper introduces SPEED, a framework to efficiently generate high-quality synthetic embedding data using open-source models, significantly reducing reliance on expensive proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Taipan: Efficient and Expressive State Space Language Models with Selective Attention</title><link>https://arxiv.org/abs/2410.18572</link><description>https://arxiv.org/abs/2410.18572&lt;br /&gt;The paper presents SPEED, a framework for efficiently generating high-quality synthetic embedding data at scale using small open-source models, significantly reducing dependence on expensive proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Prompting and Fine-Tuning of Small LLMs for Length-Controllable Telephone Call Summarization</title><link>https://arxiv.org/abs/2410.18624</link><description>https://arxiv.org/abs/2410.18624&lt;br /&gt;The paper introduces SPEED, a framework that enables small open-source models to generate large-scale, high-quality synthetic embedding data efficiently, reducing reliance on expensive proprietary models like GPT-4.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Supporting Assessment of Novelty of Design Problems Using Concept of Problem SAPPhIRE</title><link>https://arxiv.org/abs/2410.18629</link><description>https://arxiv.org/abs/2410.18629&lt;br /&gt;The paper introduces SPEED, a framework for using open-source small models to efficiently generate large-scale synthetic embedding data, outperforming traditional models like E5_mistral while using fewer resources.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Little Giants: Synthesizing High-Quality Embedding Data at Scale</title><link>https://arxiv.org/abs/2410.18634</link><description>https://arxiv.org/abs/2410.18634&lt;br /&gt;The paper introduces SPEED, a framework for efficiently generating high-quality synthetic embedding data using small open-source models, significantly reducing reliance on costly models like GPT-4, and outperforms state-of-the-art models using its synthetic data.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Weak-to-Strong Preference Optimization: Stealing Reward from Weak Aligned Model</title><link>https://arxiv.org/abs/2410.18640</link><description>https://arxiv.org/abs/2410.18640&lt;br /&gt;The paper proposes a method for improving the efficiency of large language models (LLMs) during inference by dynamically pruning the vocabulary for token predictions at intermediate layers, thereby maintaining performance while enhancing computational efficiency.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Towards Better Open-Ended Text Generation: A Multicriteria Evaluation Framework</title><link>https://arxiv.org/abs/2410.18653</link><description>https://arxiv.org/abs/2410.18653&lt;br /&gt;The paper introduces a method for dynamic vocabulary pruning in early-exit LLMs, enhancing inference efficiency by reducing the computational cost of confidence estimation without compromising performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Unleashing Reasoning Capability of LLMs via Scalable Question Synthesis from Scratch</title><link>https://arxiv.org/abs/2410.18693</link><description>https://arxiv.org/abs/2410.18693&lt;br /&gt;The paper proposes a method for improving the efficiency of large language model (LLM) inference by dynamically pruning the vocabulary during early-exit scenarios, which enhances decision-making efficiency without compromising performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>How Good Are LLMs for Literary Translation, Really? Literary Translation Evaluation with Humans and LLMs</title><link>https://arxiv.org/abs/2410.18697</link><description>https://arxiv.org/abs/2410.18697&lt;br /&gt;The paper explores dynamic vocabulary pruning techniques in early-exit large language models to improve inference efficiency while maintaining performance by reducing the vocabulary size used for confidence estimation at intermediate layers.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning</title><link>https://arxiv.org/abs/2410.18702</link><description>https://arxiv.org/abs/2410.18702&lt;br /&gt;The paper introduces a method for enhancing the efficiency of large language models (LLMs) by dynamically pruning vocabulary at test time to expedite inference without compromising performance in early-exit models.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Why Does the Effective Context Length of LLMs Fall Short?</title><link>https://arxiv.org/abs/2410.18745</link><description>https://arxiv.org/abs/2410.18745&lt;br /&gt;The paper introduces FaultyMath, a benchmark dataset for evaluating the logical reasoning capabilities of large language models (LLMs) on faulty mathematical problems, demonstrating that many LLMs act as 'Blind Solvers' and lack the reasoning capabilities necessary to identify and explain logical inconsistencies.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Does Differential Privacy Impact Bias in Pretrained NLP Models?</title><link>https://arxiv.org/abs/2410.18749</link><description>https://arxiv.org/abs/2410.18749&lt;br /&gt;This paper introduces a dynamic vocabulary pruning technique for large language models that enhances inference efficiency by reducing the computational costs associated with large vocabulary sizes during early-exit token predictions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Task Calibration: Calibrating Large Language Models on Inference Tasks</title><link>https://arxiv.org/abs/2410.18764</link><description>https://arxiv.org/abs/2410.18764&lt;br /&gt;The paper introduces a method for improving the efficiency of large language model (LLM) inference by dynamically pruning the vocabulary during early-exiting, enhancing computational efficiency while maintaining performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Distill Visual Chart Reasoning Ability from LLMs to MLLMs</title><link>https://arxiv.org/abs/2410.18798</link><description>https://arxiv.org/abs/2410.18798&lt;br /&gt;The paper introduces a method for dynamic vocabulary pruning to enhance the efficiency of inference in early-exiting large language models (LLMs) without degrading performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Delving into the Reversal Curse: How Far Can Large Language Models Generalize?</title><link>https://arxiv.org/abs/2410.18808</link><description>https://arxiv.org/abs/2410.18808&lt;br /&gt;The paper introduces dynamic vocabulary pruning in early-exit large language models (LLMs) to enhance inference efficiency by reducing computational cost without compromising performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>From Imitation to Introspection: Probing Self-Consciousness in Language Models</title><link>https://arxiv.org/abs/2410.18819</link><description>https://arxiv.org/abs/2410.18819&lt;br /&gt;The paper introduces dynamic vocabulary pruning in early-exit large language models (LLMs) to improve inference efficiency by reducing vocabulary size during intermediate-layer predictions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>From English-Centric to Effective Bilingual: LLMs with Custom Tokenizers for Underrepresented Languages</title><link>https://arxiv.org/abs/2410.18836</link><description>https://arxiv.org/abs/2410.18836&lt;br /&gt;The paper introduces dynamic vocabulary pruning in early-exit large language models (LLMs) to enhance inference efficiency by reducing the computational cost of confidence estimation while maintaining performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>We Augmented Whisper With kNN and You Won't Believe What Came Next</title><link>https://arxiv.org/abs/2410.18850</link><description>https://arxiv.org/abs/2410.18850&lt;br /&gt;The paper explores dynamic vocabulary pruning in large language models to improve inference efficiency without compromising performance by reducing vocabulary size early in the processing layers.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations</title><link>https://arxiv.org/abs/2410.18860</link><description>https://arxiv.org/abs/2410.18860&lt;br /&gt;The paper proposes a method for enhancing the efficiency of LLM inference by dynamically pruning the vocabulary during test time to reduce computational cost while maintaining performance in early-exit models.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Survey of Multimodal Sarcasm Detection</title><link>https://arxiv.org/abs/2410.18882</link><description>https://arxiv.org/abs/2410.18882&lt;br /&gt;The paper introduces a benchmark dataset, FaultyMath, to evaluate and analyze the reasoning capabilities of large language models (LLMs) by presenting them with faulty mathematical problems, revealing that most LLMs act as 'Blind Solvers' and lack the deeper reasoning skills of 'Logical Thinkers'.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Are LLMs Better than Reported? Detecting Label Errors and Mitigating Their Effect on Model Performance</title><link>https://arxiv.org/abs/2410.18889</link><description>https://arxiv.org/abs/2410.18889&lt;br /&gt;The paper explores dynamic vocabulary pruning in large language models (LLMs) to enhance efficiency during inference by reducing vocabulary size at early layers while maintaining performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LLMs for Extremely Low-Resource Finno-Ugric Languages</title><link>https://arxiv.org/abs/2410.18902</link><description>https://arxiv.org/abs/2410.18902&lt;br /&gt;The paper introduces a benchmark dataset, FaultyMath, to evaluate large language models (LLMs) on their ability to detect flaws in math problems, revealing that existing LLMs primarily act as 'Blind Solvers' rather than 'Logical Thinkers' capable of identifying logical inconsistencies.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>PRISM: A Methodology for Auditing Biases in Large Language Models</title><link>https://arxiv.org/abs/2410.18906</link><description>https://arxiv.org/abs/2410.18906&lt;br /&gt;The paper introduces dynamic vocabulary pruning in early-exit large language models (LLMs) to enhance inference efficiency by reducing computational overhead during token prediction without sacrificing performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical Integrity on Faulty Mathematical Problems</title><link>https://arxiv.org/abs/2410.18921</link><description>https://arxiv.org/abs/2410.18921&lt;br /&gt;The paper proposes dynamically pruning the vocabulary of large language models during inference to improve the efficiency of early-exiting LLMs without compromising performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Dynamic Vocabulary Pruning in Early-Exit LLMs</title><link>https://arxiv.org/abs/2410.18952</link><description>https://arxiv.org/abs/2410.18952&lt;br /&gt;The paper proposes a benchmark dataset, FaultyMath, to evaluate large language models' ability to detect and reason about inconsistencies in math problems, revealing that current models frequently function as 'Blind Solvers' rather than 'Logical Thinkers'.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Bridge-Coder: Unlocking LLMs' Potential to Overcome Language Gaps in Low-Resource Code</title><link>https://arxiv.org/abs/2410.18957</link><description>https://arxiv.org/abs/2410.18957&lt;br /&gt;The paper introduces CoreInfer, an adaptive sparse activation method for large language models to improve inference efficiency without degrading performance by activating only essential neurons based on sentence-level prediction.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions</title><link>https://arxiv.org/abs/2410.18966</link><description>https://arxiv.org/abs/2410.18966&lt;br /&gt;CoreInfer introduces an MLP-free adaptive sparse activation method for accelerating large language model inference by identifying critical core neurons based on sentence semantics, achieving significant speedups without degrading performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>$M^3EL$: A Multi-task Multi-topic Dataset for Multi-modal Entity Linking</title><link>https://arxiv.org/abs/2410.18096</link><description>https://arxiv.org/abs/2410.18096&lt;br /&gt;CoreInfer is a novel adaptive sparse activation method for accelerating LLM inference by using sentence-level core neurons to maintain performance while reducing computational cost and memory demands.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Gesture2Text: A Generalizable Decoder for Word-Gesture Keyboards in XR Through Trajectory Coarse Discretization and Pre-training</title><link>https://arxiv.org/abs/2410.18099</link><description>https://arxiv.org/abs/2410.18099&lt;br /&gt;WAFFLE is a multi-modal model for automating front-end development by fine-tuning large language models to better translate UI designs into accurate HTML through structure-aware attention and contrastive fine-tuning strategies.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>RingGesture: A Ring-Based Mid-Air Gesture Typing System Powered by a Deep-Learning Word Prediction Framework</title><link>https://arxiv.org/abs/2410.18100</link><description>https://arxiv.org/abs/2410.18100&lt;br /&gt;This paper introduces CoreInfer, a method that uses adaptive sparse activation for efficient inference in large language models, leveraging sentence-level semantic predictions to significantly accelerate computational performance without sacrificing accuracy.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Improving Embedding Accuracy for Document Retrieval Using Entity Relationship Maps and Model-Aware Contrastive Sampling</title><link>https://arxiv.org/abs/2410.18105</link><description>https://arxiv.org/abs/2410.18105&lt;br /&gt;CoreInfer introduces an adaptive sparse activation inference method that speeds up large language model inference by using sentence-level prediction of core neurons, improving efficiency on resource-constrained devices.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Yesterday's News: Benchmarking Multi-Dimensional Out-of-Distribution Generalisation of Misinformation Detection Models</title><link>https://arxiv.org/abs/2410.18122</link><description>https://arxiv.org/abs/2410.18122&lt;br /&gt;WAFFLE introduces a fine-tuning strategy with a structure-aware attention mechanism and contrastive fine-tuning to enhance LLMs' ability to generate HTML code from UI designs, addressing challenges of HTML structure representation and alignment with visual designs.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Optimizing Preference Alignment with Differentiable NDCG Ranking</title><link>https://arxiv.org/abs/2410.18127</link><description>https://arxiv.org/abs/2410.18127&lt;br /&gt;The paper introduces WAFFLE, a multi-modal model that improves the conversion of UI designs to HTML code by addressing hierarchical and representation challenges using a structure-aware attention mechanism and contrastive fine-tuning.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Graph Contrastive Learning via Cluster-refined Negative Sampling for Semi-supervised Text Classification</title><link>https://arxiv.org/abs/2410.18130</link><description>https://arxiv.org/abs/2410.18130&lt;br /&gt;WAFFLE is a novel fine-tuning strategy for Large Language Models (LLMs) that uses structure-aware attention and contrastive fine-tuning to improve the generation of HTML code from UI designs.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Tethering Broken Themes: Aligning Neural Topic Models with Labels and Authors</title><link>https://arxiv.org/abs/2410.18140</link><description>https://arxiv.org/abs/2410.18140&lt;br /&gt;WAFFLE introduces a multi-modal model for automated front-end development that improves UI-to-HTML code generation by enhancing LLMs' understanding of HTML structures and bridging the gap between visual UI designs and text-based HTML.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>SmartRAG: Jointly Learn RAG-Related Tasks From the Environment Feedback</title><link>https://arxiv.org/abs/2410.18141</link><description>https://arxiv.org/abs/2410.18141&lt;br /&gt;WAFFLE introduces a fine-tuning strategy with a structure-aware attention mechanism and contrastive fine-tuning to improve LLMs in generating HTML code from UI designs, enhancing understanding of HTML structures and aligning visual designs with code.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ZIP-FIT: Embedding-Free Data Selection via Compression-Based Alignment</title><link>https://arxiv.org/abs/2410.18194</link><description>https://arxiv.org/abs/2410.18194&lt;br /&gt;WAFFLE is a multi-modal fine-tuning strategy to improve Large Language Models (LLMs) for generating HTML code from UI designs, enhancing their understanding of HTML structures and aligning UI images with text-based code.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Advancing NLP Security by Leveraging LLMs as Adversarial Engines</title><link>https://arxiv.org/abs/2410.18215</link><description>https://arxiv.org/abs/2410.18215&lt;br /&gt;WAFFLE is a multi-modal model that enhances LLMs' ability to convert UI designs into HTML code by using a structure-aware attention mechanism and contrastive fine-tuning, improving code generation accuracy and alignment with visual inputs.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Optimizing the role of human evaluation in LLM-based spoken document summarization systems</title><link>https://arxiv.org/abs/2410.18218</link><description>https://arxiv.org/abs/2410.18218&lt;br /&gt;WAFFLE introduces a fine-tuning strategy to enhance large language models' capability in UI-to-HTML code generation by employing structure-aware attention and contrastive learning to better understand HTML's structure and align visual UI designs with text-based HTML.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Asynchronous RLHF: Faster and More Efficient Off-Policy RL for Language Models</title><link>https://arxiv.org/abs/2410.18252</link><description>https://arxiv.org/abs/2410.18252&lt;br /&gt;This paper introduces WAFFLE, a multi-modal model that enhances LLMs for automated UI-to-HTML code generation by employing a structure-aware attention mechanism and a contrastive fine-tuning approach to align visual UI designs with HTML code.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Kenyan Sign Language (KSL) Dataset: Using Artificial Intelligence (AI) in Bridging Communication Barrier among the Deaf Learners</title><link>https://arxiv.org/abs/2410.18295</link><description>https://arxiv.org/abs/2410.18295&lt;br /&gt;CoreInfer introduces an MLP-free adaptive sparse activation inference method for large language models, leveraging sentence-level neuron predictions to accelerate model inference by activating only the most critical neurons, thereby optimizing resource use and improving speed without performance loss.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Robust and Explainable Depression Identification from Speech Using Vowel-Based Ensemble Learning Approaches</title><link>https://arxiv.org/abs/2410.18298</link><description>https://arxiv.org/abs/2410.18298&lt;br /&gt;CoreInfer is an inference method for large language models that accelerates computation by using adaptive sparse activation based on sentence-level semantic prediction to determine core neurons, improving efficiency without degrading performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>CoreInfer: Accelerating Large Language Model Inference with Semantics-Inspired Adaptive Sparse Activation</title><link>https://arxiv.org/abs/2410.18311</link><description>https://arxiv.org/abs/2410.18311&lt;br /&gt;CoreInfer introduces a method for accelerating large language models via sentence-level adaptive sparse activation, focusing on semantic-inspired core neuron selection to improve inference efficiency.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>WAFFLE: Multi-Modal Model for Automated Front-End Development</title><link>https://arxiv.org/abs/2410.18362</link><description>https://arxiv.org/abs/2410.18362&lt;br /&gt;WAFFLE improves LLMs' ability to generate HTML code from UI designs using a structure-aware attention mechanism to handle HTML's hierarchical nature and a contrastive fine-tuning approach to align the understanding of visual UI and HTML code.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ADELIE: Aligning Large Language Models on Information Extraction</title><link>https://arxiv.org/abs/2405.05008</link><description>https://arxiv.org/abs/2405.05008&lt;br /&gt;This paper presents a scaling law model for neural language models that integrates learning rate annealing, offering a way to predict validation loss across training steps for various learning rate schedulers, thereby reducing computational costs and providing insights into training dynamics.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>RE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation</title><link>https://arxiv.org/abs/2406.05794</link><description>https://arxiv.org/abs/2406.05794&lt;br /&gt;This paper introduces a scaling law with learning rate annealing for neural language models, allowing for accurate prediction of validation loss at any training step, thereby improving computational efficiency in formulating scaling laws and understanding LLM training dynamics.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation</title><link>https://arxiv.org/abs/2406.07054</link><description>https://arxiv.org/abs/2406.07054&lt;br /&gt;The paper introduces a scaling law that incorporates learning rate annealing to predict the loss throughout the training steps of neural language models, providing insights into optimizing training dynamics and strategies.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Evaluation of Language Models in the Medical Context Under Resource-Constrained Settings</title><link>https://arxiv.org/abs/2406.16611</link><description>https://arxiv.org/abs/2406.16611&lt;br /&gt;This paper introduces a scaling law for cross-entropy loss in neural language models, accounting for learning rate annealing over training steps, which enhances understanding of training dynamics and provides a theoretical framework to predict loss under various learning rate schedules.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention</title><link>https://arxiv.org/abs/2407.00377</link><description>https://arxiv.org/abs/2407.00377&lt;br /&gt;The paper investigates a scaling law that describes the cross-entropy loss curves of neural language models during training, incorporating learning rate annealing to predict training dynamics, thus enhancing understanding and efficiency of large language model training.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning</title><link>https://arxiv.org/abs/2407.04528</link><description>https://arxiv.org/abs/2407.04528&lt;br /&gt;The paper introduces a scaling law for neural language model training that incorporates learning rate annealing, offering an accurate prediction of validation loss at any step across different learning rate schedulers, thereby reducing computational costs and providing insights into training dynamics.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Rule Extrapolation in Language Models: A Study of Compositional Generalization on OOD Prompts</title><link>https://arxiv.org/abs/2409.13728</link><description>https://arxiv.org/abs/2409.13728&lt;br /&gt;This survey provides a comprehensive overview of the progress and future directions in Low-Rank Adaptation (LoRA) for large language models, focusing on improving downstream adaptation, cross-task generalization, efficiency, data privacy, and various applications.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LongGenBench: Long-context Generation Benchmark</title><link>https://arxiv.org/abs/2410.04199</link><description>https://arxiv.org/abs/2410.04199&lt;br /&gt;This survey provides a comprehensive overview of Low-Rank Adaptation (LoRA) in large language models, focusing on improvements for downstream tasks, cross-task generalization, efficiency, and data privacy, while also discussing future directions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ScienceAgentBench: Toward Rigorous Assessment of Language Agents for Data-Driven Scientific Discovery</title><link>https://arxiv.org/abs/2410.05080</link><description>https://arxiv.org/abs/2410.05080&lt;br /&gt;This survey provides a comprehensive overview of Low-Rank Adaptation (LoRA) methods for fine-tuning large language models, highlighting advancements in downstream adaptation, cross-task generalization, efficiency improvements, and privacy preservation.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering</title><link>https://arxiv.org/abs/2410.07095</link><description>https://arxiv.org/abs/2410.07095&lt;br /&gt;The paper surveys the advances and applications of Low-Rank Adaptation (LoRA) in large language models, highlighting its efficiency, cross-task generalization, and privacy-preserving capabilities.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Scalable Multi-Domain Adaptation of Language Models using Modular Experts</title><link>https://arxiv.org/abs/2410.10181</link><description>https://arxiv.org/abs/2410.10181&lt;br /&gt;This survey provides a comprehensive overview of the advancements in Low-Rank Adaptation (LoRA) for Large Language Models, highlighting its improvements in downstream task performance, cross-task generalization, efficiency, and data privacy, and discussing future research directions.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>PortLLM: Personalizing Evolving Large Language Models with Training-Free and Portable Model Patches</title><link>https://arxiv.org/abs/2410.10870</link><description>https://arxiv.org/abs/2410.10870&lt;br /&gt;This survey provides a comprehensive overview of the Low-Rank Adaptation (LoRA) approach for efficiently fine-tuning large language models, covering advancements in downstream tasks, cross-task generalization, efficiency improvements, and privacy preservation.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ChuLo: Chunk-Level Key Information Representation for Long Document Processing</title><link>https://arxiv.org/abs/2410.11119</link><description>https://arxiv.org/abs/2410.11119&lt;br /&gt;This survey paper reviews the progress and applications of Low-Rank Adaptation (LoRA) in fine-tuning large language models, focusing on its downstream adaptation, cross-task generalization, computational efficiency, and privacy-preserving methods.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>"Is Hate Lost in Translation?": Evaluation of Multilingual LGBTQIA+ Hate Speech Detection</title><link>https://arxiv.org/abs/2410.11230</link><description>https://arxiv.org/abs/2410.11230&lt;br /&gt;This survey comprehensively reviews the progress of Low-Rank Adaptation (LoRA) in improving parameter-efficient fine-tuning of large language models, covering aspects such as downstream adaptation, cross-task generalization, efficiency, and privacy-preserving capabilities.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Novel Interpretability Metric for Explaining Bias in Language Models: Applications on Multilingual Models from Southeast Asia</title><link>https://arxiv.org/abs/2410.15464</link><description>https://arxiv.org/abs/2410.15464&lt;br /&gt;This paper provides a comprehensive overview of Low-Rank Adaptation (LoRA) in large language models, highlighting its use in parameter-efficient fine-tuning, cross-task generalization, and privacy-preservation.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Learning Mathematical Rules with Large Language Models</title><link>https://arxiv.org/abs/2410.16973</link><description>https://arxiv.org/abs/2410.16973&lt;br /&gt;This survey provides a comprehensive overview of Low-Rank Adaptation (LoRA) methods for large language models, highlighting advancements in downstream task performance, cross-task generalization, efficiency, data privacy, and various applications.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Efficient End-to-end Language Model Fine-tuning on Graphs</title><link>https://arxiv.org/abs/2312.04737</link><description>https://arxiv.org/abs/2312.04737&lt;br /&gt;The paper provides a comprehensive overview of Low-Rank Adaptation (LoRA) in large language models, highlighting its efficiency in fine-tuning, cross-task generalization, and data privacy-preserving applications.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Large Language Model for Table Processing: A Survey</title><link>https://arxiv.org/abs/2402.05121</link><description>https://arxiv.org/abs/2402.05121&lt;br /&gt;This survey provides an overview of Low-Rank Adaptation (LoRA) in large language models, highlighting advancements in performance, cross-task generalization, efficiency, and privacy preservation, along with future directions in this field.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>FlashSpeech: Efficient Zero-Shot Speech Synthesis</title><link>https://arxiv.org/abs/2404.14700</link><description>https://arxiv.org/abs/2404.14700&lt;br /&gt;The survey provides a comprehensive overview of Low-Rank Adaptation (LoRA) in large language models, focusing on its applications, efficiency, cross-task generalization, and privacy-preserving capabilities.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Taming Data and Transformers for Audio Generation</title><link>https://arxiv.org/abs/2406.19388</link><description>https://arxiv.org/abs/2406.19388&lt;br /&gt;This survey provides a comprehensive overview of the Low-Rank Adaptation (LoRA) technique for large language models, covering its performance on various downstream tasks, cross-task generalization, efficiency improvements, and data privacy applications.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Survey on LoRA of Large Language Models</title><link>https://arxiv.org/abs/2407.11046</link><description>https://arxiv.org/abs/2407.11046&lt;br /&gt;This survey provides a comprehensive overview of Low-Rank Adaptation (LoRA) techniques in large language models, focusing on improvements in parameter efficiency, cross-task generalization, and privacy preservation.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>GCoder: Improving Large Language Model for Generalized Graph Problem Solving</title><link>https://arxiv.org/abs/2410.19084</link><description>https://arxiv.org/abs/2410.19084&lt;br /&gt;This paper presents a method to enhance Large Language Models (LLMs) for mathematics problem-solving by integrating text and number embeddings, employing expressive numerical embeddings and a routing layer to improve handling of numerical data and reduce artefacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LLM Tree Search</title><link>https://arxiv.org/abs/2410.19117</link><description>https://arxiv.org/abs/2410.19117&lt;br /&gt;The paper introduces a novel approach to integrate text and number embeddings in Large Language Models (LLMs) using expressive numerical embeddings and a routing layer to enhance the mathematical problem-solving capability, with reduced numerical artifacts and biases.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Read-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design</title><link>https://arxiv.org/abs/2410.19123</link><description>https://arxiv.org/abs/2410.19123&lt;br /&gt;This paper introduces a method that interleaves numerical and text embeddings in large language models (LLMs) to improve their ability to handle numerical data and solve mathematical problems, while reducing numerical artifacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Retrieving Implicit and Explicit Emotional Events Using Large Language Models</title><link>https://arxiv.org/abs/2410.19128</link><description>https://arxiv.org/abs/2410.19128&lt;br /&gt;The paper introduces a method to integrate text and number embeddings in Large Language Models (LLMs) by using expressive numerical embeddings and a routing layer, improving their capacity for arithmetic tasks without numerical artefacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback</title><link>https://arxiv.org/abs/2410.19133</link><description>https://arxiv.org/abs/2410.19133&lt;br /&gt;This paper introduces a method to improve the integration of text and number embeddings in LLMs to enhance their capability in solving mathematical problems, using distinct numerical directions and a routing layer that separates numerical and text embeddings.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>AlignCap: Aligning Speech Emotion Captioning to Human Preferences</title><link>https://arxiv.org/abs/2410.19134</link><description>https://arxiv.org/abs/2410.19134&lt;br /&gt;The paper introduces a method for integrating text and number embeddings in Large Language Models (LLMs) to improve their capability in solving mathematical problems, by assigning distinct directions to numerical embeddings and distinguishing between numerical and text embeddings using a routing layer, achieving high accuracy with reduced numerical artefacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Lived Experience Not Found: LLMs Struggle to Align with Experts on Addressing Adverse Drug Reactions from Psychiatric Medication Use</title><link>https://arxiv.org/abs/2410.19155</link><description>https://arxiv.org/abs/2410.19155&lt;br /&gt;The paper introduces a method that integrates text and number embeddings for Large Language Models (LLMs) by introducing a routing layer and more expressive numerical embeddings, which improves performance and reduces numerical artefacts in solving mathematics problems.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>No Argument Left Behind: Overlapping Chunks for Faster Processing of Arbitrarily Long Legal Texts</title><link>https://arxiv.org/abs/2410.19184</link><description>https://arxiv.org/abs/2410.19184&lt;br /&gt;This research introduces a method that integrates expressive numerical embeddings with text embeddings in language models to improve arithmetic operations, achieving high accuracy and reducing numerical artifacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Enriching GNNs with Text Contextual Representations for Detecting Disinformation Campaigns on Social Media</title><link>https://arxiv.org/abs/2410.19193</link><description>https://arxiv.org/abs/2410.19193&lt;br /&gt;The paper introduces an approach that integrates text and number embeddings through expressive numerical embeddings and a routing layer in an LLM to enhance its capacity for arithmetic operations and reduce numerical artifacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Label Set Optimization via Activation Distribution Kurtosis for Zero-shot Classification with Generative Models</title><link>https://arxiv.org/abs/2410.19195</link><description>https://arxiv.org/abs/2410.19195&lt;br /&gt;The paper introduces an approach that enhances Large Language Models (LLMs) by integrating expressive numerical embeddings to better solve mathematics problems, using a multi-layer perceptron for embedding directions and a routing layer to differentiate between text and numerical embeddings.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Can Stories Help LLMs Reason? Curating Information Space Through Narrative</title><link>https://arxiv.org/abs/2410.19221</link><description>https://arxiv.org/abs/2410.19221&lt;br /&gt;This paper introduces an approach that integrates text and number embeddings to enhance the capability of Large Language Models in solving mathematics problems by employing an MLP for distinct numerical embeddings and a routing layer to separate numerical and text embeddings, thus reducing numerical artifacts and biases.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Developing a Tutoring Dialog Dataset to Optimize LLMs for Educational Use</title><link>https://arxiv.org/abs/2410.19231</link><description>https://arxiv.org/abs/2410.19231&lt;br /&gt;The paper proposes a hybrid embedding approach that interleaves text and number embeddings using an MLP and a routing layer to improve the handling of mathematical problems in large language models, enabling better differentiation between text and numerical data while reducing numerical artefacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>The Reopening of Pandora's Box: Analyzing the Role of LLMs in the Evolving Battle Against AI-Generated Fake News</title><link>https://arxiv.org/abs/2410.19250</link><description>https://arxiv.org/abs/2410.19250&lt;br /&gt;This paper introduces a method for enhancing Large Language Models (LLMs) by interleaving text and number embeddings using an MLP and routing layer, effectively handling a wide range of numerical magnitudes and reducing numerical artefacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning</title><link>https://arxiv.org/abs/2410.19258</link><description>https://arxiv.org/abs/2410.19258&lt;br /&gt;The paper proposes a method to integrate text and number embeddings in Large Language Models using distinct directions for numbers and a routing layer to improve arithmetic capabilities and reduce numerical artefacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Fictitious Synthetic Data Can Improve LLM Factuality via Prerequisite Learning</title><link>https://arxiv.org/abs/2410.19290</link><description>https://arxiv.org/abs/2410.19290&lt;br /&gt;This paper presents a novel method for integrating text and number embeddings in Large Language Models (LLMs) by using distinct numerical encoding and a routing layer, significantly improving arithmetic problem-solving capabilities while reducing artefacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Any Other Thoughts, Hedgehog? Linking Deliberation Chains in Collaborative Dialogues</title><link>https://arxiv.org/abs/2410.19301</link><description>https://arxiv.org/abs/2410.19301&lt;br /&gt;This paper presents a method that integrates more expressive numerical embeddings into Large Language Models (LLMs) to improve their performance in arithmetic tasks by effectively handling a broad range of numerical magnitudes and reducing numerical artefacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs</title><link>https://arxiv.org/abs/2410.19317</link><description>https://arxiv.org/abs/2410.19317&lt;br /&gt;The paper introduces a method combining interleaved text and number embeddings with a routing layer, enhancing LLMs' handling of numerical magnitudes and reducing artefacts in mathematical problems.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Two are better than one: Context window extension with multi-grained self-injection</title><link>https://arxiv.org/abs/2410.19318</link><description>https://arxiv.org/abs/2410.19318&lt;br /&gt;The paper presents a new method for integrating text and numerical embeddings in Large Language Models to enhance their capacity for solving mathematics problems, eliminating numerical artefacts and handling a wide range of magnitudes effectively.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios</title><link>https://arxiv.org/abs/2410.19346</link><description>https://arxiv.org/abs/2410.19346&lt;br /&gt;This paper introduces new numerical embeddings and a routing layer that enhance the ability of large language models to integrate text and numbers effectively, improving their capability to handle diverse magnitudes without numerical artefacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Interleaving Text and Number Embeddings to Solve Mathemathics Problems</title><link>https://arxiv.org/abs/2410.19353</link><description>https://arxiv.org/abs/2410.19353&lt;br /&gt;The paper introduces an innovative approach to interleave text and number embeddings in LLMs to improve their performance on mathematical tasks by using a multi-layer perceptron for distinct numerical embedding directions and a routing layer to differentiate between numerical and text data, significantly reducing numerical artifacts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Investigating the Role of Prompting and External Tools in Hallucination Rates of Large Language Models</title><link>https://arxiv.org/abs/2410.19385</link><description>https://arxiv.org/abs/2410.19385&lt;br /&gt;The paper reports on an innovative real-time exploration approach called the O1 Replication Journey, which aims to replicate the capabilities of OpenAI's O1 model, emphasizing openness, transparency, and real-time updates in AI research, and introduces 'journey learning' that improves performance on reasoning tasks like the MATH dataset.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>KAHANI: Culturally-Nuanced Visual Storytelling Pipeline for Non-Western Cultures</title><link>https://arxiv.org/abs/2410.19419</link><description>https://arxiv.org/abs/2410.19419&lt;br /&gt;The paper introduces a transparent and strategic approach to AI research through the O1 Replication Journey, aimed at replicating OpenAI's O1 model capabilities while promoting open science by documenting the entire research process in real-time.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Intelligent Understanding of Large Language Models in Traditional Chinese Medicine Based on Prompt Engineering Framework</title><link>https://arxiv.org/abs/2410.19451</link><description>https://arxiv.org/abs/2410.19451&lt;br /&gt;Stick-breaking Attention introduces an alternative attention mechanism for transformers using a stick-breaking process to allocate attention weights, aiming to improve length generalization and perform competitively with existing methods in self-attention tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework</title><link>https://arxiv.org/abs/2410.19453</link><description>https://arxiv.org/abs/2410.19453&lt;br /&gt;The paper reports on the O1 Replication Journey, which is an open and transparent effort to replicate OpenAI's O1 model, emphasizing open science and iterative learning, and demonstrating the journey learning paradigm that significantly improves performance on tasks like the MATH dataset.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Debate-Driven Experiment on LLM Hallucinations and Accuracy</title><link>https://arxiv.org/abs/2410.19485</link><description>https://arxiv.org/abs/2410.19485&lt;br /&gt;This paper presents an innovative methodology for AI research called 'journey learning', demonstrated through the transparent and real-time replication of OpenAI's O1 model, which aims to enhance scientific discovery by encouraging models to learn through exploration and documentation of the research process.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Graph Linearization Methods for Reasoning on Graphs with Large Language Models</title><link>https://arxiv.org/abs/2410.19494</link><description>https://arxiv.org/abs/2410.19494&lt;br /&gt;The O1 Replication Journey explores a novel approach to AI research by replicating the capabilities of OpenAI's O1 model through a transparent and collaborative real-time process that improves upon traditional methodologies and demonstrates significant performance gains with journey learning.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Introducing MAPO: Momentum-Aided Gradient Descent Prompt Optimization</title><link>https://arxiv.org/abs/2410.19499</link><description>https://arxiv.org/abs/2410.19499&lt;br /&gt;The paper presents O1 Replication Journey, a transparent AI research initiative aimed at replicating OpenAI's O1 model capabilities by promoting open science and iterative learning, demonstrating its potential to outperform traditional supervised learning methods.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>SWITCH: Studying with Teacher for Knowledge Distillation of Large Language Models</title><link>https://arxiv.org/abs/2410.19503</link><description>https://arxiv.org/abs/2410.19503&lt;br /&gt;O1 Replication Journey explores a new approach to AI research by attempting to replicate OpenAI's O1 model and promoting open science and transparency in research processes, while demonstrating the potential of journey learning, which outperformed conventional supervised learning on the MATH dataset.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Detection of Human and Machine-Authored Fake News in Urdu</title><link>https://arxiv.org/abs/2410.19517</link><description>https://arxiv.org/abs/2410.19517&lt;br /&gt;The paper introduces the O1 Replication Journey, a transparent real-time process focused on replicating OpenAI's O1 model capabilities and promoting open-science in AI research, showcasing the journey learning paradigm that significantly improves performance on the MATH dataset.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ChunkRAG: Novel LLM-Chunk Filtering Method for RAG Systems</title><link>https://arxiv.org/abs/2410.19572</link><description>https://arxiv.org/abs/2410.19572&lt;br /&gt;The paper reports on the O1 Replication Journey, a transparent approach to replicating the capabilities of OpenAI's O1 model by documenting real-time progress and introducing the journey learning paradigm, which significantly improves learning on complex datasets like MATH by simulating a complete exploration process.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization</title><link>https://arxiv.org/abs/2410.19609</link><description>https://arxiv.org/abs/2410.19609&lt;br /&gt;The paper discusses a novel approach called the O1 Replication Journey, which aims to replicate the capabilities of OpenAI's O1 model through transparent and community-engaged research, introducing the journey learning paradigm that improves learning by exploring and documenting the entire research process.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A distributional simplicity bias in the learning dynamics of transformers</title><link>https://arxiv.org/abs/2410.19637</link><description>https://arxiv.org/abs/2410.19637&lt;br /&gt;The paper presents the O1 Replication Journey, which aims to replicate the capabilities of OpenAI's O1 model while promoting transparency, open science, and continuous updates throughout AI research, highlighting a novel 'journey learning' paradigm that outperforms conventional methods on the MATH dataset.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ProvocationProbe: Instigating Hate Speech Dataset from Twitter</title><link>https://arxiv.org/abs/2410.19687</link><description>https://arxiv.org/abs/2410.19687&lt;br /&gt;The O1 Replication Journey explores a new approach to AI research by transparently documenting the process of replicating OpenAI's O1 model, emphasizing open science, real-time updates, and a journey learning paradigm that outperforms traditional methods on the MATH dataset.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>AGENT-CQ: Automatic Generation and Evaluation of Clarifying Questions for Conversational Search with LLMs</title><link>https://arxiv.org/abs/2410.19692</link><description>https://arxiv.org/abs/2410.19692&lt;br /&gt;The O1 Replication Journey outlines a new approach to AI research by transparently documenting efforts to replicate OpenAI's O1 model, emphasizing open science, team collaboration, and establishing a journey learning paradigm that outperforms traditional methods in the MATH dataset.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Less is More: Extreme Gradient Boost Rank-1 Adaption for Efficient Finetuning of LLMs</title><link>https://arxiv.org/abs/2410.19694</link><description>https://arxiv.org/abs/2410.19694&lt;br /&gt;The paper proposes the stick-breaking attention mechanism as an alternative to traditional softmax-based self-attention to improve length generalization and downstream task performance in language models by incorporating a linguistic recency bias.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>2D-DPO: Scaling Direct Preference Optimization with 2-Dimensional Supervision</title><link>https://arxiv.org/abs/2410.19720</link><description>https://arxiv.org/abs/2410.19720&lt;br /&gt;The paper reports on an innovative approach to AI research called O1 Replication Journey, emphasizing open science and real-time documentation of efforts to replicate OpenAI's O1 model while introducing the journey learning paradigm for improved model performance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Counting Ability of Large Language Models and Impact of Tokenization</title><link>https://arxiv.org/abs/2410.19730</link><description>https://arxiv.org/abs/2410.19730&lt;br /&gt;The paper introduces a novel approach to AI research through the O1 Replication Journey, promoting open science and transparency by documenting their process of replicating the O1 model's capabilities and demonstrating the potential of journey learning to improve learning outcomes.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models</title><link>https://arxiv.org/abs/2410.19732</link><description>https://arxiv.org/abs/2410.19732&lt;br /&gt;The paper introduces the O1 Replication Journey, a transparent and real-time AI research approach to replicate OpenAI's O1 model, emphasizing open science and collective advancement through a journey learning paradigm that outperforms conventional methods on the MATH dataset.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Stick-breaking Attention</title><link>https://arxiv.org/abs/2410.17980</link><description>https://arxiv.org/abs/2410.17980&lt;br /&gt;The paper presents the O1 Replication Journey, a pioneering real-time exploration methodology to replicate and enhance OpenAI's O1 model capabilities, focusing on collective advancement and transparency in AI research, with a new 'journey learning' paradigm that outperforms traditional learning on complex tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>O1 Replication Journey: A Strategic Progress Report -- Part 1</title><link>https://arxiv.org/abs/2410.18982</link><description>https://arxiv.org/abs/2410.18982&lt;br /&gt;The paper introduces the O1 Replication Journey, a project aimed at replicating and transparently documenting the development of the O1 AI model to promote open science and collaborative advancements in AI research, specifically emphasizing a journey learning paradigm for AI models.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Infogent: An Agent-Based Framework for Web Information Aggregation</title><link>https://arxiv.org/abs/2410.19054</link><description>https://arxiv.org/abs/2410.19054&lt;br /&gt;The paper investigates the impact of pruning on large language models for abstractive summarization and finds that pruned models exhibit fewer hallucinations by relying more on the source document, thus increasing lexical overlap and reducing hallucination risks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Watermarking Large Language Models and the Generated Content: Opportunities and Challenges</title><link>https://arxiv.org/abs/2410.19096</link><description>https://arxiv.org/abs/2410.19096&lt;br /&gt;The paper investigates the effects of pruning on hallucinations in generative large language models for abstractive summarization, finding that pruned models tend to produce fewer hallucinations by depending more on the source document.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Test of Time: Predicting the Sustainable Success of Online Collaboration in Wikipedia</title><link>https://arxiv.org/abs/2410.19150</link><description>https://arxiv.org/abs/2410.19150&lt;br /&gt;The paper investigates the impact of pruning on large language models' tendency to hallucinate in abstractive summarization, finding that pruned models tend to rely more on the source document, reducing hallucinations.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Humanizing the Machine: Proxy Attacks to Mislead LLM Detectors</title><link>https://arxiv.org/abs/2410.19230</link><description>https://arxiv.org/abs/2410.19230&lt;br /&gt;The paper investigates how pruning affects hallucinations in large language models used for abstractive summarization, finding that pruned models exhibit fewer hallucinations due to increased reliance on source documents.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Revealing and Reducing Gender Biases in Vision and Language Assistants (VLAs)</title><link>https://arxiv.org/abs/2410.19314</link><description>https://arxiv.org/abs/2410.19314&lt;br /&gt;This paper explores the impact of pruning on large language models in the context of abstractive summarization, finding that pruned models exhibit fewer hallucinations by relying more on source documents.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning</title><link>https://arxiv.org/abs/2410.19727</link><description>https://arxiv.org/abs/2410.19727&lt;br /&gt;The paper investigates the impact of pruning on hallucinations in large language models used for abstractive summarization, finding that pruned models may reduce hallucinations by relying more on source documents.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Investigating Hallucinations in Pruned Large Language Models for Abstractive Summarization</title><link>https://arxiv.org/abs/2311.09335</link><description>https://arxiv.org/abs/2311.09335&lt;br /&gt;This paper investigates how pruning large language models affects hallucinations in abstractive summarization, finding that pruned models generally hallucinate less due to their increased reliance on source documents.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LLMRefine: Pinpointing and Refining Large Language Models via Fine-Grained Actionable Feedback</title><link>https://arxiv.org/abs/2311.09336</link><description>https://arxiv.org/abs/2311.09336&lt;br /&gt;This paper explores the effectiveness of data augmentation methods in improving confidence calibration and uncertainty estimation for Named Entity Recognition (NER) tasks, particularly in cross-genre and cross-lingual settings, highlighting the importance of sentence perplexity in these methods.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>README: Bridging Medical Jargon and Lay Understanding for Patient Education through Data-Centric NLP</title><link>https://arxiv.org/abs/2312.15561</link><description>https://arxiv.org/abs/2312.15561&lt;br /&gt;The paper examines the impact of data augmentation on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, revealing improvements in model calibration and uncertainty estimation across various settings.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>West-of-N: Synthetic Preferences for Self-Improving Reward Models</title><link>https://arxiv.org/abs/2401.12086</link><description>https://arxiv.org/abs/2401.12086&lt;br /&gt;The paper explores the impacts of data augmentation on confidence calibration and uncertainty estimation in Named Entity Recognition (NER), showing its positive effects especially in cross-genre and cross-lingual settings.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through Process Feedback</title><link>https://arxiv.org/abs/2402.01469</link><description>https://arxiv.org/abs/2402.01469&lt;br /&gt;The paper investigates the effectiveness of data augmentation in improving confidence calibration and uncertainty estimation for Named Entity Recognition (NER) tasks, particularly in safety-critical fields, by enhancing the predictions of Deep Neural Networks including Pre-trained Language Models.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Democratizing Large Language Models via Personalized Parameter-Efficient Fine-tuning</title><link>https://arxiv.org/abs/2402.04401</link><description>https://arxiv.org/abs/2402.04401&lt;br /&gt;The paper investigates how data augmentation impacts confidence calibration and uncertainty estimation in Named Entity Recognition tasks, particularly enhancing calibration when sentence perplexity is low.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>On the Robustness of Editing Large Language Models</title><link>https://arxiv.org/abs/2402.05827</link><description>https://arxiv.org/abs/2402.05827&lt;br /&gt;The paper investigates the impact of data augmentation on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, emphasizing its effectiveness in improving calibration in cross-genre and cross-lingual settings.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Grasping the Essentials: Tailoring Large Language Models for Zero-Shot Relation Extraction</title><link>https://arxiv.org/abs/2402.11142</link><description>https://arxiv.org/abs/2402.11142&lt;br /&gt;The paper investigates the effectiveness of data augmentation methods for improving confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, highlighting their potential benefits in cross-genre and cross-lingual settings using Deep Neural Networks (DNNs).</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Can GPT Improve the State of Prior Authorization via Guideline Based Automated Question Answering?</title><link>https://arxiv.org/abs/2402.18419</link><description>https://arxiv.org/abs/2402.18419&lt;br /&gt;This paper investigates the impact of data augmentation on improving confidence calibration and uncertainty estimation in Named Entity Recognition (NER), emphasizing its potential applications in safety-critical fields.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models</title><link>https://arxiv.org/abs/2403.00953</link><description>https://arxiv.org/abs/2403.00953&lt;br /&gt;This study explores the effectiveness of data augmentation methods on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, emphasizing improvements in calibration and uncertainty, especially in cross-genre and cross-lingual settings.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Skews in the Phenomenon Space Hinder Generalization in Text-to-Image Generation</title><link>https://arxiv.org/abs/2403.16394</link><description>https://arxiv.org/abs/2403.16394&lt;br /&gt;This paper evaluates the effectiveness of data augmentation methods in improving confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, especially in cross-genre and cross-lingual settings.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple Candidates for Efficient and Effective Retrieval</title><link>https://arxiv.org/abs/2405.12801</link><description>https://arxiv.org/abs/2405.12801&lt;br /&gt;This paper explores the impact of data augmentation on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, finding that it enhances calibration and uncertainty, especially in cross-genre and cross-lingual settings.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical Machine Reading Comprehension</title><link>https://arxiv.org/abs/2405.18682</link><description>https://arxiv.org/abs/2405.18682&lt;br /&gt;The paper explores the effects of data augmentation methods on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, highlighting improvements in calibration accuracy when using data augmentation, especially in cross-genre and cross-lingual contexts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Language Models Need Inductive Biases to Count Inductively</title><link>https://arxiv.org/abs/2405.20131</link><description>https://arxiv.org/abs/2405.20131&lt;br /&gt;This paper explores the effectiveness of data augmentation methods in improving confidence calibration and uncertainty estimation for Named Entity Recognition (NER) tasks, particularly in the context of deep neural networks' application in safety-critical domains like healthcare and finance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Transformers need glasses! Information over-squashing in language tasks</title><link>https://arxiv.org/abs/2406.04267</link><description>https://arxiv.org/abs/2406.04267&lt;br /&gt;The paper investigates data augmentation's effectiveness in improving confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, particularly in safety-critical fields.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Personalized Pieces: Efficient Personalized Large Language Models through Collaborative Efforts</title><link>https://arxiv.org/abs/2406.10471</link><description>https://arxiv.org/abs/2406.10471&lt;br /&gt;This paper examines the effectiveness of data augmentation methods for improving confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, particularly for applications in safety-critical fields like healthcare and finance.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>PerSEval: Assessing Personalization in Text Summarizers</title><link>https://arxiv.org/abs/2407.00453</link><description>https://arxiv.org/abs/2407.00453&lt;br /&gt;This paper investigates the impact of data augmentation on confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, highlighting improvements in cross-genre and cross-lingual settings and emphasizing the effectiveness of lower perplexity sentence augmentations.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?</title><link>https://arxiv.org/abs/2407.02062</link><description>https://arxiv.org/abs/2407.02062&lt;br /&gt;This paper assesses the applicability of data augmentation methods for improving confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, particularly for safety-critical applications, finding enhancements in various settings through increased augmented data size.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition</title><link>https://arxiv.org/abs/2407.04559</link><description>https://arxiv.org/abs/2407.04559&lt;br /&gt;The paper presents LoReKT, a framework to improve low-resource knowledge tracing tasks using supervised pre-training and an importance mechanism for fine-tuning, which prioritizes parameter updates that have high importance, achieving superior performance on multiple datasets.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>One Stone, Four Birds: A Comprehensive Solution for QA System Using Supervised Contrastive Learning</title><link>https://arxiv.org/abs/2407.09011</link><description>https://arxiv.org/abs/2407.09011&lt;br /&gt;The paper proposes LoReKT, a framework using supervised pre-training and importance mechanism fine-tuning to enhance deep learning-based knowledge tracing tasks in low-resource settings, demonstrating improved student knowledge mastery estimation.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Representational Analysis of Binding in Language Models</title><link>https://arxiv.org/abs/2409.05448</link><description>https://arxiv.org/abs/2409.05448&lt;br /&gt;This paper introduces LoReKT, a low-resource knowledge tracing framework that leverages supervised pre-training and importance mechanism fine-tuning to effectively adapt deep learning models in low-resource scenarios, thereby improving AUC and accuracy on KT tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Adversarial Multi-Agent Evaluation of Large Language Models through Iterative Debates</title><link>https://arxiv.org/abs/2410.04663</link><description>https://arxiv.org/abs/2410.04663&lt;br /&gt;The paper presents LoReKT, a framework that improves deep learning-based knowledge tracing tasks in low-resource settings through supervised pre-training on rich-resource datasets and importance mechanism fine-tuning.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>As Simple as Fine-tuning: LLM Alignment via Bidirectional Negative Feedback Loss</title><link>https://arxiv.org/abs/2410.04834</link><description>https://arxiv.org/abs/2410.04834&lt;br /&gt;The paper presents LoReKT, a framework for improving low-resource knowledge tracing tasks by leveraging supervised pre-training from high-resource datasets and fine-tuning with an importance mechanism to prevent overfitting.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Rationale-Aware Answer Verification by Pairwise Self-Evaluation</title><link>https://arxiv.org/abs/2410.04838</link><description>https://arxiv.org/abs/2410.04838&lt;br /&gt;This paper introduces the LoReKT framework to enhance knowledge tracing tasks in low-resource settings by using supervised pre-training and importance mechanism fine-tuning on deep learning models.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization</title><link>https://arxiv.org/abs/2410.08815</link><description>https://arxiv.org/abs/2410.08815&lt;br /&gt;The paper proposes a low-resource knowledge tracing framework called LoReKT, which utilizes a pre-training and fine-tuning approach with a simplified transformer model to enhance performance on low-resource datasets by learning transferable parameters from rich-resource sources.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models</title><link>https://arxiv.org/abs/2410.12851</link><description>https://arxiv.org/abs/2410.12851&lt;br /&gt;The paper presents LoReKT, a framework that enhances low-resource knowledge tracing tasks by applying supervised pre-training and an importance mechanism for fine-tuning, enabling more effective adaptation from rich-resource datasets to low-resource contexts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>BanTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla</title><link>https://arxiv.org/abs/2410.13281</link><description>https://arxiv.org/abs/2410.13281&lt;br /&gt;The paper presents a low-resource knowledge tracing framework named LoReKT, utilizing supervised pre-training and importance mechanism fine-tuning to improve knowledge tracing tasks where student interaction data is limited.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LoGU: Long-form Generation with Uncertainty Expressions</title><link>https://arxiv.org/abs/2410.14309</link><description>https://arxiv.org/abs/2410.14309&lt;br /&gt;The paper presents LoReKT, a framework that enhances performance on low-resource knowledge tracing tasks through supervised pre-training and fine-tuning with an importance mechanism.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>SPRIG: Improving Large Language Model Performance by System Prompt Optimization</title><link>https://arxiv.org/abs/2410.14826</link><description>https://arxiv.org/abs/2410.14826&lt;br /&gt;The study introduces LoReKT, a framework utilizing supervised pre-training and an importance mechanism for effective adaptation of deep learning models to low-resource knowledge tracing tasks, addressing challenges such as privacy and data scarcity.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Steering Knowledge Selection Behaviours in LLMs via SAE-Based Representation Engineering</title><link>https://arxiv.org/abs/2410.15999</link><description>https://arxiv.org/abs/2410.15999&lt;br /&gt;The paper presents LoReKT, a framework designed to improve knowledge tracing (KT) tasks in low-resource settings by leveraging supervised pre-training on richly-resourced datasets and importance mechanism fine-tuning to enhance model performance using limited data.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications</title><link>https://arxiv.org/abs/2402.05162</link><description>https://arxiv.org/abs/2402.05162&lt;br /&gt;The study proposes LoReKT, a framework that utilizes supervised pre-training and an importance mechanism for fine-tuning to improve knowledge tracing tasks in low-resource settings by leveraging transferable parameters from rich-resource datasets.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Measuring memorization in RLHF for code completion</title><link>https://arxiv.org/abs/2406.11715</link><description>https://arxiv.org/abs/2406.11715&lt;br /&gt;GeoAgent is a new interactive framework that enhances Large Language Models (LLMs) for geospatial data processing by integrating code interpretation and Retrieval-Augmented Generation (RAG) techniques within a Monte Carlo Tree Search (MCTS) algorithm, setting a new benchmark for geospatial task evaluations.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Compress then Serve: Serving Thousands of LoRA Adapters with Little Overhead</title><link>https://arxiv.org/abs/2407.00066</link><description>https://arxiv.org/abs/2407.00066&lt;br /&gt;GeoAgent is a new interactive framework that enhances large language models' (LLMs) ability to process geospatial data by integrating a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) with a Monte Carlo Tree Search (MCTS) algorithm, offering improved performance over baseline LLMs in complex geospatial tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Human-like Episodic Memory for Infinite Context LLMs</title><link>https://arxiv.org/abs/2407.09450</link><description>https://arxiv.org/abs/2407.09450&lt;br /&gt;The paper introduces GeoAgent, a framework integrating a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) with Monte Carlo Tree Search to improve large language models' processing of complex geospatial data tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling</title><link>https://arxiv.org/abs/2409.02908</link><description>https://arxiv.org/abs/2409.02908&lt;br /&gt;GeoAgent is an interactive framework that enhances large language models' effectiveness in geospatial data processing by integrating a code interpreter, static analysis, and Retrieval-Augmented Generation techniques within a Monte Carlo Tree Search algorithm, providing improvements in function calls and task completion.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Benchmarking and Building Zero-Shot Hindi Retrieval Model with Hindi-BEIR and NLLB-E5</title><link>https://arxiv.org/abs/2409.05401</link><description>https://arxiv.org/abs/2409.05401&lt;br /&gt;GeoAgent is an interactive framework that improves large language models' capabilities in handling geospatial data processing by integrating a code interpreter, static analysis, and Retrieval-Augmented Generation techniques within a Monte Carlo Tree Search algorithm.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Development and Validation of a Dynamic-Template-Constrained Large Language Model for Generating Fully-Structured Radiology Reports</title><link>https://arxiv.org/abs/2409.18319</link><description>https://arxiv.org/abs/2409.18319&lt;br /&gt;GeoAgent is an interactive framework that uses a combination of a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) within a Monte Carlo Tree Search (MCTS) to improve the handling of geospatial data processing by large language models (LLMs), overcoming challenges such as logical errors and the selection of appropriate function calls.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>System 2 thinking in OpenAI's o1-preview model: Near-perfect performance on a mathematics exam</title><link>https://arxiv.org/abs/2410.07114</link><description>https://arxiv.org/abs/2410.07114&lt;br /&gt;GeoAgent is a framework that enhances large language models in handling complex tasks in geospatial data processing by integrating code interpretation, static analysis, and retrieval-augmented generation within a Monte Carlo Tree Search algorithm.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Automated Rewards via LLM-Generated Progress Functions</title><link>https://arxiv.org/abs/2410.09187</link><description>https://arxiv.org/abs/2410.09187&lt;br /&gt;The paper presents GeoAgent, a framework that enhances Large Language Models (LLMs) in geospatial data processing by integrating a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) within a Monte Carlo Tree Search (MCTS) algorithm.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LoLCATs: On Low-Rank Linearizing of Large Language Models</title><link>https://arxiv.org/abs/2410.10254</link><description>https://arxiv.org/abs/2410.10254&lt;br /&gt;The paper introduces GeoAgent, a framework that enhances large language models' capabilities in geospatial data processing by integrating code interpretation, static analysis, and retrieval-augmented generation within a Monte Carlo Tree Search algorithm.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents</title><link>https://arxiv.org/abs/2410.13185</link><description>https://arxiv.org/abs/2410.13185&lt;br /&gt;The paper introduces GeoAgent, an interactive framework that enhances large language models' ability to handle geospatial data processing by integrating a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) within a Monte Carlo Tree Search (MCTS) algorithm.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Good Parenting is all you need -- Multi-agentic LLM Hallucination Mitigation</title><link>https://arxiv.org/abs/2410.14262</link><description>https://arxiv.org/abs/2410.14262&lt;br /&gt;GeoAgent is an interactive framework that enhances large language models (LLMs) for geospatial data processing by integrating code interpretation, static analysis, and Retrieval-Augmented Generation (RAG) with a Monte Carlo Tree Search (MCTS) approach, and demonstrates superior task performance compared to baseline LLMs.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>On Designing Effective RL Reward at Training Time for LLM Reasoning</title><link>https://arxiv.org/abs/2410.15115</link><description>https://arxiv.org/abs/2410.15115&lt;br /&gt;GeoAgent is a new framework that improves the use of large language models (LLMs) for geospatial data processing by integrating a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) within a Monte Carlo Tree Search algorithm for more effective handling of complex tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Creativity in AI: Progresses and Challenges</title><link>https://arxiv.org/abs/2410.17218</link><description>https://arxiv.org/abs/2410.17218&lt;br /&gt;GeoAgent is an interactive framework that enhances large language models' ability to process geospatial data through the integration of a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) techniques using a Monte Carlo Tree Search (MCTS) algorithm.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>$C^2$: Scalable Auto-Feedback for LLM-based Chart Generation</title><link>https://arxiv.org/abs/2410.18652</link><description>https://arxiv.org/abs/2410.18652&lt;br /&gt;GeoAgent, an interactive framework that improves large language models' ability to handle geospatial data processing, integrates techniques like Retrieval-Augmented Generation (RAG) within a Monte Carlo Tree Search (MCTS) to better manage complex tasks and reduce logical errors.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>An LLM Agent for Automatic Geospatial Data Analysis</title><link>https://arxiv.org/abs/2410.18792</link><description>https://arxiv.org/abs/2410.18792&lt;br /&gt;GeoAgent is an interactive framework that enhances large language models (LLMs) for geospatial data processing by integrating a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) techniques within a Monte Carlo Tree Search algorithm, addressing the inherent challenges of complex data structures and spatial constraints.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Diversity Helps Jailbreak Large Language Models</title><link>https://arxiv.org/abs/2411.04223</link><description>https://arxiv.org/abs/2411.04223&lt;br&gt;The paper surveys 133 summarization datasets to create an ontology that highlights the lack of high-quality resources for low-resource languages and the field's reliance on news domain and distant supervision, providing a web interface for improved dataset exploration.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Unfair Alignment: Examining Safety Alignment Across Vision Encoder Layers in Vision-Language Models</title><link>https://arxiv.org/abs/2411.04291</link><description>https://arxiv.org/abs/2411.04291&lt;br&gt;This paper surveys 133 summarization datasets across over 100 languages, highlighting the lack of high-quality datasets for low-resource languages and over-reliance on the news domain, and provides a web interface for exploring this dataset ontology.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Capabilities Approach to Studying Bias and Harm in Language Technologies</title><link>https://arxiv.org/abs/2411.04298</link><description>https://arxiv.org/abs/2411.04298&lt;br&gt;The paper surveys 133 summarization datasets across over 100 languages, proposing an ontology to categorize them, highlighting the scarcity of high-quality datasets for low-resource languages and the field's dependence on news-domain data and distant supervision.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Improving Bilingual Capabilities of Language Models to Support Diverse Linguistic Practices in Education</title><link>https://arxiv.org/abs/2411.04308</link><description>https://arxiv.org/abs/2411.04308&lt;br&gt;This paper surveys 133 summarization datasets to create an ontology of sample properties, collection methods, and distribution, highlighting gaps such as the need for high-quality datasets in low-resource languages and the field's over-reliance on the news domain.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Multilingual Sentiment Lexicon for Low-Resource Language Translation using Large Languages Models and Explainable AI</title><link>https://arxiv.org/abs/2411.04316</link><description>https://arxiv.org/abs/2411.04316&lt;br&gt;The paper surveys 133 summarization datasets, highlighting issues like disjointed annotation efforts and a reliance on the news domain, while introducing a novel ontology and tools to streamline future research in summarization.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Measuring short-form factuality in large language models</title><link>https://arxiv.org/abs/2411.04368</link><description>https://arxiv.org/abs/2411.04368&lt;br&gt;The paper surveys 133 summarization datasets across 100 languages, highlights the lack of accessible high-quality datasets for low-resource languages, and proposes an ontology to standardize terminology and streamline summarization research.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Bayesian Calibration of Win Rate Estimation with LLM Evaluators</title><link>https://arxiv.org/abs/2411.04424</link><description>https://arxiv.org/abs/2411.04424&lt;br&gt;The paper surveys 133 summarization datasets in over 100 languages, identifying a novel ontology to streamline research, with a focus on improving dataset quality and accessibility for low-resource languages.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>One fish, two fish, but not the whole sea: Alignment reduces language models' conceptual diversity</title><link>https://arxiv.org/abs/2411.04427</link><description>https://arxiv.org/abs/2411.04427&lt;br&gt;The paper surveys 133 summarization datasets across over 100 languages to create a novel ontology, highlighting gaps in high-quality datasets for low-resource languages and an over-reliance on the news domain, and provides tools for improving coherence in future summarization research.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Gradient Localization Improves Lifelong Pretraining of Language Models</title><link>https://arxiv.org/abs/2411.04448</link><description>https://arxiv.org/abs/2411.04448&lt;br&gt;This paper surveys 133 summarization datasets across more than 100 languages, identifying limitations in existing resources and proposing an ontology to improve coherence and accessibility in summarization research.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ML-Promise: A Multilingual Dataset for Corporate Promise Verification</title><link>https://arxiv.org/abs/2411.04473</link><description>https://arxiv.org/abs/2411.04473&lt;br&gt;This paper surveys 133 summarization datasets across more than 100 languages, identifying a lack of high-quality datasets for low-resource languages and an over-reliance on the news domain, while proposing a new ontology and a web tool to standardize future research.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Tomato, Tomahto, Tomate: Measuring the Role of Shared Semantics among Subwords in Multilingual Language Models</title><link>https://arxiv.org/abs/2411.04530</link><description>https://arxiv.org/abs/2411.04530&lt;br&gt;This paper surveys 133 summarization datasets across over 100 languages, presenting an ontology to highlight the lack of high-quality datasets for low-resource languages and the field's reliance on news data, alongside providing tools for more structured future research.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Pruning Literals for Highly Efficient Explainability at Word Level</title><link>https://arxiv.org/abs/2411.04557</link><description>https://arxiv.org/abs/2411.04557&lt;br&gt;This paper surveys 133 summarization datasets across over 100 languages, highlighting challenges like disjointed annotation efforts and the over-reliance on the news domain, while providing a novel ontology and web interface for improved dataset exploration.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>The State and Fate of Summarization Datasets</title><link>https://arxiv.org/abs/2411.04585</link><description>https://arxiv.org/abs/2411.04585&lt;br&gt;The paper surveys 133 summarization datasets across over 100 languages, creating an ontology to highlight gaps such as the lack of high-quality datasets for low-resource languages and the predominance of news domain data, aiming to streamline future research efforts.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Tibyan Corpus: Balanced and Comprehensive Error Coverage Corpus Using ChatGPT for Arabic Grammatical Error Correction</title><link>https://arxiv.org/abs/2411.04588</link><description>https://arxiv.org/abs/2411.04588&lt;br&gt;The Semantic Hub Hypothesis suggests that modern language models create a shared semantic representation space across diverse languages and modalities, allowing semantically similar inputs from different languages or modalities to be positioned close to one another in this space.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>FASSILA: A Corpus for Algerian Dialect Fake News Detection and Sentiment Analysis</title><link>https://arxiv.org/abs/2411.04604</link><description>https://arxiv.org/abs/2411.04604&lt;br&gt;The paper proposes the semantic hub hypothesis, suggesting that language models use a shared semantic representation space across diverse languages and modalities, enhancing semantic processing and model outputs across different data types.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Hands-On Tutorial: Labeling with LLM and Human-in-the-Loop</title><link>https://arxiv.org/abs/2411.04637</link><description>https://arxiv.org/abs/2411.04637&lt;br&gt;The paper proposes the semantic hub hypothesis, suggesting that language models develop a shared representation space that integrates semantically similar inputs across different languages and modalities, influenced by the model's primary pretraining language.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>BhasaAnuvaad: A Speech Translation Dataset for 14 Indian Languages</title><link>https://arxiv.org/abs/2411.04699</link><description>https://arxiv.org/abs/2411.04699&lt;br&gt;The paper proposes the semantic hub hypothesis, suggesting that language models share a common representation space for semantically similar inputs across different languages and modalities, which facilitates processing diverse data types and interventions across these types predictably affect model outputs.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>RetrieveGPT: Merging Prompts and Mathematical Models for Enhanced Code-Mixed Information Retrieval</title><link>https://arxiv.org/abs/2411.04752</link><description>https://arxiv.org/abs/2411.04752&lt;br&gt;The paper hypothesizes that modern language models process inputs across various languages and modalities by learning a shared representation space that aligns semantically similar inputs regardless of modality, akin to a semantic hub as in human semantic knowledge organization.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A study of Vietnamese readability assessing through semantic and statistical features</title><link>https://arxiv.org/abs/2411.04756</link><description>https://arxiv.org/abs/2411.04756&lt;br&gt;The paper proposes the 'semantic hub hypothesis', suggesting that modern language models develop shared representation spaces across different languages and modalities, allowing semantically similar inputs to be placed near one another regardless of their linguistic or modal origin, effectively integrating information in a manner akin to transmodal semantic hubs in the human brain.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>AlignXIE: Improving Multilingual Information Extraction by Cross-Lingual Alignment</title><link>https://arxiv.org/abs/2411.04794</link><description>https://arxiv.org/abs/2411.04794&lt;br&gt;The paper proposes the semantic hub hypothesis, suggesting that language models create shared representation spaces for semantically similar inputs across various modalities and languages, actively utilizing this space during processing.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Kwai-STaR: Transform LLMs into State-Transition Reasoners</title><link>https://arxiv.org/abs/2411.04799</link><description>https://arxiv.org/abs/2411.04799&lt;br&gt;The Semantic Hub Hypothesis suggests that modern language models create a shared representation space across different languages and modalities, where semantically similar inputs are positioned closely, aiding in cross-modality and cross-language processing.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LuxBank: The First Universal Dependency Treebank for Luxembourgish</title><link>https://arxiv.org/abs/2411.04813</link><description>https://arxiv.org/abs/2411.04813&lt;br&gt;The Semantic Hub Hypothesis proposes that modern language models develop a shared representation space across different languages and modalities, allowing semantically similar inputs to cluster together, which suggests active utilization in processing diverse data types.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>When Does Classical Chinese Help? Quantifying Cross-Lingual Transfer in Hanja and Kanbun</title><link>https://arxiv.org/abs/2411.04822</link><description>https://arxiv.org/abs/2411.04822&lt;br&gt;The paper proposes the semantic hub hypothesis, suggesting that language models learn a shared representation space across different languages and modalities, which allows semantically similar inputs from diverse types to be represented similarly, as evidenced by interventions affecting outputs predictably across these types.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and Benchmark Models</title><link>https://arxiv.org/abs/2411.04825</link><description>https://arxiv.org/abs/2411.04825&lt;br&gt;The paper proposes the Semantic Hub Hypothesis, suggesting that language models develop a shared representation space for semantically similar inputs from various languages and modalities, which influences model outputs across different data types.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Prompt-Guided Internal States for Hallucination Detection of Large Language Models</title><link>https://arxiv.org/abs/2411.04847</link><description>https://arxiv.org/abs/2411.04847&lt;br&gt;The Semantic Hub Hypothesis suggests that modern language models process diverse languages and modalities by creating a shared representation space that semantically links inputs from different modalities and languages.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Sentiment Analysis of Spanish Political Party Tweets Using Pre-trained Language Models</title><link>https://arxiv.org/abs/2411.04862</link><description>https://arxiv.org/abs/2411.04862&lt;br&gt;The paper proposes the semantic hub hypothesis, suggesting that language models learn a shared representation space allowing semantically similar inputs across languages and modalities to be closely positioned, affecting outputs predictably across data types.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models</title><link>https://arxiv.org/abs/2411.04905</link><description>https://arxiv.org/abs/2411.04905&lt;br&gt;The paper proposes the semantic hub hypothesis, demonstrating that language models utilize a shared representation space across different languages and modalities to process semantically similar inputs, evidencing transmodal semantic integration akin to a hub-and-spoke neural model.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>GASE: Generatively Augmented Sentence Encoding</title><link>https://arxiv.org/abs/2411.04914</link><description>https://arxiv.org/abs/2411.04914&lt;br&gt;The paper proposes the semantic hub hypothesis, suggesting that language models acquire the ability to process multiple languages and modalities through a shared representation space that integrates semantically similar inputs across different types.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>GPTKB: Building Very Large Knowledge Bases from Language Models</title><link>https://arxiv.org/abs/2411.04920</link><description>https://arxiv.org/abs/2411.04920&lt;br&gt;The study proposes the semantic hub hypothesis, suggesting that language models organize semantic knowledge across languages and modalities into a shared representation space, allowing for semantically similar inputs from different data types to be processed efficiently.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Estimating the Influence of Sequentially Correlated Literary Properties in Textual Classification: A Data-Centric Hypothesis-Testing Approach</title><link>https://arxiv.org/abs/2411.04950</link><description>https://arxiv.org/abs/2411.04950&lt;br&gt;The paper hypothesizes that modern language models develop shared semantic representations across different languages and modalities, aligning semantically similar inputs from diverse data types into a cohesive space, resembling the transmodal semantic 'hub' concept from neuroscience.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>BitNet a4.8: 4-bit Activations for 1-bit LLMs</title><link>https://arxiv.org/abs/2411.04965</link><description>https://arxiv.org/abs/2411.04965&lt;br&gt;The paper proposes the Semantic Hub Hypothesis, suggesting that language models utilize a shared representation space for semantically similar inputs across different languages and modalities, facilitating integrated processing of diverse data types.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>SuffixDecoding: A Model-Free Approach to Speeding Up Large Language Model Inference</title><link>https://arxiv.org/abs/2411.04975</link><description>https://arxiv.org/abs/2411.04975&lt;br&gt;The paper proposes the Semantic Hub Hypothesis, suggesting that modern language models learn a shared representation space across different languages and modalities, placing semantically similar inputs near each other and demonstrating cross-language and cross-modality semantic processing capabilities.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities</title><link>https://arxiv.org/abs/2411.04986</link><description>https://arxiv.org/abs/2411.04986&lt;br&gt;The Semantic Hub Hypothesis proposes that language models develop shared representation spaces across different languages and modalities, aligning semantically similar inputs, which suggests an active utilization of these spaces for input processing.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models</title><link>https://arxiv.org/abs/2411.04996</link><description>https://arxiv.org/abs/2411.04996&lt;br&gt;The paper reveals that visual languages derived from transformer-based vision-language models exhibit statistical patterns similar to natural languages, such as Zipfian distribution, but lack cohesive grammatical structures, suggesting insights for enhancing computer vision models.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?</title><link>https://arxiv.org/abs/2411.05000</link><description>https://arxiv.org/abs/2411.05000&lt;br&gt;The paper explores the statistical properties of discrete visual languages used in transformer-based vision and language models, highlighting their Zipfian distributions, higher entropy, weak hierarchical organization compared to natural languages, and potential implications for the design of computer vision models.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination</title><link>https://arxiv.org/abs/2411.03823</link><description>https://arxiv.org/abs/2411.03823&lt;br&gt;The paper investigates the discrete tokenized representation of images in transformer-based models, analyzing visual languages' statistical properties and comparing them to natural languages, revealing similarities and differences in distribution, structure, and alignment.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>A Comparative Study on the Impact of Test-Driven Development (TDD) and Behavior-Driven Development (BDD) on Enterprise Software Delivery Effectiveness</title><link>https://arxiv.org/abs/2411.04141</link><description>https://arxiv.org/abs/2411.04141&lt;br&gt;The paper analyzes discrete visual languages used in transformer-based vision and language models, exploring their statistical properties, such as Zipfian distributions and lack of grammatical structures, compared to natural languages.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Unified Pathological Speech Analysis with Prompt Tuning</title><link>https://arxiv.org/abs/2411.04142</link><description>https://arxiv.org/abs/2411.04142&lt;br&gt;This paper investigates the statistical properties of discrete visual languages used in transformer-based models for vision and language tasks, finding both similarities and differences with natural languages, such as adherence to Zipfian distributions but lack of cohesive grammatical structures.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Software Design Pattern Model and Data Structure Algorithm Abilities on Microservices Architecture Design in High-tech Enterprises</title><link>https://arxiv.org/abs/2411.04143</link><description>https://arxiv.org/abs/2411.04143&lt;br&gt;The paper analyzes the statistical properties of discrete visual languages used in transformer-based vision and language models, revealing similarities to and differences from natural languages, such as their lack of cohesive grammatical structures and higher token entropy.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Crystal: Illuminating LLM Abilities on Language and Code</title><link>https://arxiv.org/abs/2411.04156</link><description>https://arxiv.org/abs/2411.04156&lt;br&gt;This paper analyzes the discrete tokenized representation of images in transformer-based vision and language models, revealing similarities and differences with natural languages in terms of statistical behavior and structural properties.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Analyzing Multimodal Features of Spontaneous Voice Assistant Commands for Mild Cognitive Impairment Detection</title><link>https://arxiv.org/abs/2411.04158</link><description>https://arxiv.org/abs/2411.04158&lt;br&gt;The paper introduces a natural-language-centric analysis of visual token languages used in transformer-based vision and language models, uncovering their Zipfian distributions and highlighting their lack of cohesive grammatical structures compared to natural languages.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding</title><link>https://arxiv.org/abs/2411.04282</link><description>https://arxiv.org/abs/2411.04282&lt;br&gt;The paper investigates the statistical properties and behaviors of discrete visual languages in transformer-based vision models, revealing similarities and differences with natural languages in terms of distributions and structural organization.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Scaling Laws for Precision</title><link>https://arxiv.org/abs/2411.04330</link><description>https://arxiv.org/abs/2411.04330&lt;br&gt;This paper explores the statistical behavior of discrete visual languages used in transformer-based vision and language models, revealing similarities and differences with natural languages, such as adherence to Zipfian distributions but lacking cohesive grammatical structures.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Robust and Efficient Fine-tuning of LLMs with Bayesian Reparameterization of Low-Rank Adaptation</title><link>https://arxiv.org/abs/2411.04358</link><description>https://arxiv.org/abs/2411.04358&lt;br&gt;The paper examines the statistical properties of discrete visual languages used in transformer-based models, revealing key differences and similarities with natural languages in terms of token distribution, grammar, and hierarchical organization.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Variational Low-Rank Adaptation Using IVON</title><link>https://arxiv.org/abs/2411.04421</link><description>https://arxiv.org/abs/2411.04421&lt;br&gt;The paper investigates the statistical similarities and differences between discrete visual languages used in transformer-based vision and language models and natural languages, revealing unique frequency distributions and lack of grammatical cohesion in visual representations.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Best Practices for Distilling Large Language Models into BERT for Web Search Ranking</title><link>https://arxiv.org/abs/2411.04539</link><description>https://arxiv.org/abs/2411.04539&lt;br&gt;The paper examines the statistical properties of discrete tokenized visual languages in transformer-based vision and language models, revealing their alignment with natural language token distributions but highlighting differences in grammatical cohesion.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Self-Calibrated Listwise Reranking with Large Language Models</title><link>https://arxiv.org/abs/2411.04602</link><description>https://arxiv.org/abs/2411.04602&lt;br&gt;The paper analyzes discrete visual languages in transformer-based models, uncovering similarities and differences with natural languages, such as greater entropy and weaker grammatical structures.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>DISCO: DISCovering Overfittings as Causal Rules for Text Classification Models</title><link>https://arxiv.org/abs/2411.04649</link><description>https://arxiv.org/abs/2411.04649&lt;br&gt;The paper explores the statistical properties of discrete visual languages in transformer-based vision and language models, revealing differences in token behavior and structural alignment compared to natural languages.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Enhancing Investment Analysis: Optimizing AI-Agent Collaboration in Financial Research</title><link>https://arxiv.org/abs/2411.04788</link><description>https://arxiv.org/abs/2411.04788&lt;br&gt;This paper investigates the statistical behavior of discrete visual languages used in transformer-based models for vision and language tasks, revealing their Zipfian distribution and lack of cohesive grammatical structure compared to natural languages.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding</title><link>https://arxiv.org/abs/2411.04952</link><description>https://arxiv.org/abs/2411.04952&lt;br&gt;The paper examines the statistical properties of discrete visual token languages used in transformer-based vision and language models, highlighting their similarities and differences with natural languages, such as adherence to Zipfian distributions but lacking cohesive grammatical structures.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability</title><link>https://arxiv.org/abs/2411.04962</link><description>https://arxiv.org/abs/2411.04962&lt;br&gt;The paper explores the statistical properties of discrete visual languages in transformer-based models for vision and language tasks, revealing similarities to natural languages in token distribution but differences in grammatical cohesion and hierarchical organization.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation</title><link>https://arxiv.org/abs/2411.04997</link><description>https://arxiv.org/abs/2411.04997&lt;br&gt;This paper investigates the statistical properties of visual token languages used in transformer-based models for vision and language tasks, highlighting their similarities and differences with natural languages, particularly in terms of token distribution, entropy, and grammatical structure.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Analyzing The Language of Visual Tokens</title><link>https://arxiv.org/abs/2411.05001</link><description>https://arxiv.org/abs/2411.05001&lt;br&gt;The paper explores the statistical behaviors of transformer-based discrete visual token languages and compares them to natural languages, uncovering differences in distributions and grammatical structures.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Personalized Large Language Models</title><link>https://arxiv.org/abs/2402.09269</link><description>https://arxiv.org/abs/2402.09269&lt;br&gt;This paper investigates how large language models interpret linguistic expressions of uncertainty compared to humans, concluding that while some models align with human interpretations, they exhibit biases depending on their prior knowledge.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>LongEmbed: Extending Embedding Models for Long Context Retrieval</title><link>https://arxiv.org/abs/2404.12096</link><description>https://arxiv.org/abs/2404.12096&lt;br&gt;The paper investigates how language models interpret linguistic expressions of uncertainty and their ability to map these expressions to numerical responses, comparing them with human interpretation and noting sensitivities based on the model's prior knowledge.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Instruct, Not Assist: LLM-based Multi-Turn Planning and Hierarchical Questioning for Socratic Code Debugging</title><link>https://arxiv.org/abs/2406.11709</link><description>https://arxiv.org/abs/2406.11709&lt;br&gt;This paper investigates how language models interpret linguistic expressions of uncertainty and compares their responses to human interpretations, revealing biases in model assessments based on prior knowledge.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making</title><link>https://arxiv.org/abs/2407.06567</link><description>https://arxiv.org/abs/2407.06567&lt;br&gt;The paper evaluates how language models interpret linguistic expressions of uncertainty and compares this to human interpretation, revealing that while many models respond similarly to humans, they exhibit biases based on their prior knowledge.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ALI-Agent: Assessing LLMs' Alignment with Human Values via Agent-based Evaluation</title><link>https://arxiv.org/abs/2405.14125</link><description>https://arxiv.org/abs/2405.14125&lt;br&gt;This paper investigates how large language models, specifically transformers, solve complex logical reasoning tasks by analyzing their internal mechanisms and identifying planning and reasoning circuits.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>ReMoDetect: Reward Models Recognize Aligned LLM's Generations</title><link>https://arxiv.org/abs/2405.17382</link><description>https://arxiv.org/abs/2405.17382&lt;br&gt;The paper investigates the internal mechanisms of transformers in solving propositional logic problems, identifying specific circuits for planning and reasoning within the network.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Linguistic Collapse: Neural Collapse in (Large) Language Models</title><link>https://arxiv.org/abs/2405.17767</link><description>https://arxiv.org/abs/2405.17767&lt;br&gt;The paper investigates how large language models, specifically transformers, solve propositional logic problems by analyzing their internal mechanisms and identifying planning and reasoning circuits within the network.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>Transcoders Find Interpretable LLM Feature Circuits</title><link>https://arxiv.org/abs/2406.11944</link><description>https://arxiv.org/abs/2406.11944&lt;br&gt;The paper investigates the internal mechanisms of small and large transformers in solving complex propositional logic problems, identifying specific circuits and components that enable planning and reasoning.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>GPT-4V Cannot Generate Radiology Reports Yet</title><link>https://arxiv.org/abs/2407.12176</link><description>https://arxiv.org/abs/2407.12176&lt;br&gt;This paper investigates the internal mechanisms of small and large transformers for solving propositional logic problems, identifying planning and reasoning circuits critical for logical reasoning tasks.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>INQUIRE: A Natural World Text-to-Image Retrieval Benchmark</title><link>https://arxiv.org/abs/2411.02537</link><description>https://arxiv.org/abs/2411.02537&lt;br&gt;This paper analyzes how transformers, including both small models and larger ones like Mistral 7B, solve propositional logic problems by identifying internal planning and reasoning circuits within the network.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item><item><title>How Transformers Solve Propositional Logic Problems: A Mechanistic Analysis</title><link>https://arxiv.org/abs/2411.04105</link><description>https://arxiv.org/abs/2411.04105&lt;br&gt;The paper investigates how large language models and transformers solve complex propositional logic problems, revealing specific planning and reasoning circuits within the networks that enable logical reasoning and planning.</description><pubDate>Fri, 08 Nov 2024 09:35:26 GMT</pubDate></item></channel></rss>