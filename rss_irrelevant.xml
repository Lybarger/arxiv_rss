<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Irrelevant arXiv Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss_irrelevant.xml</link><description>Irrelevant arXiv Papers</description><lastBuildDate>Mon, 21 Oct 2024 10:13:12 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation</title><link>https://arxiv.org/abs/2410.13944</link><description>https://arxiv.org/abs/2410.13944&lt;br /&gt;RaDis (Rationale Distillation) is a novel approach that improves machine translation skills of Large Language Models (LLMs) by using self-generated rationales to prevent catastrophic forgetting, thereby maintaining their general abilities and ensuring safety in training.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>From Single to Multi: How LLMs Hallucinate in Multi-Document Summarization</title><link>https://arxiv.org/abs/2410.13961</link><description>https://arxiv.org/abs/2410.13961&lt;br /&gt;This paper investigates hallucinations in large language models (LLMs) during multi-document summarization, revealing that up to 75% of generated content may be fabricated, particularly towards the end of summaries, and highlights the limitations of current methods to reduce these inaccuracies.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Detecting AI-Generated Texts in Cross-Domains</title><link>https://arxiv.org/abs/2410.13966</link><description>https://arxiv.org/abs/2410.13966&lt;br /&gt;This paper presents RoBERTa-Ranker, a modified ranking classifier that improves the detection of AI-generated texts across multiple domains by fine-tuning with minimal labeled data, outperforming existing tools like DetectGPT and GPTZero.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Are LLMs Models of Distributional Semantics? A Case Study on Quantifiers</title><link>https://arxiv.org/abs/2410.13984</link><description>https://arxiv.org/abs/2410.13984&lt;br /&gt;This paper explores the alignment between large language models (LLMs) and human judgments in understanding vague and exact quantifiers, suggesting a need to re-evaluate the assumptions of distributional semantics models.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>LLMs are Biased Teachers: Evaluating LLM Bias in Personalized Education</title><link>https://arxiv.org/abs/2410.14012</link><description>https://arxiv.org/abs/2410.14012&lt;br&gt;This research paper evaluates biases in large language models (LLMs) used as teachers in personalized education, revealing significant disparities in how they generate and select educational content for different demographic groups.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Generating Signed Language Instructions in Large-Scale Dialogue Systems</title><link>https://arxiv.org/abs/2410.14026</link><description>https://arxiv.org/abs/2410.14026&lt;br&gt;This paper presents a goal-oriented conversational AI system that generates American Sign Language (ASL) instructions through a multimodal platform, utilizing retrieval methods and large language models while integrating feedback from the Deaf and Hard-of-Hearing community.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Measuring and Modifying the Readability of English Texts with GPT-4</title><link>https://arxiv.org/abs/2410.14028</link><description>https://arxiv.org/abs/2410.14028&lt;br&gt;This paper investigates the ability of Large Language Models (LLMs), specifically GPT-4, to assess and modify the readability of English texts, demonstrating high correlation with human evaluations and showing that LLMs can effectively alter text readability despite some unexplained variance in judgments.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Efficient Retrieval of Temporal Event Sequences from Textual Descriptions</title><link>https://arxiv.org/abs/2410.14043</link><description>https://arxiv.org/abs/2410.14043&lt;br&gt;TPP-LLM-Embedding is a model that efficiently retrieves temporal event sequences from textual descriptions by integrating large language models with temporal point processes, ensuring a shared embedding space and optimizing contrastive loss for improved retrieval performance.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Learning Metadata-Agnostic Representations for Text-to-SQL In-Context Example Selection</title><link>https://arxiv.org/abs/2410.14049</link><description>https://arxiv.org/abs/2410.14049&lt;br&gt;MARLO is a method that enhances the selection of in-context examples for Text-to-SQL tasks by aligning natural language questions and SQL query representations in a shared embedding space, improving execution accuracy without relying on database metadata.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Learning Multimodal Cues of Children's Uncertainty</title><link>https://arxiv.org/abs/2410.14050</link><description>https://arxiv.org/abs/2410.14050&lt;br&gt;This study introduces a dataset annotated for nonverbal cues of uncertainty and develops a multimodal machine learning model that predicts uncertainty from video clips, advancing understanding of cognitive coordination in human-AI interactions.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs</title><link>https://arxiv.org/abs/2410.14057</link><description>https://arxiv.org/abs/2410.14057&lt;br&gt;This paper introduces XC-Translate, a large-scale benchmark for machine translation that focuses on culturally nuanced entity names, alongside KG-MT, a novel method that integrates information from multilingual knowledge graphs into neural machine translation using a dense retrieval mechanism, demonstrating significant performance improvements over existing models.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Be My Donor. Transfer the NLP Datasets Between the Languages Using LLM</title><link>https://arxiv.org/abs/2410.14074</link><description>https://arxiv.org/abs/2410.14074&lt;br&gt;This paper explores the transfer of NLP datasets and annotations between languages using Large Language Models (LLMs), specifically focusing on translating the DEFT corpus from English to Russian, thereby facilitating resource sharing in low-resource languages.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>A Lightweight Multi Aspect Controlled Text Generation Solution For Large Language Models</title><link>https://arxiv.org/abs/2410.14144</link><description>https://arxiv.org/abs/2410.14144&lt;br&gt;This paper proposes a lightweight pipeline for Multi-Aspect Controllable Text Generation (MCTG) in Large Language Models (LLMs) that utilizes data augmentation to address bias in datasets, resulting in improved performance and reduced correlations in aspect data.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent</title><link>https://arxiv.org/abs/2410.14152</link><description>https://arxiv.org/abs/2410.14152&lt;br&gt;SRAP-Agent is an innovative framework that integrates Large Language Models (LLMs) into economic simulations for optimizing public scarce resource allocation, specifically focusing on housing allocation scenarios to address limitations in traditional methods.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Towards Faithful Natural Language Explanations: A Study Using Activation Patching in Large Language Models</title><link>https://arxiv.org/abs/2410.14155</link><description>https://arxiv.org/abs/2410.14155&lt;br&gt;This paper introduces a new metric called Causal Faithfulness, which utilizes activation patching to measure the faithfulness of Natural Language Explanations generated by Large Language Models, arguing that existing methods are inadequate and highlighting the importance of model alignment tuning in producing trustworthy explanations.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning</title><link>https://arxiv.org/abs/2410.14157</link><description>https://arxiv.org/abs/2410.14157&lt;br&gt;The paper introduces discrete diffusion models, which outperformed autoregressive language models in complex reasoning and planning tasks by effectively learning difficult subgoals, highlighting their potential for advanced language understanding and problem-solving.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item></channel></rss>