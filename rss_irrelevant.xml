<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Irrelevant arXiv Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss_irrelevant.xml</link><description>Irrelevant arXiv Papers</description><lastBuildDate>Mon, 21 Oct 2024 10:56:07 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation</title><link>https://arxiv.org/abs/2410.13944</link><description>https://arxiv.org/abs/2410.13944&lt;br /&gt;The paper presents RaDis (Rationale Distillation), a novel method that enhances the machine translation skills of Large Language Models (LLMs) while preserving their overall general capabilities by replaying self-generated rationales to prevent forgetting during training.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>From Single to Multi: How LLMs Hallucinate in Multi-Document Summarization</title><link>https://arxiv.org/abs/2410.13961</link><description>https://arxiv.org/abs/2410.13961&lt;br /&gt;This study investigates how hallucinations occur in large language models (LLMs) during multi-document summarization, revealing that up to 75% of content generated can be fabricated, especially in the latter parts of summaries, and emphasizes the need for better mitigation strategies against such errors.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Detecting AI-Generated Texts in Cross-Domains</title><link>https://arxiv.org/abs/2410.13966</link><description>https://arxiv.org/abs/2410.13966&lt;br /&gt;The paper presents RoBERTa-Ranker, a modified ranking classifier that enhances the detection of AI-generated texts across different domains by leveraging fine-tuning techniques with limited labeled data, outperforming existing tools like DetectGPT and GPTZero.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Are LLMs Models of Distributional Semantics? A Case Study on Quantifiers</title><link>https://arxiv.org/abs/2410.13984</link><description>https://arxiv.org/abs/2410.13984&lt;br /&gt;This paper evaluates the performance of Large Language Models (LLMs) in capturing distributional semantics, particularly focusing on their ability to understand vague and exact quantifiers, and finds that LLMs align more closely with human judgments on exact quantifiers than previously expected.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>LLMs are Biased Teachers: Evaluating LLM Bias in Personalized Education</title><link>https://arxiv.org/abs/2410.14012</link><description>https://arxiv.org/abs/2410.14012&lt;br /&gt;This paper evaluates biases in large language models (LLMs) used in personalized education, highlighting significant disparities in how educational content is generated for different demographic groups, and proposes two metrics to analyze these biases.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Measuring and Modifying the Readability of English Texts with GPT-4</title><link>https://arxiv.org/abs/2410.14028</link><description>https://arxiv.org/abs/2410.14028&lt;br /&gt;This paper investigates the ability of Large Language Models (LLMs) like GPT-4 to assess and modify the readability of English texts, demonstrating high correlation with human judgments and indicating potential for making texts more accessible, despite some unexplained variance in responses.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Efficient Retrieval of Temporal Event Sequences from Textual Descriptions</title><link>https://arxiv.org/abs/2410.14043</link><description>https://arxiv.org/abs/2410.14043&lt;br /&gt;TPP-LLM-Embedding is a unified model that enhances the retrieval of temporal event sequences from textual descriptions by integrating large language models with temporal point processes, enabling efficient embedding and improved performance over baseline models.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Learning Metadata-Agnostic Representations for Text-to-SQL In-Context Example Selection</title><link>https://arxiv.org/abs/2410.14049</link><description>https://arxiv.org/abs/2410.14049&lt;br /&gt;MARLO is a technique that enables more effective selection of in-context examples for Text-to-SQL tasks by learning metadata-agnostic representations, aligning natural language questions and SQL queries in a shared embedding space to enhance execution accuracy.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Learning Multimodal Cues of Children's Uncertainty</title><link>https://arxiv.org/abs/2410.14050</link><description>https://arxiv.org/abs/2410.14050&lt;br /&gt;This paper introduces a novel dataset for studying nonverbal cues of children's uncertainty and presents a multimodal machine learning model that predicts uncertainty from video clips, highlighting the importance of understanding uncertainty in human-AI collaboration.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs</title><link>https://arxiv.org/abs/2410.14057</link><description>https://arxiv.org/abs/2410.14057&lt;br /&gt;This paper presents XC-Translate, a benchmark for cross-cultural machine translation focusing on culturally-nuanced entity names, and proposes KG-MT, a novel method that integrates multilingual knowledge graphs into translation models using a dense retrieval mechanism, achieving significant performance improvements over existing models.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Be My Donor. Transfer the NLP Datasets Between the Languages Using LLM</title><link>https://arxiv.org/abs/2410.14074</link><description>https://arxiv.org/abs/2410.14074&lt;br /&gt;The paper explores how Large Language Models (LLMs) can be utilized to transfer datasets and annotations between languages, specifically translating the DEFT corpus from English to Russian, to enhance resource availability and expedite data annotation efforts.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>A Lightweight Multi Aspect Controlled Text Generation Solution For Large Language Models</title><link>https://arxiv.org/abs/2410.14144</link><description>https://arxiv.org/abs/2410.14144&lt;br /&gt;This paper presents a lightweight data augmentation pipeline for Multi-Aspect Controllable Text Generation (MCTG) in Large Language Models (LLMs), addressing biases and correlations in traditional datasets, leading to improved performance and accuracy.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>SRAP-Agent: Simulating and Optimizing Scarce Resource Allocation Policy with LLM-based Agent</title><link>https://arxiv.org/abs/2410.14152</link><description>https://arxiv.org/abs/2410.14152&lt;br /&gt;SRAP-Agent is a framework that utilizes Large Language Models (LLMs) to enhance the simulation and optimization of public scarce resource allocation policies, addressing limitations of traditional methods by incorporating real-world dynamics into economic simulations.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Towards Faithful Natural Language Explanations: A Study Using Activation Patching in Large Language Models</title><link>https://arxiv.org/abs/2410.14155</link><description>https://arxiv.org/abs/2410.14155&lt;br /&gt;This paper presents a novel metric called Causal Faithfulness, which measures the consistency of causal attributions in Natural Language Explanations generated by Large Language Models (LLMs), proposing that models with alignment tuning yield more faithful explanations than those tested by traditional methods.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Beyond Autoregression: Discrete Diffusion for Complex Reasoning and Planning</title><link>https://arxiv.org/abs/2410.14157</link><description>https://arxiv.org/abs/2410.14157&lt;br /&gt;The paper presents a novel approach using discrete diffusion models for complex reasoning and planning tasks, which demonstrates significant performance improvements over traditional autoregressive language models in handling challenging subgoals.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Automated Genre-Aware Article Scoring and Feedback Using Large Language Models</title><link>https://arxiv.org/abs/2410.14165</link><description>https://arxiv.org/abs/2410.14165&lt;br /&gt;The paper presents an advanced article scoring system that combines the BERT model and Chat-GPT to provide genre-aware evaluations and personalized feedback on written work, outperforming traditional methods in quality assessments.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>LLM The Genius Paradox: A Linguistic and Math Expert's Struggle with Simple Word-based Counting Problems</title><link>https://arxiv.org/abs/2410.14166</link><description>https://arxiv.org/abs/2410.14166&lt;br /&gt;This paper examines the limitations of Large Language Models (LLMs) in performing simple word-based counting tasks, explores reasons behind their deficiencies, and advocates for leveraging reasoning capabilities to improve performance on such tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>MultiChartQA: Benchmarking Vision-Language Models on Multi-Chart Problems</title><link>https://arxiv.org/abs/2410.14179</link><description>https://arxiv.org/abs/2410.14179&lt;br /&gt;MultiChartQA introduces a benchmark for evaluating Multimodal Large Language Models (MLLMs) on complex multi-chart problems, focusing on various reasoning tasks that reflect real-world applications and highlighting performance gaps compared to human abilities.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>XForecast: Evaluating Natural Language Explanations for Time Series Forecasting</title><link>https://arxiv.org/abs/2410.14180</link><description>https://arxiv.org/abs/2410.14180&lt;br /&gt;XForecast introduces new performance metrics for evaluating natural language explanations in time series forecasting, focusing on their accessibility to laypeople and the correlation of these metrics with human judgments, while also assessing the explanatory capabilities of large language models (LLMs).</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs</title><link>https://arxiv.org/abs/2410.14182</link><description>https://arxiv.org/abs/2410.14182&lt;br /&gt;LabSafety Bench introduces a benchmarking framework to evaluate the reliability of large language models (LLMs) in providing safety guidance for laboratory settings, highlighting their critical errors despite outperforming human participants.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Speciesism in Natural Language Processing Research</title><link>https://arxiv.org/abs/2410.14194</link><description>https://arxiv.org/abs/2410.14194&lt;br /&gt;This study investigates speciesism, or discrimination against nonhuman animals, in Natural Language Processing (NLP) research, revealing its presence among researchers, in datasets, and within NLP models, and discusses potential strategies for mitigation.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Supervised Chain of Thought</title><link>https://arxiv.org/abs/2410.14198</link><description>https://arxiv.org/abs/2410.14198&lt;br /&gt;The paper 'Supervised Chain of Thought' demonstrates that task-specific supervision is crucial for optimizing the prompt use in Large Language Models (LLMs) to enhance reasoning performance, overcoming the limitations of a 'one-prompt-for-all' approach.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Rationale Behind Essay Scores: Enhancing S-LLM's Multi-Trait Essay Scoring with Rationale Generated by LLMs</title><link>https://arxiv.org/abs/2410.14202</link><description>https://arxiv.org/abs/2410.14202&lt;br /&gt;The paper introduces Rationale-based Multiple Trait Scoring (RMTS), a novel method for automated essay scoring that combines large language models with trait-specific rationale generation to improve the accuracy and reliability of multi-trait essay evaluation.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Montessori-Instruct: Generate Influential Training Data Tailored for Student Learning</title><link>https://arxiv.org/abs/2410.14208</link><description>https://arxiv.org/abs/2410.14208&lt;br /&gt;Montessori-Instruct is a data synthesis framework that improves the generation of training data for language models by aligning synthetic data with the learning preferences of student models, leading to significant improvements in their performance over traditional synthesis methods.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model</title><link>https://arxiv.org/abs/2410.14225</link><description>https://arxiv.org/abs/2410.14225&lt;br /&gt;The paper presents the Knowledge-Enhanced Cross-modal Prompt Model (KECPM) for Few-Shot Joint Multimodal Entity-Relation Extraction, which generates supplementary background knowledge to improve performance on multimodal data involving text-image pairs, surpassing existing methods in evaluation metrics.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Unveiling Large Language Models Generated Texts: A Multi-Level Fine-Grained Detection Framework</title><link>https://arxiv.org/abs/2410.14231</link><description>https://arxiv.org/abs/2410.14231&lt;br /&gt;The Multi-level Fine-grained Detection (MFD) framework proposed in this research enhances the detection of Large Language Model (LLM)-generated texts by integrating multiple levels of analysis, improving robustness against evasion techniques, and providing a mechanism to address concerns over authorship and originality.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Towards Robust Knowledge Representations in Multilingual LLMs for Equivalence and Inheritance based Consistent Reasoning</title><link>https://arxiv.org/abs/2410.14235</link><description>https://arxiv.org/abs/2410.14235&lt;br /&gt;The paper investigates the limitations of Large Language Models (LLMs) in performing consistent reasoning across languages, introducing new tasks and benchmarks to evaluate their understanding of equivalence and inheritance relationships, and proposing 'Compositional Representations' to enhance multilingual reasoning consistency.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>A Novel Method to Metigate Demographic and Expert Bias in ICD Coding with Causal Inference</title><link>https://arxiv.org/abs/2410.14236</link><description>https://arxiv.org/abs/2410.14236&lt;br /&gt;The paper presents DECI, a causal inference-based method designed to mitigate demographic and expert biases in ICD coding, demonstrating improved accuracy and reduced spurious correlations compared to existing models.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models</title><link>https://arxiv.org/abs/2410.14248</link><description>https://arxiv.org/abs/2410.14248&lt;br /&gt;This research paper investigates selection bias in Multiple-Choice Question Answering (MCQA) for Video Language Models (VLMs), proposing a calibration technique called BOLD to enhance performance by reducing the impact of bias and improving genuine understanding in evaluations.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>MoDification: Mixture of Depths Made Easy</title><link>https://arxiv.org/abs/2410.14268</link><description>https://arxiv.org/abs/2410.14268&lt;br /&gt;MoDification presents a method for optimizing large language models (LLMs) by leveraging a mixture of depths to significantly enhance efficiency in terms of latency and memory usage, especially for long-context tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>REEF: Representation Encoding Fingerprints for Large Language Models</title><link>https://arxiv.org/abs/2410.14273</link><description>https://arxiv.org/abs/2410.14273&lt;br /&gt;REEF is a training-free method for identifying relationships between Large Language Models by comparing their feature representations via centered kernel alignment similarity, aiming to protect intellectual property without impairing model capabilities.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>EcomEdit: An Automated E-commerce Knowledge Editing Framework for Enhanced Product and Purchase Intention Understanding</title><link>https://arxiv.org/abs/2410.14276</link><description>https://arxiv.org/abs/2410.14276&lt;br /&gt;ECOMEDIT is an automated framework that applies Knowledge Editing to enhance Large Language Models' understanding of product features and customer purchase intentions in the e-commerce sector by enabling automatic conflict detection and improving semantic coverage.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>LoGU: Long-form Generation with Uncertainty Expressions</title><link>https://arxiv.org/abs/2410.14309</link><description>https://arxiv.org/abs/2410.14309&lt;br /&gt;LoGU introduces the task of Long-form Generation with Uncertainty, addressing challenges in allowing Large Language Models (LLMs) to express uncertainty accurately while generating longer responses, improving accuracy and reducing hallucinations through a specialized data collection and training approach.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Efficiently Computing Susceptibility to Context in Language Models</title><link>https://arxiv.org/abs/2410.14361</link><description>https://arxiv.org/abs/2410.14361&lt;br /&gt;The paper introduces Fisher susceptibility, an efficient method for estimating the sensitivity of language models to context changes in user queries, demonstrating its effectiveness compared to traditional Monte Carlo methods.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>How Do Multilingual Models Remember? Investigating Multilingual Factual Recall Mechanisms</title><link>https://arxiv.org/abs/2410.14387</link><description>https://arxiv.org/abs/2410.14387&lt;br /&gt;This paper investigates the mechanisms of factual recall in multilingual Large Language Models (LLMs) and examines the extent to which findings from English monolingual models apply to multilingual contexts, identifying both language-independent and language-dependent mechanisms.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Analyzing Context Utilization of LLMs in Document-Level Translation</title><link>https://arxiv.org/abs/2410.14391</link><description>https://arxiv.org/abs/2410.14391&lt;br /&gt;This paper examines the context utilization of large language models (LLMs) in document-level translation, revealing that while LLMs show enhanced overall translation capabilities, their performance on pronoun translation does not consistently reflect these improvements, emphasizing the importance of context-aware fine-tuning.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Generative AI, Pragmatics, and Authenticity in Second Language Learning</title><link>https://arxiv.org/abs/2410.14395</link><description>https://arxiv.org/abs/2410.14395&lt;br /&gt;This paper discusses the limitations and challenges of using generative AI in second language learning, highlighting issues of cultural bias and the lack of pragmatics and authenticity in AI-generated language compared to human interaction.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic Reasoning</title><link>https://arxiv.org/abs/2410.14399</link><description>https://arxiv.org/abs/2410.14399&lt;br /&gt;SylloBio-NLI introduces a framework for evaluating Large Language Models on biomedical syllogistic reasoning, revealing challenges in zero-shot performance and improvements with few-shot prompting, while highlighting dependencies on model architecture and pre-training for biomedical applications.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Unlearning Backdoor Attacks for LLMs with Weak-to-Strong Knowledge Distillation</title><link>https://arxiv.org/abs/2410.14425</link><description>https://arxiv.org/abs/2410.14425&lt;br /&gt;The paper presents W2SDefense, a weak-to-strong unlearning algorithm that uses feature alignment knowledge distillation to help large language models (LLMs) effectively unlearn backdoor attacks while maintaining their performance on downstream tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>A Systematic Study of Cross-Layer KV Sharing for Efficient LLM Inference</title><link>https://arxiv.org/abs/2410.14442</link><description>https://arxiv.org/abs/2410.14442&lt;br /&gt;This paper presents a systematic study on cross-layer key-value (KV) sharing techniques for enhancing the efficiency of large language models (LLMs) during inference, demonstrating that reduced KV cache sizes can maintain competitive performance while improving throughput in various configurations.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Combining Entropy and Matrix Nuclear Norm for Enhanced Evaluation of Language Models</title><link>https://arxiv.org/abs/2410.14480</link><description>https://arxiv.org/abs/2410.14480&lt;br /&gt;This paper presents a novel hybrid evaluation method for large language models (LLMs) that combines entropy from covariance matrices and the Matrix Nuclear Norm, offering a comprehensive, efficient evaluation framework adaptable to various objectives.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>SignAttention: On the Interpretability of Transformer Models for Sign Language Translation</title><link>https://arxiv.org/abs/2410.14506</link><description>https://arxiv.org/abs/2410.14506&lt;br /&gt;This paper provides an interpretability analysis of a Transformer model for Sign Language Translation, revealing how the model aligns visual inputs with corresponding glosses and text, highlighting the dynamics of attention mechanisms throughout the translation process.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization</title><link>https://arxiv.org/abs/2410.14545</link><description>https://arxiv.org/abs/2410.14545&lt;br /&gt;This paper presents a multi-source meeting summarization approach using large language models that enhances summary relevance and informativeness by integrating supplementary materials and personalizing outputs based on participant characteristics.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Large Language Models Are Overparameterized Text Encoders</title><link>https://arxiv.org/abs/2410.14578</link><description>https://arxiv.org/abs/2410.14578&lt;br /&gt;This paper demonstrates that large language models (LLMs) can be effectively pruned to reduce memory and inference time with minimal performance impact, leading to the conclusion that LLMs are overparameterized for text embedding tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Dialetto, ma Quanto Dialetto? Transcribing and Evaluating Dialects on a Continuum</title><link>https://arxiv.org/abs/2410.14589</link><description>https://arxiv.org/abs/2410.14589&lt;br /&gt;This research investigates within-dialect variation in Italian dialects by measuring speech-to-text performance and revealing geographical disparities that correlate with linguistic similarity, while suggesting that existing models bias performance towards dialects similar to standard varieties.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Toolshed: Scale Tool-Equipped Agents with Advanced RAG-Tool Fusion and Tool Knowledge Bases</title><link>https://arxiv.org/abs/2410.14594</link><description>https://arxiv.org/abs/2410.14594&lt;br /&gt;Toolshed introduces a tool knowledge base and Advanced RAG-Tool Fusion techniques to enhance the performance and retrieval accuracy of tool-equipped agents by optimizing tool selection without requiring model fine-tuning.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>You Shall Know a Tool by the Traces it Leaves: The Predictability of Sentiment Analysis Tools</title><link>https://arxiv.org/abs/2410.14626</link><description>https://arxiv.org/abs/2410.14626&lt;br /&gt;This paper demonstrates that different sentiment analysis tools yield inconsistent results across various datasets and languages, revealing an algorithmic bias that can be predicted from their outcomes, and emphasizes the necessity for improved evaluation standards in natural language processing (NLP).</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>GenEOL: Harnessing the Generative Power of LLMs for Training-Free Sentence Embeddings</title><link>https://arxiv.org/abs/2410.14635</link><description>https://arxiv.org/abs/2410.14635&lt;br /&gt;GenEOL introduces a novel method for obtaining training-free sentence embeddings by leveraging the generative capabilities of large language models (LLMs) to create diverse transformations of sentences, significantly improving performance in semantic text similarity and related tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Distance between Relevant Information Pieces Causes Bias in Long-Context LLMs</title><link>https://arxiv.org/abs/2410.14641</link><description>https://arxiv.org/abs/2410.14641&lt;br /&gt;The research presents LongPiBench, a benchmark to evaluate positional bias in large language models (LLMs) when processing multiple relevant information pieces, revealing significant biases related to their spacing and the challenges posed by the 'lost in the middle' phenomenon.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>DiscoGraMS: Enhancing Movie Screen-Play Summarization using Movie Character-Aware Discourse Graph</title><link>https://arxiv.org/abs/2410.14666</link><description>https://arxiv.org/abs/2410.14666&lt;br /&gt;DiscoGraMS introduces a novel discourse graph representation for movie screenplays that enhances summarization by capturing complex character interactions and contextual nuances, while addressing limitations of current transformer models.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>MiCEval: Unveiling Multimodal Chain of Thought's Quality via Image Description and Reasoning Steps</title><link>https://arxiv.org/abs/2410.14668</link><description>https://arxiv.org/abs/2410.14668&lt;br /&gt;MiCEval introduces a framework for evaluating the quality of reasoning chains in Multimodal Chain of Thought (MCoT) among multimodal large language models (MLLMs) by assessing both image descriptions and the correctness of reasoning steps.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment</title><link>https://arxiv.org/abs/2410.14676</link><description>https://arxiv.org/abs/2410.14676&lt;br /&gt;SudoLM introduces a framework that enables Large Language Models (LLMs) to learn access control over parametric knowledge using authorization alignment, allowing qualified users to access specific knowledge while restricting it from non-qualified users.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Are AI Detectors Good Enough? A Survey on Quality of Datasets With Machine-Generated Texts</title><link>https://arxiv.org/abs/2410.14677</link><description>https://arxiv.org/abs/2410.14677&lt;br /&gt;This paper surveys the quality of datasets used for training AI detectors of machine-generated texts, questioning the reliability of these detectors and advocating for improved methods in evaluating and enhancing the datasets involved.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Stars, Stripes, and Silicon: Unravelling the ChatGPT's All-American, Monochrome, Cis-centric Bias</title><link>https://arxiv.org/abs/2410.13868</link><description>https://arxiv.org/abs/2410.13868&lt;br /&gt;The paper explores the biases, toxicity, and unreliability of large language models like ChatGPT, attributing these issues to the quality and diversity of training data rather than model architectures, and calls for interdisciplinary collaboration to address these challenges and mitigate societal harm.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Observing the Southern US Culture of Honor Using Large-Scale Social Media Analysis</title><link>https://arxiv.org/abs/2410.13887</link><description>https://arxiv.org/abs/2410.13887&lt;br /&gt;This study examines the 'culture of honor' in the Southern US by analyzing social media interactions, finding that individuals from this region are more likely to retaliate to insults, and utilizes GPT-3.5 for geolocation and insult detection.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>NSmark: Null Space Based Black-box Watermarking Defense Framework for Pre-trained Language Models</title><link>https://arxiv.org/abs/2410.13907</link><description>https://arxiv.org/abs/2410.13907&lt;br /&gt;NSmark is a black-box watermarking defense framework designed for pre-trained language models that resists Linear Functionality Equivalence Attacks by leveraging the invariant properties of the output matrix's null space, ensuring the protection of intellectual property in language models.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Automatically Interpreting Millions of Features in Large Language Models</title><link>https://arxiv.org/abs/2410.13928</link><description>https://arxiv.org/abs/2410.13928&lt;br /&gt;This paper presents an automated pipeline developed to generate and evaluate natural language explanations for features from sparse autoencoders in large language models, employing new techniques to assess explanation quality and enhancing the interpretability of neural network activations.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Identifying High Consideration E-Commerce Search Queries</title><link>https://arxiv.org/abs/2410.13951</link><description>https://arxiv.org/abs/2410.13951&lt;br /&gt;The paper introduces an Engagement-based Query Ranking (EQR) approach to identify High Consideration e-commerce search queries, enabling better user experiences and improved engagement through targeted search features.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Debiasing Large Vision-Language Models by Ablating Protected Attribute Representations</title><link>https://arxiv.org/abs/2410.13976</link><description>https://arxiv.org/abs/2410.13976&lt;br /&gt;This research introduces a debiasing framework for Large Vision-Language Models (LVLMs) that aims to reduce societal biases in text generation by ablating biased attribute representations without requiring additional training.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Graph Neural Flows for Unveiling Systemic Interactions Among Irregularly Sampled Time Series</title><link>https://arxiv.org/abs/2410.14030</link><description>https://arxiv.org/abs/2410.14030&lt;br /&gt;This paper presents a graph-based model called graph neural flows that effectively captures systemic interactions among irregularly sampled time series by learning conditional dependencies and improving prediction accuracy compared to traditional methods.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>UCFE: A User-Centric Financial Expertise Benchmark for Large Language Models</title><link>https://arxiv.org/abs/2410.14059</link><description>https://arxiv.org/abs/2410.14059&lt;br /&gt;The UCFE benchmark is a user-centric framework for evaluating large language models' ability to manage complex financial tasks, combining human expert assessments with dynamic interactions to simulate real-world scenarios, and demonstrating alignment with user preferences.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Efficient Vision-Language Models by Summarizing Visual Tokens into Compact Registers</title><link>https://arxiv.org/abs/2410.14072</link><description>https://arxiv.org/abs/2410.14072&lt;br /&gt;The paper introduces 'Victor', a method to enhance the efficiency of vision-language models by summarizing visual tokens into a compact set of register tokens, significantly improving computational efficiency while maintaining model performance.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>ViConsFormer: Constituting Meaningful Phrases of Scene Texts using Transformer-based Method in Vietnamese Text-based Visual Question Answering</title><link>https://arxiv.org/abs/2410.14132</link><description>https://arxiv.org/abs/2410.14132&lt;br /&gt;ViConsFormer is a novel transformer-based method for Vietnamese Text-based Visual Question Answering (VQA) that effectively utilizes the meaning extracted from scene texts in images to improve answer accuracy, achieving state-of-the-art results on two large-scale datasets.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Coherence-Driven Multimodal Safety Dialogue with Active Learning for Embodied Agents</title><link>https://arxiv.org/abs/2410.14141</link><description>https://arxiv.org/abs/2410.14141&lt;br /&gt;M-CoDAL is a multimodal dialogue system for embodied agents that enhances safety communication in critical situations by interpreting visual cues and leveraging discourse coherence relations, evaluated through a user study with safety scenarios.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Fine-Grained Verifiers: Preference Modeling as Next-token Prediction in Vision-Language Alignment</title><link>https://arxiv.org/abs/2410.14148</link><description>https://arxiv.org/abs/2410.14148&lt;br /&gt;This paper introduces FiSAO, a self-alignment method that uses a model's own visual encoder as a fine-grained verifier to enhance alignment between vision and language in Vision-Language Large Models (VLLMs), addressing misalignment issues without requiring additional data.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Utilizing Large Language Models for Event Deconstruction to Enhance Multimodal Aspect-Based Sentiment Analysis</title><link>https://arxiv.org/abs/2410.14150</link><description>https://arxiv.org/abs/2410.14150&lt;br /&gt;This paper presents a novel framework, MABSA-RL, that utilizes Large Language Models (LLMs) for event decomposition to improve Multimodal Aspect-Based Sentiment Analysis (MABSA) by simplifying the complexity of analysis through reinforcement learning optimization.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation</title><link>https://arxiv.org/abs/2410.14251</link><description>https://arxiv.org/abs/2410.14251&lt;br /&gt;The paper presents MATRIX, a multi-agent simulation framework that generates diverse text-based scenarios for post-training data synthesis, enabling LLMs to better follow human instructions, and demonstrates its effectiveness through superior performance on various benchmarks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Good Parenting is all you need -- Multi-agentic LLM Hallucination Mitigation</title><link>https://arxiv.org/abs/2410.14262</link><description>https://arxiv.org/abs/2410.14262&lt;br /&gt;This study demonstrates that multi-agent setups using advanced Large Language Models (LLMs) can effectively detect and correct hallucinations in AI-generated content, achieving high accuracy in identifying inaccuracies and revising outputs.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Fine-Tuning Pre-trained Language Models for Robust Causal Representation Learning</title><link>https://arxiv.org/abs/2410.14375</link><description>https://arxiv.org/abs/2410.14375&lt;br /&gt;The research investigates how fine-tuning pre-trained language models can enhance their generalizability in single-domain scenarios by utilizing causal mechanisms to mitigate the effect of spurious features, demonstrating superior performance in both synthetic and real-world settings.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>MomentumSMoE: Integrating Momentum into Sparse Mixture of Experts</title><link>https://arxiv.org/abs/2410.14574</link><description>https://arxiv.org/abs/2410.14574&lt;br /&gt;MomentumSMoE introduces a new framework for Sparse Mixture of Experts by integrating momentum to enhance stability and robustness during training, demonstrating improved performance across various practical tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Optimizing Attention with Mirror Descent: Generalized Max-Margin Token Selection</title><link>https://arxiv.org/abs/2410.14581</link><description>https://arxiv.org/abs/2410.14581&lt;br /&gt;This paper explores the optimization dynamics and convergence properties of mirror descent algorithms for softmax attention mechanisms, demonstrating their effectiveness in token selection and generalization in classification tasks compared to traditional gradient descent methods.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Do LLMs estimate uncertainty well in instruction-following?</title><link>https://arxiv.org/abs/2410.14582</link><description>https://arxiv.org/abs/2410.14582&lt;br /&gt;This paper systematically evaluates the ability of large language models (LLMs) to estimate uncertainty while following instructions and identifies challenges in existing benchmarks, aiming to improve the reliability of LLMs in high-stakes applications.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>CELI: Controller-Embedded Language Model Interactions</title><link>https://arxiv.org/abs/2410.14627</link><description>https://arxiv.org/abs/2410.14627&lt;br /&gt;CELI introduces a framework that embeds control logic within language model prompts to enhance complex task execution and dynamic adaptation, leading to significant performance improvements in code generation and content creation tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples</title><link>https://arxiv.org/abs/2410.14669</link><description>https://arxiv.org/abs/2410.14669&lt;br /&gt;NaturalBench is a new benchmark for evaluating vision-language models (VLMs) using 10,000 human-verified visual-question-answering samples that highlight the models' struggles with natural images and complex reasoning, exposing significant biases and performance gaps compared to human understanding.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Improving Word Translation via Two-Stage Contrastive Learning</title><link>https://arxiv.org/abs/2203.08307</link><description>https://arxiv.org/abs/2203.08307&lt;br /&gt;This paper introduces a two-stage contrastive learning framework for improving bilingual lexicon induction (BLI), enhancing word translation by refining cross-lingual linear maps and fine-tuning mBERT to achieve substantial performance gains across multiple language pairs.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Improving Bilingual Lexicon Induction with Cross-Encoder Reranking</title><link>https://arxiv.org/abs/2210.16953</link><description>https://arxiv.org/abs/2210.16953&lt;br /&gt;The paper presents BLICEr, a novel semi-supervised post-hoc reranking method that enhances bilingual lexicon induction by combining cross-lingual word embeddings with semantic similarity scores from a fine-tuned multilingual pre-trained language model.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition</title><link>https://arxiv.org/abs/2302.08102</link><description>https://arxiv.org/abs/2302.08102&lt;br /&gt;The paper presents a method for improving speaker-adaptive Visual Speech Recognition (VSR) by using prompt tuning of Deep Neural Networks (DNNs), allowing the model to better adapt to unseen speakers with minimal adaptation data.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>I run as fast as a rabbit, can you? A Multilingual Simile Dialogue Dataset</title><link>https://arxiv.org/abs/2306.05672</link><description>https://arxiv.org/abs/2306.05672&lt;br /&gt;The paper introduces the Multilingual Simile Dialogue (MSD) dataset, the largest manually annotated simile data that facilitates the study of complex simile phenomena in dialogues, featuring tasks for simile recognition, interpretation, generation, and dialogue generation using English and Chinese data.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models</title><link>https://arxiv.org/abs/2306.15087</link><description>https://arxiv.org/abs/2306.15087&lt;br /&gt;WinoQueer is a benchmark created to assess and quantify the anti-LGBTQ+ bias present in large language models (LLMs), utilizing community input to generate the benchmark and demonstrating that bias can be mitigated by fine-tuning with data produced by community members.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Entity Matching using Large Language Models</title><link>https://arxiv.org/abs/2310.11244</link><description>https://arxiv.org/abs/2310.11244&lt;br /&gt;This paper explores the use of generative large language models (LLMs) for entity matching, demonstrating their reduced dependency on task-specific training data and increased robustness compared to traditional pre-trained language models (PLMs).</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>"We Demand Justice!": Towards Social Context Grounding of Political Texts</title><link>https://arxiv.org/abs/2311.09106</link><description>https://arxiv.org/abs/2311.09106&lt;br /&gt;This paper explores the social context necessary for understanding ambiguous political discourse on social media, proposing datasets to benchmark large pre-trained models and structured models in their capacity for contextual and pragmatic language understanding.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models</title><link>https://arxiv.org/abs/2402.13606</link><description>https://arxiv.org/abs/2402.13606&lt;br /&gt;This paper presents a comprehensive study of multilingual confidence estimation in Large Language Models (LLMs), highlighting the performance disparities across languages and introducing a native-tone prompting strategy to enhance reliability and accuracy on language-specific tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Framing in the Presence of Supporting Data: A Case Study in U.S. Economic News</title><link>https://arxiv.org/abs/2402.14224</link><description>https://arxiv.org/abs/2402.14224&lt;br /&gt;The paper presents a computational framework for analyzing editorial choices in U.S. economic news by framing prediction with objective measures derived from economic indicators, allowing for evaluation of how publications select and frame economic information from 2015 to 2023.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis</title><link>https://arxiv.org/abs/2403.01976</link><description>https://arxiv.org/abs/2403.01976&lt;br /&gt;SciAssess is a benchmarking framework that evaluates the proficiency of Large Language Models (LLMs) in analyzing scientific literature across various domains, focusing on their Memorization, Comprehension, and Analysis &amp; Reasoning capabilities.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>MaiBaam Annotation Guidelines</title><link>https://arxiv.org/abs/2403.05902</link><description>https://arxiv.org/abs/2403.05902&lt;br /&gt;The MaiBaam Annotation Guidelines document outlines the processes and principles for annotating the Bavarian corpus with part-of-speech tags and syntactic dependencies, contributing to the Universal Dependencies project.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>One size doesn't fit all: Predicting the Number of Examples for In-Context Learning</title><link>https://arxiv.org/abs/2403.06402</link><description>https://arxiv.org/abs/2403.06402&lt;br /&gt;The study introduces a dynamic approach to In-Context Learning (ICL) by predicting the optimal number of examples to use for each data instance in few-shot inference with Large Language Models (LLMs), leading to improved performance compared to standard ICL methods.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Efficiently Quantifying and Mitigating Ripple Effects in Model Editing</title><link>https://arxiv.org/abs/2403.07825</link><description>https://arxiv.org/abs/2403.07825&lt;br /&gt;This paper presents Graphical Impact Evaluation (GIE) and Selective Impact Revision (SIR) as methodologies to quantify and mitigate the ripple effects in model editing for Large Language Models, which can adversely affect model performance and editing tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Train &amp; Constrain: Phonologically Informed Tongue-Twister Generation from Topics and Paraphrases</title><link>https://arxiv.org/abs/2403.13901</link><description>https://arxiv.org/abs/2403.13901&lt;br /&gt;The paper introduces TwisterLister, a pipeline for generating English tongue twisters using phonologically informed methods, which utilizes a phonologically constrained vocabulary and large language models to create the largest annotated dataset of tongue twisters while maintaining semantic consistency and grammatical correctness.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Multi-Conditional Ranking with Large Language Models</title><link>https://arxiv.org/abs/2404.00211</link><description>https://arxiv.org/abs/2404.00211&lt;br /&gt;This paper introduces MCRank, a benchmark for evaluating large language models (LLMs) in the task of multi-conditional ranking, and presents a decomposed reasoning method (EXSIR) that significantly improves LLM performance on complex ranking tasks involving diverse conditions.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural Knowledge</title><link>https://arxiv.org/abs/2404.06833</link><description>https://arxiv.org/abs/2404.06833&lt;br /&gt;This research investigates the cultural biases present in Large Language Models (LLMs) concerning food-related knowledge, introducing the FmLAMA dataset to analyze LLM performance in both monolingual and multilingual settings, highlighting the influence of cultural context on LLMs' ability to access and accurately represent food-related cultural facts.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>What's under the hood: Investigating Automatic Metrics on Meeting Summarization</title><link>https://arxiv.org/abs/2404.11124</link><description>https://arxiv.org/abs/2404.11124&lt;br /&gt;This paper investigates the effectiveness of automatic metrics for evaluating meeting summarization, identifying their shortcomings in capturing meeting-specific errors and correlating these metrics with human evaluations across a detailed error taxonomy, revealing that existing metrics often mask important summarization errors.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding</title><link>https://arxiv.org/abs/2404.16710</link><description>https://arxiv.org/abs/2404.16710&lt;br /&gt;LayerSkip is an end-to-end solution designed to accelerate inference in large language models (LLMs) by employing layer dropout during training and a self-speculative decoding approach that allows for early exit inference, resulting in significant speedups without additional model complexity.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Everything is Editable: Extend Knowledge Editing to Unstructured Data in Large Language Models</title><link>https://arxiv.org/abs/2405.15349</link><description>https://arxiv.org/abs/2405.15349&lt;br /&gt;The paper proposes UnKE, a novel method for editing unstructured knowledge in large language models by introducing non-local block key-value storage and cause-driven optimization to improve representation and context preservation.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>PertEval: Unveiling Real Knowledge Capacity of LLMs with Knowledge-Invariant Perturbations</title><link>https://arxiv.org/abs/2405.19740</link><description>https://arxiv.org/abs/2405.19740&lt;br /&gt;PertEval is a toolkit designed to assess the knowledge capacity of large language models (LLMs) through knowledge-invariant perturbations, revealing significant overestimations in LLM performance on traditional benchmarks and providing insights for advancing their knowledge mastery.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>A Fundamental Trade-off in Aligned Language Models and its Relation to Sampling Adaptors</title><link>https://arxiv.org/abs/2406.10203</link><description>https://arxiv.org/abs/2406.10203&lt;br /&gt;This paper explores the trade-off between quality and probability in aligned language models, particularly focusing on how sampling adaptors can influence the balance between average reward and log-likelihood when samples are drawn from a model aligned to human preferences through reinforcement learning.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Error Span Annotation: A Balanced Approach for Human Evaluation of Machine Translation</title><link>https://arxiv.org/abs/2406.11580</link><description>https://arxiv.org/abs/2406.11580&lt;br /&gt;Error Span Annotation (ESA) is a new human evaluation protocol for machine translation that balances the efficiency of Direct Assessment with the detailed error classification of Multidimensional Quality Metrics, offering quicker and more cost-effective evaluations without needing expert involvement.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>LLM Critics Help Catch Bugs in Mathematics: Towards a Better Mathematical Verifier with Natural Language Feedback</title><link>https://arxiv.org/abs/2406.14024</link><description>https://arxiv.org/abs/2406.14024&lt;br /&gt;The paper presents Math-Minos, a natural language feedback-enhanced mathematical verifier that improves assessment accuracy of solutions by using step-wise natural language feedback instead of binary classification labels.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>MACAROON: Training Vision-Language Models To Be Your Engaged Partners</title><link>https://arxiv.org/abs/2406.14137</link><description>https://arxiv.org/abs/2406.14137&lt;br /&gt;MACAROON introduces a framework that enhances the proactive engagement capabilities of large vision-language models (LVLMs) by enabling them to autonomously generate contrastive response pairs to improve their interaction with ambiguous or personalizable questions.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Evaluating Contextualized Representations of (Spanish) Ambiguous Words: A New Lexical Resource and Empirical Analysis</title><link>https://arxiv.org/abs/2406.14678</link><description>https://arxiv.org/abs/2406.14678&lt;br /&gt;This paper evaluates how different BERT-based language models represent ambiguous Spanish nouns in context, providing a novel dataset for understanding their capacity to reflect human semantic judgments, and analyzing the influence of model architecture and size on performance.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>"Vorbe\c{s}ti Rom\^ane\c{s}te?" A Recipe to Train Powerful Romanian LLMs with English Instructions</title><link>https://arxiv.org/abs/2406.18266</link><description>https://arxiv.org/abs/2406.18266&lt;br /&gt;This paper presents the development and training of Romanian Large Language Models (RoLLMs) using a large collection of translated texts and benchmarks to achieve high performance and state-of-the-art results, aimed at improving LLM capabilities for Romanian and supporting research on low-resourced languages.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models</title><link>https://arxiv.org/abs/2407.02067</link><description>https://arxiv.org/abs/2407.02067&lt;br /&gt;The paper explores cultural understanding in Large Multimodal Models (LMMs) through a study involving a dataset of images and cultural artifact extraction, revealing disparities in cultural understanding and emphasizing the importance of culture-aware systems.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>P3: A Policy-Driven, Pace-Adaptive, and Diversity-Promoted Framework for data pruning in LLM Training</title><link>https://arxiv.org/abs/2408.05541</link><description>https://arxiv.org/abs/2408.05541&lt;br /&gt;P3 is an adaptive framework for fine-tuning Large Language Models (LLMs) that optimizes data pruning through policy-driven difficulty measurement, pace-adaptive selection, and diversity promotion, enhancing model performance on reasoning tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding</title><link>https://arxiv.org/abs/2409.03258</link><description>https://arxiv.org/abs/2409.03258&lt;br /&gt;GraphInsight is a framework designed to enhance Large Language Models' comprehension of graph structures by addressing positional biases in memory performance and leveraging an external knowledge base for improved understanding and multi-step reasoning in graph tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models</title><link>https://arxiv.org/abs/2409.14917</link><description>https://arxiv.org/abs/2409.14917&lt;br /&gt;The study investigates the ability of Vision Language Models (VLMs) and Large Language Models (LLMs) to understand sound symbolism through experiments that explore the connection between sounds and concepts by using visual and textual information.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>English offensive text detection using CNN based Bi-GRU model</title><link>https://arxiv.org/abs/2409.15652</link><description>https://arxiv.org/abs/2409.15652&lt;br /&gt;This paper presents a novel Bi-GRU-CNN model for automating the detection of offensive text on social media platforms, improving the classification of inappropriate content compared to existing models.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>A Modular-based Strategy for Mitigating Gradient Conflicts in Simultaneous Speech Translation</title><link>https://arxiv.org/abs/2409.15911</link><description>https://arxiv.org/abs/2409.15911&lt;br /&gt;The study introduces a Modular Gradient Conflict Mitigation (MGCM) strategy that detects and resolves optimization conflicts in Simultaneous Speech Translation (SimulST), leading to improved performance and significantly reduced GPU memory consumption.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding for Large Language Models</title><link>https://arxiv.org/abs/2409.19700</link><description>https://arxiv.org/abs/2409.19700&lt;br /&gt;The paper introduces 2D-TPE, a Two-Dimensional Positional Encoding method designed to enhance the ability of large language models (LLMs) in understanding table structures by preserving spatial relationships and improving performance on tabular data tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning</title><link>https://arxiv.org/abs/2410.02052</link><description>https://arxiv.org/abs/2410.02052&lt;br /&gt;ExACT presents a novel approach that combines Reflective Monte Carlo Tree Search and Exploratory Learning to enhance the decision-making capabilities of autonomous agents, particularly in complex multistep tasks, achieving significant performance improvements in various applications.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Contextual Document Embeddings</title><link>https://arxiv.org/abs/2410.02525</link><description>https://arxiv.org/abs/2410.02525&lt;br /&gt;This paper introduces two methods for creating contextualized document embeddings that enhance neural retrieval by considering both the target document and its neighboring documents, leading to improved performance over traditional biencoders.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Hyper-multi-step: The Truth Behind Difficult Long-context Tasks</title><link>https://arxiv.org/abs/2410.04422</link><description>https://arxiv.org/abs/2410.04422&lt;br /&gt;The paper investigates the challenges faced by Long-context Language Models (LCLMs) in completing difficult long-context tasks, identifying that the challenges primarily arise from 'multi-matching retrieval' and 'logic-based retrieval' requirements that exceed LCLMs' capabilities due to their hyper-multi-step nature.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization</title><link>https://arxiv.org/abs/2410.04717</link><description>https://arxiv.org/abs/2410.04717&lt;br /&gt;The paper investigates how the diversity of training instructions across various semantic domains affects the generalization abilities of large language models (LLMs) and provides guidelines for effective dataset collection for instruction-tuning.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing</title><link>https://arxiv.org/abs/2410.06331</link><description>https://arxiv.org/abs/2410.06331&lt;br /&gt;The paper presents IFMET, a novel locate-then-edit approach for knowledge editing in Large Language Models (LLMs), which enhances multi-hop factual recall by modifying both shallow and deep MLP layers to overcome limitations of previous methods.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Advocating Character Error Rate for Multilingual ASR Evaluation</title><link>https://arxiv.org/abs/2410.07400</link><description>https://arxiv.org/abs/2410.07400&lt;br /&gt;The paper advocates for the use of character error rate (CER) as the primary evaluation metric for multilingual automatic speech recognition (ASR) systems, highlighting its advantages over the traditional word error rate (WER) in accounting for the complexities of different languages.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>GUS-Net: Social Bias Classification in Text with Generalizations, Unfairness, and Stereotypes</title><link>https://arxiv.org/abs/2410.08388</link><description>https://arxiv.org/abs/2410.08388&lt;br /&gt;GUS-Net is a novel approach for detecting social biases in text, focusing on generalizations, unfairness, and stereotypes, utilizing generative AI and automated agents to create a synthetic dataset for improved multi-label token classification.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective</title><link>https://arxiv.org/abs/2410.10291</link><description>https://arxiv.org/abs/2410.10291&lt;br /&gt;The paper introduces a novel metric and benchmark for evaluating the causal relationship between semantic variations in linguistic inputs and outputs in text-to-image synthesis, highlighting the limitations of existing evaluation methods.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>FAME: Towards Factual Multi-Task Model Editing</title><link>https://arxiv.org/abs/2410.10859</link><description>https://arxiv.org/abs/2410.10859&lt;br /&gt;FAME introduces a factual, comprehensive, and multi-task dataset for model editing in large language models, along with SKEME, a novel editing method that employs a caching mechanism to improve synchronization with real-world information and enhance LLM capabilities in practical applications.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models</title><link>https://arxiv.org/abs/2410.12478</link><description>https://arxiv.org/abs/2410.12478&lt;br /&gt;MlingConf presents a comprehensive study of Multilingual Confidence Estimation on Large Language Models, revealing insights on language dominance and proposing a native-tone prompting strategy to enhance the reliability and accuracy of LLMs in different languages.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Comparative Analysis of Extrinsic Factors for NER in French</title><link>https://arxiv.org/abs/2410.12750</link><description>https://arxiv.org/abs/2410.12750&lt;br /&gt;This paper explores various extrinsic factors including model structure, corpus annotation schemes, and data augmentation techniques to enhance the performance of Named Entity Recognition (NER) models for the French language, demonstrating significant improvements in F1 scores with limited data.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>UniAutoML: A Human-Centered Framework for Unified Discriminative and Generative AutoML with Large Language Models</title><link>https://arxiv.org/abs/2410.12841</link><description>https://arxiv.org/abs/2410.12841&lt;br /&gt;UniAutoML is a human-centered AutoML framework that integrates Large Language Models to unify discriminative and generative tasks with a conversational user interface, enhancing user engagement, transparency, and control in the AutoML process.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework</title><link>https://arxiv.org/abs/2410.12855</link><description>https://arxiv.org/abs/2410.12855&lt;br /&gt;JAILJUDGE introduces a comprehensive benchmark for evaluating Large Language Model defenses against jailbreak attacks by providing a diverse set of risk scenarios and utilizing a Multi-Agent framework for explainable, fine-grained scoring.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>On Debiasing Text Embeddings Through Context Injection</title><link>https://arxiv.org/abs/2410.12874</link><description>https://arxiv.org/abs/2410.12874&lt;br /&gt;This paper reviews 19 embedding models to analyze their biases and the effectiveness of context injection for debiasing, revealing that higher-performing models are more prone to biases but also better at incorporating context, and it proposes a new algorithm for improved retrieval that addresses bias issues.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs</title><link>https://arxiv.org/abs/2410.13276</link><description>https://arxiv.org/abs/2410.13276&lt;br /&gt;SeerAttention introduces a novel adaptive attention mechanism for Large Language Models (LLMs) that learns attention sparsity dynamically, significantly improving efficiency and scalability for long-context language tasks while balancing accuracy and speedup.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>BANTH: A Multi-label Hate Speech Detection Dataset for Transliterated Bangla</title><link>https://arxiv.org/abs/2410.13281</link><description>https://arxiv.org/abs/2410.13281&lt;br /&gt;BANTH introduces the first multi-label hate speech detection dataset for transliterated Bangla, consisting of 37.3k samples sourced from YouTube comments, and establishes novel transformer encoder-based baselines that achieve state-of-the-art performance while addressing classification challenges in low-resource languages.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>BenTo: Benchmark Task Reduction with In-Context Transferability</title><link>https://arxiv.org/abs/2410.13804</link><description>https://arxiv.org/abs/2410.13804&lt;br /&gt;BenTo introduces a method for efficiently reducing the number of tasks used to benchmark large language models (LLMs) by utilizing task transferability and relevance to identify a representative subset, achieving significant task reduction while maintaining evaluation quality.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off</title><link>https://arxiv.org/abs/2403.04808</link><description>https://arxiv.org/abs/2403.04808&lt;br /&gt;WaterMax introduces a novel watermarking scheme for Large Language Models that achieves high watermark detectability while maintaining the quality of the generated text, overcoming the traditional quality-robustness trade-off in watermarking techniques.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Movie101v2: Improved Movie Narration Benchmark</title><link>https://arxiv.org/abs/2404.13370</link><description>https://arxiv.org/abs/2404.13370&lt;br /&gt;Movie101v2 introduces a large-scale, bilingual dataset and establishes a benchmark for automatic movie narration to support visually impaired audiences, focusing on generating video-aligned plot descriptions across multiple shots.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>On the Use of Large Language Models to Generate Capability Ontologies</title><link>https://arxiv.org/abs/2404.17524</link><description>https://arxiv.org/abs/2404.17524&lt;br /&gt;This paper investigates how Large Language Models (LLMs) can assist in the generation of capability ontologies by creating machine-interpretable models from natural language and evaluating the quality of generated ontologies through various experiments and checks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs</title><link>https://arxiv.org/abs/2406.02958</link><description>https://arxiv.org/abs/2406.02958&lt;br /&gt;PrE-Text is a method for generating differentially private synthetic textual data that allows small models to outperform traditional on-device training while requiring significantly less communication and computation, and also enhances the performance of large language models on private data.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Toward a Method to Generate Capability Ontologies from Natural Language Descriptions</title><link>https://arxiv.org/abs/2406.07962</link><description>https://arxiv.org/abs/2406.07962&lt;br /&gt;This paper presents an automated method for generating capability ontologies from natural language descriptions using Large Language Models (LLMs), which includes a looped verification process to ensure correctness and reduce manual effort.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>MolecularGPT: Open Large Language Model (LLM) for Few-Shot Molecular Property Prediction</title><link>https://arxiv.org/abs/2406.12950</link><description>https://arxiv.org/abs/2406.12950&lt;br /&gt;MolecularGPT introduces a fine-tuned large language model (LLM) for few-shot molecular property prediction, showcasing its ability to adapt to new tasks with minimal examples and outperforming traditional methods and standard LLMs in various evaluation metrics.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Amphista: Bi-directional Multi-head Decoding for Accelerating LLM Inference</title><link>https://arxiv.org/abs/2406.13170</link><description>https://arxiv.org/abs/2406.13170&lt;br /&gt;Amphista is a speculative decoding framework for Large Language Models (LLMs) that enhances inference speed through bi-directional multi-head decoding, achieving significant speedup while maintaining the quality of generated content.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>LatentExplainer: Explaining Latent Representations in Deep Generative Models with Multi-modal Foundation Models</title><link>https://arxiv.org/abs/2406.14862</link><description>https://arxiv.org/abs/2406.14862&lt;br /&gt;LatentExplainer is a framework that generates semantically meaningful explanations of latent variables in deep generative models by perturbing these variables and utilizing multi-modal large language models to produce human-understandable interpretations.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>From Introspection to Best Practices: Principled Analysis of Demonstrations in Multimodal In-Context Learning</title><link>https://arxiv.org/abs/2407.00902</link><description>https://arxiv.org/abs/2407.00902&lt;br /&gt;The paper presents a principled analysis of multimodal in-context learning (ICL) in Large Language Models (LLMs), exploring how different modalities affect task performance and recommending strategies for effective demonstrations to enhance ICL across various tasks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Dating ancient manuscripts using radiocarbon and AI-based writing style analysis</title><link>https://arxiv.org/abs/2407.12013</link><description>https://arxiv.org/abs/2407.12013&lt;br /&gt;The study presents Enoch, an AI-based model leveraging Bayesian ridge regression and handwriting style analysis to predict the dates of ancient manuscripts, particularly the Dead Sea Scrolls, achieving improved granularity and contributing to the chronology of historical texts.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Improving Retrieval in Sponsored Search by Leveraging Query Context Signals</title><link>https://arxiv.org/abs/2407.14346</link><description>https://arxiv.org/abs/2407.14346&lt;br /&gt;This paper presents an approach to enhance retrieval in Sponsored Search by utilizing query context signals from web search results and large language models to improve understanding of user intent, leading to better performance in retrieving relevant keywords for short, ambiguous queries.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>A Tighter Complexity Analysis of SparseGPT</title><link>https://arxiv.org/abs/2408.12151</link><description>https://arxiv.org/abs/2408.12151&lt;br /&gt;This paper presents an improved analysis of SparseGPT's running time, reducing it from $O(d^{3})$ to $O(d^{2.53})$ by examining the lazy update behavior in iterative maintenance problems.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>SciLitLLM: How to Adapt LLMs for Scientific Literature Understanding</title><link>https://arxiv.org/abs/2408.15545</link><description>https://arxiv.org/abs/2408.15545&lt;br /&gt;SciLitLLM is a framework that enhances Large Language Models (LLMs) for scientific literature understanding through continual pre-training and supervised fine-tuning, addressing challenges in knowledge infusion and instructional generation.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Supervised Fine-Tuning Achieve Rapid Task Adaption Via Alternating Attention Head Activation Patterns</title><link>https://arxiv.org/abs/2409.15820</link><description>https://arxiv.org/abs/2409.15820&lt;br /&gt;The paper explores how supervised fine-tuning (SFT) can enhance the rapid adaptation of Large Language Models (LLMs) to complex tasks by analyzing attention head activation patterns, revealing that selective activation of task-specific heads and parameter changes can improve task performance.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Fisher Information-based Efficient Curriculum Federated Learning with Large Language Models</title><link>https://arxiv.org/abs/2410.00131</link><description>https://arxiv.org/abs/2410.00131&lt;br /&gt;FibecFed is a Fisher Information-based framework that enhances the efficiency of Federated Learning for fine-tuning Large Language Models by implementing adaptive sampling and sparse parameter updates to reduce communication costs and improve training speed.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>System 2 thinking in OpenAI's o1-preview model: Near-perfect performance on a mathematics exam</title><link>https://arxiv.org/abs/2410.07114</link><description>https://arxiv.org/abs/2410.07114&lt;br /&gt;The study evaluates OpenAI's o1-preview model, which demonstrates near-perfect performance on a mathematics exam, indicating its capability for System 2-like reasoning, while also identifying variability in outputs and the importance of a self-consistency approach for improving accuracy.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>VLFeedback: A Large-Scale AI Feedback Dataset for Large Vision-Language Models Alignment</title><link>https://arxiv.org/abs/2410.09421</link><description>https://arxiv.org/abs/2410.09421&lt;br /&gt;VLFeedback introduces a large-scale dataset for AI feedback aimed at aligning large vision-language models (LVLMs), demonstrating improved performance in helpfulness, visual faithfulness, and safety, while addressing challenges such as hallucinations and vulnerability to adversarial attacks.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models</title><link>https://arxiv.org/abs/2410.09804</link><description>https://arxiv.org/abs/2410.09804&lt;br /&gt;BlackDAN is a multi-objective optimization framework designed to enhance the effectiveness and contextual relevance of jailbreak attacks on large language models (LLMs) while minimizing their detectability, utilizing Multiobjective Evolutionary Algorithms for prompt generation.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Learning Linear Attention in Polynomial Time</title><link>https://arxiv.org/abs/2410.10101</link><description>https://arxiv.org/abs/2410.10101&lt;br /&gt;This study demonstrates that single-layer Transformers with linear attention can be learned in polynomial time and provides insights into their theoretical expressivity and practical applications, including associative memories and finite automata.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis</title><link>https://arxiv.org/abs/2410.10270</link><description>https://arxiv.org/abs/2410.10270&lt;br /&gt;QUIS is a fully automated exploratory data analysis system that generates and refines questions to drive insight generation from large datasets, eliminating the need for human intervention and allowing for adaptability to new data.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Liger Kernel: Efficient Triton Kernels for LLM Training</title><link>https://arxiv.org/abs/2410.10989</link><description>https://arxiv.org/abs/2410.10989&lt;br /&gt;Liger Kernel introduces a set of optimized Triton kernels for efficient training of Large Language Models (LLMs), achieving significant improvements in training throughput and GPU memory usage.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Scaling laws for post-training quantized large language models</title><link>https://arxiv.org/abs/2410.12119</link><description>https://arxiv.org/abs/2410.12119&lt;br /&gt;This research paper investigates the predictability of post-training performance in quantized large language models (LLMs) by identifying scaling factors related to the local loss landscape, providing a statistical model for estimating their performance after compression.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>An Evolved Universal Transformer Memory</title><link>https://arxiv.org/abs/2410.13166</link><description>https://arxiv.org/abs/2410.13166&lt;br /&gt;The paper introduces Neural Attention Memory Models (NAMMs), which enhance the performance and efficiency of transformers by evolving memory management to focus on the most relevant information for attention layers, achieving significant improvements in long-context tasks and demonstrating general applicability across various transformer architectures.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>MoR: Mixture of Ranks for Low-Rank Adaptation Tuning</title><link>https://arxiv.org/abs/2410.13408</link><description>https://arxiv.org/abs/2410.13408&lt;br /&gt;MoR introduces a new framework for Low-Rank Adaptation that efficiently captures task-specific information and integrates multi-rank data to improve performance while reducing parameter usage in comparison to traditional methods.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Harnessing Webpage UIs for Text-Rich Visual Understanding</title><link>https://arxiv.org/abs/2410.13824</link><description>https://arxiv.org/abs/2410.13824&lt;br /&gt;The paper presents MultiUI, a dataset comprising 7.3 million samples from 1 million websites, which synthesizes multimodal instructions from webpage UIs to train models for improved text-rich visual understanding across various tasks, demonstrating significant performance enhancements in web UI and non-UI applications.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles</title><link>https://arxiv.org/abs/2410.14042</link><description>https://arxiv.org/abs/2410.14042&lt;br&gt;Style-Compress is a framework that enables a smaller language model to effectively compress prompts for larger models by utilizing task-specific styles, improving efficiency and performance across multiple tasks while significantly reducing computational costs.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion</title><link>https://arxiv.org/abs/2410.14405</link><description>https://arxiv.org/abs/2410.14405&lt;br&gt;The paper investigates the distinct behaviors of language models (LMs) in processing factual information through a model-specific framework called PrISM, revealing variations in model reliability across different prediction scenarios for fact completion.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas</title><link>https://arxiv.org/abs/2410.14255</link><description>https://arxiv.org/abs/2410.14255&lt;br&gt;Nova presents an iterative planning and search methodology that enhances the novelty and diversity of ideas generated by large language models (LLMs) by effectively retrieving and integrating external knowledge, resulting in a significant increase in the generation of unique and high-quality research ideas.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item><item><title>PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data</title><link>https://arxiv.org/abs/2406.15053</link><description>https://arxiv.org/abs/2406.15053&lt;br&gt;The paper investigates the agreement between human evaluators and Large Language Models (LLMs) on the assessment of multilingual models across various Indic languages, revealing differences in evaluation performance and biases.</description><pubDate>Mon, 21 Oct 2024 10:56:07 GMT</pubDate></item></channel></rss>