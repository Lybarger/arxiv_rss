<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Relevant arXiv Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss_relevant.xml</link><description>Relevant arXiv Papers</description><lastBuildDate>Mon, 21 Oct 2024 10:23:35 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs</title><link>https://arxiv.org/abs/2410.13987</link><description>https://arxiv.org/abs/2410.13987&lt;br&gt;RiTeK is a dataset designed to improve the ability of Large Language Models (LLMs) in complex reasoning tasks over textual knowledge graphs, particularly focusing on the medical domain and integrating an enhanced Monte Carlo Tree Search method for better relational path retrieval.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Generating Signed Language Instructions in Large-Scale Dialogue Systems</title><link>https://arxiv.org/abs/2410.14026</link><description>https://arxiv.org/abs/2410.14026&lt;br&gt;This paper presents a novel goal-oriented conversational AI system that generates American Sign Language instructions using retrieval methods and Large Language Models, enabling seamless interaction through a touch-based interface and supported by community engagement.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles</title><link>https://arxiv.org/abs/2410.14042</link><description>https://arxiv.org/abs/2410.14042&lt;br&gt;Style-Compress introduces a lightweight framework that enables smaller language models to efficiently compress prompts for larger models, improving performance on downstream tasks while reducing inference time and computational costs.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs</title><link>https://arxiv.org/abs/2410.14052</link><description>https://arxiv.org/abs/2410.14052&lt;br&gt;MemTree is an algorithm that introduces a dynamic, tree-structured memory representation to improve long-term memory management in large language models, allowing for better organization, retrieval, and integration of information, thus enhancing performance in complex reasoning tasks and multi-turn dialogue understanding.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>CAPE: A Chinese Dataset for Appraisal-based Emotional Generation using Large Language Models</title><link>https://arxiv.org/abs/2410.14145</link><description>https://arxiv.org/abs/2410.14145&lt;br&gt;CAPE introduces a Chinese dataset for appraisal-based emotional generation, enabling large language models to produce emotionally appropriate responses in conversations by considering various personal and situational factors.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>MetaAlign: Align Large Language Models with Diverse Preferences during Inference Time</title><link>https://arxiv.org/abs/2410.14184</link><description>https://arxiv.org/abs/2410.14184&lt;br&gt;MetaAlign is a proposed method that enables Large Language Models (LLMs) to dynamically align with diverse human preferences during inference time, overcoming the limitations of static alignment techniques such as Reinforcement Learning from Human Feedback (RLHF).</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations</title><link>https://arxiv.org/abs/2410.14204</link><description>https://arxiv.org/abs/2410.14204&lt;br&gt;MediTOD is a newly developed English dialogue dataset for medical history taking that includes comprehensive annotations for medical tasks, aiming to enhance the capabilities of dialogue systems in supporting doctors and improving patient interactions.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Paths-over-Graph: Knowledge Graph Enpowered Large Language Model Reasoning</title><link>https://arxiv.org/abs/2410.14211</link><description>https://arxiv.org/abs/2410.14211&lt;br&gt;Paths-over-Graph (PoG) is a novel method that enhances Large Language Model (LLM) reasoning by integrating knowledge reasoning paths from Knowledge Graphs (KGs), addressing multi-hop and multi-entity questions, and improving the interpretability and faithfulness of LLM outputs through a dynamic exploration process.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via Role Recognition and Involvement Measurement</title><link>https://arxiv.org/abs/2410.14259</link><description>https://arxiv.org/abs/2410.14259&lt;br&gt;This paper proposes a novel approach for detecting LLM-generated content that moves beyond binary classification through the introduction of LLM Role Recognition and LLM Influence Measurement, providing a benchmark for evaluating detection methods in various real-world scenarios.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>SwaQuAD-24: QA Benchmark Dataset in Swahili</title><link>https://arxiv.org/abs/2410.14289</link><description>https://arxiv.org/abs/2410.14289&lt;br&gt;The paper presents SwaQuAD-24, a Swahili Question Answering (QA) benchmark dataset designed to improve the representation of Swahili in natural language processing, featuring annotated question-answer pairs and focused on ethical considerations and future expansions.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Critical Questions Generation: Motivation and Challenges</title><link>https://arxiv.org/abs/2410.14335</link><description>https://arxiv.org/abs/2410.14335&lt;br&gt;This paper introduces Critical Questions Generation, a new task for Large Language Models (LLMs) focused on generating critical questions from argumentative texts to address issues of outdated knowledge and hallucinated content, ultimately enhancing the effectiveness of LLMs in argumentation analysis.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion</title><link>https://arxiv.org/abs/2410.14405</link><description>https://arxiv.org/abs/2410.14405&lt;br&gt;This paper investigates different prediction scenarios of language models (LMs) in relation to fact completion, highlighting variations in their reliability and the distinct types of information processed, and proposes a model-specific method for constructing datasets to better understand these behaviors.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions</title><link>https://arxiv.org/abs/2410.14567</link><description>https://arxiv.org/abs/2410.14567&lt;br&gt;RAG-ConfusionQA introduces a synthetic data generation method for creating context-grounded confusing questions, evaluates the performance of large language models in responding to these questions, and provides a benchmark dataset for improving Retrieval-Augmented Generation (RAG) agents.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Teaching Models to Balance Resisting and Accepting Persuasion</title><link>https://arxiv.org/abs/2410.14596</link><description>https://arxiv.org/abs/2410.14596&lt;br&gt;The paper introduces Persuasion-Balanced Training (PBT), a method for optimizing large language models to effectively balance resistance against negative persuasion while also being amenable to positive persuasion, thereby improving their performance in adversarial settings and multi-agent debates.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Diverging Preferences: When do Annotators Disagree and do Models Know?</title><link>https://arxiv.org/abs/2410.14632</link><description>https://arxiv.org/abs/2410.14632&lt;br&gt;This paper investigates the sources of disagreement in human-labeled preference datasets, highlighting how standard reward modeling methods and LLM evaluations struggle to account for this diverging feedback, which can affect the development of pluralistically aligned LLMs.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Real-time Fake News from Adversarial Feedback</title><link>https://arxiv.org/abs/2410.14651</link><description>https://arxiv.org/abs/2410.14651&lt;br&gt;The paper presents a novel pipeline that uses adversarial feedback to challenge LLM-based fake news detectors by modifying real-time news into deceptive fake news, revealing the vulnerabilities of retrieval-free models and showcasing the importance of retrieval-augmented generation in both detection and generation of fake news.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Enhancing Large Language Models' Situated Faithfulness to External Contexts</title><link>https://arxiv.org/abs/2410.14675</link><description>https://arxiv.org/abs/2410.14675&lt;br&gt;The paper presents approaches to enhance the situated faithfulness of Large Language Models (LLMs) by dynamically calibrating their trust in external information using Self-Guided Confidence Reasoning and Rule-Based Confidence Reasoning to improve their accuracy in question-answering tasks involving both correct and incorrect contexts.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>SoK: Prompt Hacking of Large Language Models</title><link>https://arxiv.org/abs/2410.13901</link><description>https://arxiv.org/abs/2410.13901&lt;br&gt;This paper provides a systematic overview of prompt hacking attacks on large language models (LLMs), categorizing them into jailbreaking, leaking, and injection, while proposing a new framework for evaluating LLM responses to improve the safety and robustness of LLM-based applications.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>FinQAPT: Empowering Financial Decisions with End-to-End LLM-driven Question Answering Pipeline</title><link>https://arxiv.org/abs/2410.13959</link><description>https://arxiv.org/abs/2410.13959&lt;br&gt;FinQAPT is an end-to-end LLM-driven question answering pipeline designed to enhance financial decision-making by effectively identifying and extracting relevant information from financial documents and optimizing LLM performance through clustering-based negative sampling and Dynamic N-shot Prompting.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Personalized Adaptation via In-Context Preference Learning</title><link>https://arxiv.org/abs/2410.14001</link><description>https://arxiv.org/abs/2410.14001&lt;br&gt;The paper presents the Preference Pretrained Transformer (PPT), a novel method for personalized adaptation in language models using reinforcement learning from human feedback and in-context learning to dynamically adjust to individual user preferences, demonstrating improved efficiency and effectiveness in a contextual bandit setting.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>From Barriers to Tactics: A Behavioral Science-Informed Agentic Workflow for Personalized Nutrition Coaching</title><link>https://arxiv.org/abs/2410.14041</link><description>https://arxiv.org/abs/2410.14041&lt;br&gt;This paper presents a novel LLM-powered workflow for personalized nutrition coaching that utilizes behavioral science to identify patient-specific barriers and provide tailored strategies for managing cardiometabolic conditions effectively.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>E3D-GPT: Enhanced 3D Visual Foundation for Medical Vision-Language Model</title><link>https://arxiv.org/abs/2410.14200</link><description>https://arxiv.org/abs/2410.14200&lt;br&gt;E3D-GPT is a 3D medical vision-language model that utilizes self-supervised learning and spatial convolutions to enhance the extraction of visual features from 3D CT scans, improving performance in report generation, visual question answering, and disease diagnosis.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas</title><link>https://arxiv.org/abs/2410.14255</link><description>https://arxiv.org/abs/2410.14255&lt;br&gt;The paper presents Nova, a novel iterative planning and search methodology that enhances the creativity and diversity of ideas generated by large language models (LLMs) by leveraging external knowledge, resulting in a significant increase in the number of unique and high-quality suggestions compared to existing methods.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Do LLMs "know" internally when they follow instructions?</title><link>https://arxiv.org/abs/2410.14516</link><description>https://arxiv.org/abs/2410.14516&lt;br&gt;This research investigates how the internal states of large language models (LLMs) influence their ability to follow instructions, revealing that specific dimensions in the input embedding space are crucial for successful instruction adherence, and that modifying these representations can enhance performance without degrading response quality.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>DiSCo Meets LLMs: A Unified Approach for Sparse Retrieval and Contextual Distillation in Conversational Search</title><link>https://arxiv.org/abs/2410.14609</link><description>https://arxiv.org/abs/2410.14609&lt;br&gt;The paper presents a novel distillation method that unifies retrieval and contextual modeling in Conversational Search using Large Language Models (LLMs), achieving significant improvements in retrieval performance through multi-teacher distillation and enhanced control over model sparsity.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Large Language Models, scientific knowledge and factuality: A framework to streamline human expert evaluation</title><link>https://arxiv.org/abs/2305.17819</link><description>https://arxiv.org/abs/2305.17819&lt;br&gt;This paper presents a framework for evaluating the factuality and coherence of Large Language Models (LLMs) in the context of biomedical knowledge, highlighting current limitations in accuracy while suggesting improvements through systematic assessments and human expert involvement.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue</title><link>https://arxiv.org/abs/2310.14626</link><description>https://arxiv.org/abs/2310.14626&lt;br&gt;This paper explores the synergistic collaboration between Conversational Recommender Systems (CRSs) and Large Language Models (LLMs) in E-commerce pre-sales dialogues, demonstrating that their combined strengths can enhance user interaction and recommendation accuracy.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Towards Verifiable Text Generation with Evolving Memory and Self-Reflection</title><link>https://arxiv.org/abs/2312.09075</link><description>https://arxiv.org/abs/2312.09075&lt;br&gt;The paper presents VTG, a framework for Verifiable Text Generation that leverages evolving memory and self-reflection to reduce factually incorrect information by integrating citations for accuracy verification and enhancing the precision and breadth of retrieved documents.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature</title><link>https://arxiv.org/abs/2405.04819</link><description>https://arxiv.org/abs/2405.04819&lt;br&gt;DALK is a framework that enhances the ability of large language models to answer questions about Alzheimer's Disease by dynamically co-augmenting them with a specialized knowledge graph sourced from scientific literature.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI: The First Romanian Natural Language Inference Corpus</title><link>https://arxiv.org/abs/2405.11877</link><description>https://arxiv.org/abs/2405.11877&lt;br&gt;This paper introduces the first Romanian Natural Language Inference (RoNLI) corpus and utilizes a novel cartography-based curriculum learning method to improve NLI models, facilitating advancements in natural language understanding tasks.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems</title><link>https://arxiv.org/abs/2405.15585</link><description>https://arxiv.org/abs/2405.15585&lt;br&gt;SyncTOD is an end-to-end Task-Oriented Dialog system that enhances large language models' performance in low-data settings by integrating task-specific hints and exemplar selection to improve response alignment and comprehension.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Improving Reward Models with Synthetic Critiques</title><link>https://arxiv.org/abs/2405.20850</link><description>https://arxiv.org/abs/2405.20850&lt;br&gt;The paper proposes a method to enhance reward models for aligning language models by using synthetic critiques generated by large language models, improving data efficiency, interpretability, and robustness while reducing reliance on human annotations.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>On Subjective Uncertainty Quantification and Calibration in Natural Language Generation</title><link>https://arxiv.org/abs/2406.05213</link><description>https://arxiv.org/abs/2406.05213&lt;br&gt;This paper discusses methods for quantifying and calibrating subjective uncertainty in natural language generation using Bayesian decision theory, focusing on task-specific calibration and providing evaluations in question answering and machine translation tasks.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Graph Neural Network Enhanced Retrieval for Question Answering of LLMs</title><link>https://arxiv.org/abs/2406.06572</link><description>https://arxiv.org/abs/2406.06572&lt;br&gt;The paper introduces GNN-Ret, a retrieval method that enhances question answering in large language models (LLMs) by leveraging graph neural networks to exploit relationships between passages, demonstrating improved accuracy in answering complex reasoning questions.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Towards Lifelong Dialogue Agents via Relation-aware Memory Construction and Timeline-augmented Response Generation</title><link>https://arxiv.org/abs/2406.10996</link><description>https://arxiv.org/abs/2406.10996&lt;br&gt;Theanine is a framework for LLM-based lifelong dialogue agents that utilizes relation-aware memory construction and memory timelines to enhance response generation by retaining and linking outdated contextual memories for improved long-term human-agent interaction.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Do Not Design, Learn: A Trainable Scoring Function for Uncertainty Estimation in Generative LLMs</title><link>https://arxiv.org/abs/2406.11278</link><description>https://arxiv.org/abs/2406.11278&lt;br&gt;The paper introduces Learnable Response Scoring (LARS), a novel scoring function for uncertainty estimation in generative large language models that improves the reliability of generated responses by effectively capturing complex dependencies between tokens and probabilities.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Can Few-shot Work in Long-Context? Recycling the Context to Generate Demonstrations</title><link>https://arxiv.org/abs/2406.13632</link><description>https://arxiv.org/abs/2406.13632&lt;br&gt;This paper presents a method to enhance the performance of Large Language Models (LLMs) on long-context question answering tasks by generating few-shot examples from the same context, thereby reducing token overhead and improving answer attribution.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation</title><link>https://arxiv.org/abs/2406.13663</link><description>https://arxiv.org/abs/2406.13663&lt;br&gt;MIRAGE is a plug-and-play approach that enhances answer attribution in retrieval-augmented generation (RAG) by using model internals to identify context-sensitive answer tokens and their corresponding supporting documents, achieving high agreement with human attribution in question answering tasks.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>AutoPal: Autonomous Adaptation to Users for Personal AI Companionship</title><link>https://arxiv.org/abs/2406.13960</link><description>https://arxiv.org/abs/2406.13960&lt;br&gt;AutoPal is a hierarchical framework designed to enhance personal AI companionship by enabling agents to autonomously adapt their persona based on user interactions, thereby providing tailored emotional support and effectively responding to users' changing needs.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data</title><link>https://arxiv.org/abs/2406.15053</link><description>https://arxiv.org/abs/2406.15053&lt;br&gt;PARIKSHA investigates the agreement between human and LLM evaluators in multilingual contexts, examining 30 models across 10 Indic languages and highlighting variances in evaluation outcomes and biases, thus contributing to the understanding of multilingual evaluation for Large Language Models.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Unveiling Entity-Level Unlearning for Large Language Models: A Comprehensive Analysis</title><link>https://arxiv.org/abs/2406.15796</link><description>https://arxiv.org/abs/2406.15796&lt;br&gt;This paper explores the concept of entity-level unlearning in large language models, addressing the limitations of current instance-level unlearning methods and investigating factors affecting the efficacy of unlearning algorithms with a focus on security and privacy implications.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs' Memorization</title><link>https://arxiv.org/abs/2407.03525</link><description>https://arxiv.org/abs/2407.03525&lt;br&gt;UnSeenTimeQA introduces a new benchmark for time-sensitive question-answering that tests large language models on their ability to perform temporal reasoning using synthetically generated facts, avoiding reliance on pre-trained factual knowledge.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations</title><link>https://arxiv.org/abs/2408.15232</link><description>https://arxiv.org/abs/2408.15232&lt;br&gt;Co-STORM is a collaborative language model framework that allows users to engage in conversations with LM agents to discover information about unknown unknowns, facilitating learning and interaction by organizing discourse into a dynamic mind map and generating comprehensive reports.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Modeling offensive content detection for TikTok</title><link>https://arxiv.org/abs/2408.16857</link><description>https://arxiv.org/abs/2408.16857&lt;br&gt;This research paper develops machine learning and deep learning models for detecting offensive content on TikTok by analyzing a large dataset of user comments, achieving an F1 score of 0.863 in a balanced binary classification approach.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Large Language Model Based Generative Error Correction: A Challenge and Baselines for Speech Recognition, Speaker Tagging, and Emotion Recognition</title><link>https://arxiv.org/abs/2409.09785</link><description>https://arxiv.org/abs/2409.09785&lt;br&gt;The paper introduces the GenSEC challenge, which focuses on enhancing acoustic modeling tasks in speech processing using large language models (LLMs) for post-ASR transcription correction, speaker tagging, and emotion recognition, while providing baseline evaluations and insights for future developments.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Understanding Likelihood Over-optimisation in Direct Alignment Algorithms</title><link>https://arxiv.org/abs/2410.11677</link><description>https://arxiv.org/abs/2410.11677&lt;br&gt;This paper investigates likelihood over-optimisation in Direct Alignment Algorithms (DAAs) for aligning language models to human preferences, revealing that higher generation likelihood does not always correlate with improved model performance and may lead to issues with output diversity and generalisation.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Open Domain Question Answering with Conflicting Contexts</title><link>https://arxiv.org/abs/2410.12311</link><description>https://arxiv.org/abs/2410.12311&lt;br&gt;This paper highlights the challenges of open domain question answering systems when faced with conflicting information retrieved from large text collections, presenting a dataset to evaluate LLMs' abilities and demonstrating the benefits of finetuning them to explain their reasoning.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning</title><link>https://arxiv.org/abs/2410.12847</link><description>https://arxiv.org/abs/2410.12847&lt;br&gt;ACCEPT introduces an Adaptive Codebook for Composite and Efficient Prompt Tuning that allows for parameter-efficient fine-tuning of large-scale pretrained Language Models (PLMs) by enabling shared learnable codebook vectors across prompts, achieving superior performance on various natural language tasks while tuning only a small fraction of parameters.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback</title><link>https://arxiv.org/abs/2410.13191</link><description>https://arxiv.org/abs/2410.13191&lt;br&gt;MCQG-SRefine is a framework that improves the generation of high-quality multiple-choice questions for professional medical exams by utilizing an iterative self-critique and correction process within large language models, along with an automatic evaluation metric to enhance quality and difficulty alignment with expert standards.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>ZeQR: Zero-shot Query Reformulation for Conversational Search</title><link>https://arxiv.org/abs/2307.09384</link><description>https://arxiv.org/abs/2307.09384&lt;br&gt;ZeQR introduces a Zero-shot Query Reformulation framework that enhances conversational search by resolving ambiguities in queries based on previous dialogue contexts without needing supervision, making it universally applicable and more explainable compared to existing methods.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models</title><link>https://arxiv.org/abs/2405.20680</link><description>https://arxiv.org/abs/2405.20680&lt;br&gt;This paper investigates the inconsistencies in performance between Retrieval-Augmented Large Language Models (RALMs) and traditional retrieval-free models, identifying key factors contributing to these inconsistencies, and introduces a new framework, Ensemble of Retrievers (EoR), to improve performance by adaptively retrieving from various knowledge sources.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item><item><title>Multi-LLM QA with Embodied Exploration</title><link>https://arxiv.org/abs/2406.10918</link><description>https://arxiv.org/abs/2406.10918&lt;br&gt;This research explores the use of multiple language model agents (Multi-Embodied LLM Explorers) for question-answering tasks in unknown environments through embodied exploration, demonstrating improved accuracy via a central answer module over traditional aggregation methods.</description><pubDate>Mon, 21 Oct 2024 10:23:35 GMT</pubDate></item></channel></rss>
