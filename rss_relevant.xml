<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Relevant arXiv Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss_relevant.xml</link><description>Relevant arXiv Papers</description><lastBuildDate>Tue, 22 Oct 2024 10:19:58 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs</title><link>https://arxiv.org/abs/2410.13987</link><description>https://arxiv.org/abs/2410.13987&lt;br /&gt;RiTeK is a dataset designed to improve the ability of Large Language Models (LLMs) in complex reasoning tasks over textual knowledge graphs, particularly focusing on the medical domain and integrating an enhanced Monte Carlo Tree Search method for better relational path retrieval.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Generating Signed Language Instructions in Large-Scale Dialogue Systems</title><link>https://arxiv.org/abs/2410.14026</link><description>https://arxiv.org/abs/2410.14026&lt;br /&gt;This paper presents a novel goal-oriented conversational AI system that generates American Sign Language instructions using retrieval methods and Large Language Models, enabling seamless interaction through a touch-based interface and supported by community engagement.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles</title><link>https://arxiv.org/abs/2410.14042</link><description>https://arxiv.org/abs/2410.14042&lt;br /&gt;Style-Compress introduces a lightweight framework that enables smaller language models to efficiently compress prompts for larger models, improving performance on downstream tasks while reducing inference time and computational costs.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs</title><link>https://arxiv.org/abs/2410.14052</link><description>https://arxiv.org/abs/2410.14052&lt;br /&gt;MemTree is an algorithm that introduces a dynamic, tree-structured memory representation to improve long-term memory management in large language models, allowing for better organization, retrieval, and integration of information, thus enhancing performance in complex reasoning tasks and multi-turn dialogue understanding.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>CAPE: A Chinese Dataset for Appraisal-based Emotional Generation using Large Language Models</title><link>https://arxiv.org/abs/2410.14145</link><description>https://arxiv.org/abs/2410.14145&lt;br /&gt;CAPE introduces a Chinese dataset for appraisal-based emotional generation, enabling large language models to produce emotionally appropriate responses in conversations by considering various personal and situational factors.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>MetaAlign: Align Large Language Models with Diverse Preferences during Inference Time</title><link>https://arxiv.org/abs/2410.14184</link><description>https://arxiv.org/abs/2410.14184&lt;br /&gt;MetaAlign is a proposed method that enables Large Language Models (LLMs) to dynamically align with diverse human preferences during inference time, overcoming the limitations of static alignment techniques such as Reinforcement Learning from Human Feedback (RLHF).</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>MediTOD: An English Dialogue Dataset for Medical History Taking with Comprehensive Annotations</title><link>https://arxiv.org/abs/2410.14204</link><description>https://arxiv.org/abs/2410.14204&lt;br /&gt;MediTOD is a newly developed English dialogue dataset for medical history taking that includes comprehensive annotations for medical tasks, aiming to enhance the capabilities of dialogue systems in supporting doctors and improving patient interactions.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Paths-over-Graph: Knowledge Graph Enpowered Large Language Model Reasoning</title><link>https://arxiv.org/abs/2410.14211</link><description>https://arxiv.org/abs/2410.14211&lt;br /&gt;Paths-over-Graph (PoG) is a novel method that enhances Large Language Model (LLM) reasoning by integrating knowledge reasoning paths from Knowledge Graphs (KGs), addressing multi-hop and multi-entity questions, and improving the interpretability and faithfulness of LLM outputs through a dynamic exploration process.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via Role Recognition and Involvement Measurement</title><link>https://arxiv.org/abs/2410.14259</link><description>https://arxiv.org/abs/2410.14259&lt;br /&gt;This paper proposes a novel approach for detecting LLM-generated content that moves beyond binary classification through the introduction of LLM Role Recognition and LLM Influence Measurement, providing a benchmark for evaluating detection methods in various real-world scenarios.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>SwaQuAD-24: QA Benchmark Dataset in Swahili</title><link>https://arxiv.org/abs/2410.14289</link><description>https://arxiv.org/abs/2410.14289&lt;br /&gt;The paper presents SwaQuAD-24, a Swahili Question Answering (QA) benchmark dataset designed to improve the representation of Swahili in natural language processing, featuring annotated question-answer pairs and focused on ethical considerations and future expansions.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Critical Questions Generation: Motivation and Challenges</title><link>https://arxiv.org/abs/2410.14335</link><description>https://arxiv.org/abs/2410.14335&lt;br /&gt;This paper introduces Critical Questions Generation, a new task for Large Language Models (LLMs) focused on generating critical questions from argumentative texts to address issues of outdated knowledge and hallucinated content, ultimately enhancing the effectiveness of LLMs in argumentation analysis.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Fact Recall, Heuristics or Pure Guesswork? Precise Interpretations of Language Models for Fact Completion</title><link>https://arxiv.org/abs/2410.14405</link><description>https://arxiv.org/abs/2410.14405&lt;br /&gt;This paper investigates different prediction scenarios of language models (LMs) in relation to fact completion, highlighting variations in their reliability and the distinct types of information processed, and proposes a model-specific method for constructing datasets to better understand these behaviors.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions</title><link>https://arxiv.org/abs/2410.14567</link><description>https://arxiv.org/abs/2410.14567&lt;br /&gt;RAG-ConfusionQA introduces a synthetic data generation method for creating context-grounded confusing questions, evaluates the performance of large language models in responding to these questions, and provides a benchmark dataset for improving Retrieval-Augmented Generation (RAG) agents.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Teaching Models to Balance Resisting and Accepting Persuasion</title><link>https://arxiv.org/abs/2410.14596</link><description>https://arxiv.org/abs/2410.14596&lt;br /&gt;The paper introduces Persuasion-Balanced Training (PBT), a method for optimizing large language models to effectively balance resistance against negative persuasion while also being amenable to positive persuasion, thereby improving their performance in adversarial settings and multi-agent debates.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Diverging Preferences: When do Annotators Disagree and do Models Know?</title><link>https://arxiv.org/abs/2410.14632</link><description>https://arxiv.org/abs/2410.14632&lt;br /&gt;This paper investigates the sources of disagreement in human-labeled preference datasets, highlighting how standard reward modeling methods and LLM evaluations struggle to account for this diverging feedback, which can affect the development of pluralistically aligned LLMs.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Real-time Fake News from Adversarial Feedback</title><link>https://arxiv.org/abs/2410.14651</link><description>https://arxiv.org/abs/2410.14651&lt;br /&gt;The paper presents a novel pipeline that uses adversarial feedback to challenge LLM-based fake news detectors by modifying real-time news into deceptive fake news, revealing the vulnerabilities of retrieval-free models and showcasing the importance of retrieval-augmented generation in both detection and generation of fake news.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Enhancing Large Language Models' Situated Faithfulness to External Contexts</title><link>https://arxiv.org/abs/2410.14675</link><description>https://arxiv.org/abs/2410.14675&lt;br /&gt;The paper presents approaches to enhance the situated faithfulness of Large Language Models (LLMs) by dynamically calibrating their trust in external information using Self-Guided Confidence Reasoning and Rule-Based Confidence Reasoning to improve their accuracy in question-answering tasks involving both correct and incorrect contexts.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>SoK: Prompt Hacking of Large Language Models</title><link>https://arxiv.org/abs/2410.13901</link><description>https://arxiv.org/abs/2410.13901&lt;br /&gt;This paper provides a systematic overview of prompt hacking attacks on large language models (LLMs), categorizing them into jailbreaking, leaking, and injection, while proposing a new framework for evaluating LLM responses to improve the safety and robustness of LLM-based applications.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>FinQAPT: Empowering Financial Decisions with End-to-End LLM-driven Question Answering Pipeline</title><link>https://arxiv.org/abs/2410.13959</link><description>https://arxiv.org/abs/2410.13959&lt;br /&gt;FinQAPT is an end-to-end LLM-driven question answering pipeline designed to enhance financial decision-making by effectively identifying and extracting relevant information from financial documents and optimizing LLM performance through clustering-based negative sampling and Dynamic N-shot Prompting.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Personalized Adaptation via In-Context Preference Learning</title><link>https://arxiv.org/abs/2410.14001</link><description>https://arxiv.org/abs/2410.14001&lt;br /&gt;The paper presents the Preference Pretrained Transformer (PPT), a novel method for personalized adaptation in language models using reinforcement learning from human feedback and in-context learning to dynamically adjust to individual user preferences, demonstrating improved efficiency and effectiveness in a contextual bandit setting.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>From Barriers to Tactics: A Behavioral Science-Informed Agentic Workflow for Personalized Nutrition Coaching</title><link>https://arxiv.org/abs/2410.14041</link><description>https://arxiv.org/abs/2410.14041&lt;br /&gt;This paper presents a novel LLM-powered workflow for personalized nutrition coaching that utilizes behavioral science to identify patient-specific barriers and provide tailored strategies for managing cardiometabolic conditions effectively.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>E3D-GPT: Enhanced 3D Visual Foundation for Medical Vision-Language Model</title><link>https://arxiv.org/abs/2410.14200</link><description>https://arxiv.org/abs/2410.14200&lt;br /&gt;E3D-GPT is a 3D medical vision-language model that utilizes self-supervised learning and spatial convolutions to enhance the extraction of visual features from 3D CT scans, improving performance in report generation, visual question answering, and disease diagnosis.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas</title><link>https://arxiv.org/abs/2410.14255</link><description>https://arxiv.org/abs/2410.14255&lt;br /&gt;The paper presents Nova, a novel iterative planning and search methodology that enhances the creativity and diversity of ideas generated by large language models (LLMs) by leveraging external knowledge, resulting in a significant increase in the number of unique and high-quality suggestions compared to existing methods.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Do LLMs "know" internally when they follow instructions?</title><link>https://arxiv.org/abs/2410.14516</link><description>https://arxiv.org/abs/2410.14516&lt;br /&gt;This research investigates how the internal states of large language models (LLMs) influence their ability to follow instructions, revealing that specific dimensions in the input embedding space are crucial for successful instruction adherence, and that modifying these representations can enhance performance without degrading response quality.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>DiSCo Meets LLMs: A Unified Approach for Sparse Retrieval and Contextual Distillation in Conversational Search</title><link>https://arxiv.org/abs/2410.14609</link><description>https://arxiv.org/abs/2410.14609&lt;br /&gt;The paper presents a novel distillation method that unifies retrieval and contextual modeling in Conversational Search using Large Language Models (LLMs), achieving significant improvements in retrieval performance through multi-teacher distillation and enhanced control over model sparsity.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Large Language Models, scientific knowledge and factuality: A framework to streamline human expert evaluation</title><link>https://arxiv.org/abs/2305.17819</link><description>https://arxiv.org/abs/2305.17819&lt;br /&gt;This paper presents a framework for evaluating the factuality and coherence of Large Language Models (LLMs) in the context of biomedical knowledge, highlighting current limitations in accuracy while suggesting improvements through systematic assessments and human expert involvement.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue</title><link>https://arxiv.org/abs/2310.14626</link><description>https://arxiv.org/abs/2310.14626&lt;br /&gt;This paper explores the synergistic collaboration between Conversational Recommender Systems (CRSs) and Large Language Models (LLMs) in E-commerce pre-sales dialogues, demonstrating that their combined strengths can enhance user interaction and recommendation accuracy.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Towards Verifiable Text Generation with Evolving Memory and Self-Reflection</title><link>https://arxiv.org/abs/2312.09075</link><description>https://arxiv.org/abs/2312.09075&lt;br /&gt;The paper presents VTG, a framework for Verifiable Text Generation that leverages evolving memory and self-reflection to reduce factually incorrect information by integrating citations for accuracy verification and enhancing the precision and breadth of retrieved documents.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature</title><link>https://arxiv.org/abs/2405.04819</link><description>https://arxiv.org/abs/2405.04819&lt;br /&gt;DALK is a framework that enhances the ability of large language models to answer questions about Alzheimer's Disease by dynamically co-augmenting them with a specialized knowledge graph sourced from scientific literature.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>A Novel Cartography-Based Curriculum Learning Method Applied on RoNLI: The First Romanian Natural Language Inference Corpus</title><link>https://arxiv.org/abs/2405.11877</link><description>https://arxiv.org/abs/2405.11877&lt;br /&gt;This paper introduces the first Romanian Natural Language Inference (RoNLI) corpus and utilizes a novel cartography-based curriculum learning method to improve NLI models, facilitating advancements in natural language understanding tasks.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems</title><link>https://arxiv.org/abs/2405.15585</link><description>https://arxiv.org/abs/2405.15585&lt;br /&gt;SyncTOD is an end-to-end Task-Oriented Dialog system that enhances large language models' performance in low-data settings by integrating task-specific hints and exemplar selection to improve response alignment and comprehension.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Improving Reward Models with Synthetic Critiques</title><link>https://arxiv.org/abs/2405.20850</link><description>https://arxiv.org/abs/2405.20850&lt;br /&gt;The paper proposes a method to enhance reward models for aligning language models by using synthetic critiques generated by large language models, improving data efficiency, interpretability, and robustness while reducing reliance on human annotations.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>On Subjective Uncertainty Quantification and Calibration in Natural Language Generation</title><link>https://arxiv.org/abs/2406.05213</link><description>https://arxiv.org/abs/2406.05213&lt;br /&gt;This paper discusses methods for quantifying and calibrating subjective uncertainty in natural language generation using Bayesian decision theory, focusing on task-specific calibration and providing evaluations in question answering and machine translation tasks.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Graph Neural Network Enhanced Retrieval for Question Answering of LLMs</title><link>https://arxiv.org/abs/2406.06572</link><description>https://arxiv.org/abs/2406.06572&lt;br /&gt;The paper introduces GNN-Ret, a retrieval method that enhances question answering in large language models (LLMs) by leveraging graph neural networks to exploit relationships between passages, demonstrating improved accuracy in answering complex reasoning questions.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Towards Lifelong Dialogue Agents via Relation-aware Memory Construction and Timeline-augmented Response Generation</title><link>https://arxiv.org/abs/2406.10996</link><description>https://arxiv.org/abs/2406.10996&lt;br /&gt;Theanine is a framework for LLM-based lifelong dialogue agents that utilizes relation-aware memory construction and memory timelines to enhance response generation by retaining and linking outdated contextual memories for improved long-term human-agent interaction.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Do Not Design, Learn: A Trainable Scoring Function for Uncertainty Estimation in Generative LLMs</title><link>https://arxiv.org/abs/2406.11278</link><description>https://arxiv.org/abs/2406.11278&lt;br /&gt;The paper introduces Learnable Response Scoring (LARS), a novel scoring function for uncertainty estimation in generative large language models that improves the reliability of generated responses by effectively capturing complex dependencies between tokens and probabilities.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Can Few-shot Work in Long-Context? Recycling the Context to Generate Demonstrations</title><link>https://arxiv.org/abs/2406.13632</link><description>https://arxiv.org/abs/2406.13632&lt;br /&gt;This paper presents a method to enhance the performance of Large Language Models (LLMs) on long-context question answering tasks by generating few-shot examples from the same context, thereby reducing token overhead and improving answer attribution.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Model Internals-based Answer Attribution for Trustworthy Retrieval-Augmented Generation</title><link>https://arxiv.org/abs/2406.13663</link><description>https://arxiv.org/abs/2406.13663&lt;br /&gt;MIRAGE is a plug-and-play approach that enhances answer attribution in retrieval-augmented generation (RAG) by using model internals to identify context-sensitive answer tokens and their corresponding supporting documents, achieving high agreement with human attribution in question answering tasks.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>AutoPal: Autonomous Adaptation to Users for Personal AI Companionship</title><link>https://arxiv.org/abs/2406.13960</link><description>https://arxiv.org/abs/2406.13960&lt;br /&gt;AutoPal is a hierarchical framework designed to enhance personal AI companionship by enabling agents to autonomously adapt their persona based on user interactions, thereby providing tailored emotional support and effectively responding to users' changing needs.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>PARIKSHA: A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data</title><link>https://arxiv.org/abs/2406.15053</link><description>https://arxiv.org/abs/2406.15053&lt;br /&gt;PARIKSHA investigates the agreement between human and LLM evaluators in multilingual contexts, examining 30 models across 10 Indic languages and highlighting variances in evaluation outcomes and biases, thus contributing to the understanding of multilingual evaluation for Large Language Models.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Unveiling Entity-Level Unlearning for Large Language Models: A Comprehensive Analysis</title><link>https://arxiv.org/abs/2406.15796</link><description>https://arxiv.org/abs/2406.15796&lt;br /&gt;This paper explores the concept of entity-level unlearning in large language models, addressing the limitations of current instance-level unlearning methods and investigating factors affecting the efficacy of unlearning algorithms with a focus on security and privacy implications.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs' Memorization</title><link>https://arxiv.org/abs/2407.03525</link><description>https://arxiv.org/abs/2407.03525&lt;br /&gt;UnSeenTimeQA introduces a new benchmark for time-sensitive question-answering that tests large language models on their ability to perform temporal reasoning using synthetically generated facts, avoiding reliance on pre-trained factual knowledge.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Into the Unknown Unknowns: Engaged Human Learning through Participation in Language Model Agent Conversations</title><link>https://arxiv.org/abs/2408.15232</link><description>https://arxiv.org/abs/2408.15232&lt;br /&gt;Co-STORM is a collaborative language model framework that allows users to engage in conversations with LM agents to discover information about unknown unknowns, facilitating learning and interaction by organizing discourse into a dynamic mind map and generating comprehensive reports.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Modeling offensive content detection for TikTok</title><link>https://arxiv.org/abs/2408.16857</link><description>https://arxiv.org/abs/2408.16857&lt;br /&gt;This research paper develops machine learning and deep learning models for detecting offensive content on TikTok by analyzing a large dataset of user comments, achieving an F1 score of 0.863 in a balanced binary classification approach.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Large Language Model Based Generative Error Correction: A Challenge and Baselines for Speech Recognition, Speaker Tagging, and Emotion Recognition</title><link>https://arxiv.org/abs/2409.09785</link><description>https://arxiv.org/abs/2409.09785&lt;br /&gt;The paper introduces the GenSEC challenge, which focuses on enhancing acoustic modeling tasks in speech processing using large language models (LLMs) for post-ASR transcription correction, speaker tagging, and emotion recognition, while providing baseline evaluations and insights for future developments.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Understanding Likelihood Over-optimisation in Direct Alignment Algorithms</title><link>https://arxiv.org/abs/2410.11677</link><description>https://arxiv.org/abs/2410.11677&lt;br /&gt;This paper investigates likelihood over-optimisation in Direct Alignment Algorithms (DAAs) for aligning language models to human preferences, revealing that higher generation likelihood does not always correlate with improved model performance and may lead to issues with output diversity and generalisation.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Open Domain Question Answering with Conflicting Contexts</title><link>https://arxiv.org/abs/2410.12311</link><description>https://arxiv.org/abs/2410.12311&lt;br /&gt;This paper highlights the challenges of open domain question answering systems when faced with conflicting information retrieved from large text collections, presenting a dataset to evaluate LLMs' abilities and demonstrating the benefits of finetuning them to explain their reasoning.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning</title><link>https://arxiv.org/abs/2410.12847</link><description>https://arxiv.org/abs/2410.12847&lt;br /&gt;ACCEPT introduces an Adaptive Codebook for Composite and Efficient Prompt Tuning that allows for parameter-efficient fine-tuning of large-scale pretrained Language Models (PLMs) by enabling shared learnable codebook vectors across prompts, achieving superior performance on various natural language tasks while tuning only a small fraction of parameters.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback</title><link>https://arxiv.org/abs/2410.13191</link><description>https://arxiv.org/abs/2410.13191&lt;br /&gt;MCQG-SRefine is a framework that improves the generation of high-quality multiple-choice questions for professional medical exams by utilizing an iterative self-critique and correction process within large language models, along with an automatic evaluation metric to enhance quality and difficulty alignment with expert standards.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>ZeQR: Zero-shot Query Reformulation for Conversational Search</title><link>https://arxiv.org/abs/2307.09384</link><description>https://arxiv.org/abs/2307.09384&lt;br /&gt;ZeQR introduces a Zero-shot Query Reformulation framework that enhances conversational search by resolving ambiguities in queries based on previous dialogue contexts without needing supervision, making it universally applicable and more explainable compared to existing methods.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models</title><link>https://arxiv.org/abs/2405.20680</link><description>https://arxiv.org/abs/2405.20680&lt;br /&gt;This paper investigates the inconsistencies in performance between Retrieval-Augmented Large Language Models (RALMs) and traditional retrieval-free models, identifying key factors contributing to these inconsistencies, and introduces a new framework, Ensemble of Retrievers (EoR), to improve performance by adaptively retrieving from various knowledge sources.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Multi-LLM QA with Embodied Exploration</title><link>https://arxiv.org/abs/2406.10918</link><description>https://arxiv.org/abs/2406.10918&lt;br /&gt;This research explores the use of multiple language model agents (Multi-Embodied LLM Explorers) for question-answering tasks in unknown environments through embodied exploration, demonstrating improved accuracy via a central answer module over traditional aggregation methods.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Boosting LLM Translation Skills without General Ability Loss via Rationale Distillation</title><link>https://arxiv.org/abs/2410.13944</link><description>https://arxiv.org/abs/2410.13944&lt;br /&gt;The paper introduces RaDis (Rationale Distillation), a novel approach to improve machine translation in Large Language Models (LLMs) by using self-generated rationales to preserve general abilities and safety while enhancing translation performance.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>LabSafety Bench: Benchmarking LLMs on Safety Issues in Scientific Labs</title><link>https://arxiv.org/abs/2410.14182</link><description>https://arxiv.org/abs/2410.14182&lt;br /&gt;LabSafety Bench is a benchmarking framework that evaluates the performance of large language models (LLMs) on safety issues in scientific laboratories, revealing their critical errors and the necessity for specialized assessments in safety-critical contexts.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models</title><link>https://arxiv.org/abs/2410.14248</link><description>https://arxiv.org/abs/2410.14248&lt;br /&gt;This paper investigates and addresses selection bias in Multiple-Choice Question Answering for Video Language Models, introducing a calibration technique called BOLD to improve model performance and reduce reliance on arbitrary patterns during evaluation.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>LoGU: Long-form Generation with Uncertainty Expressions</title><link>https://arxiv.org/abs/2410.14309</link><description>https://arxiv.org/abs/2410.14309&lt;br /&gt;LoGU introduces a framework for Long-form Generation with Uncertainty that improves Large Language Models' ability to express uncertainty and reduce hallucinations by employing a two-stage training approach and a data collection framework focused on refining uncertainty for accurate long responses.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Are AI Detectors Good Enough? A Survey on Quality of Datasets With Machine-Generated Texts</title><link>https://arxiv.org/abs/2410.14677</link><description>https://arxiv.org/abs/2410.14677&lt;br /&gt;This paper surveys the quality of datasets used for training AI detectors of machine-generated texts and highlights the need for robust evaluation methods to ensure the reliability of these detectors, which may be overstated due to poor dataset quality.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>ViConsFormer: Constituting Meaningful Phrases of Scene Texts using Transformer-based Method in Vietnamese Text-based Visual Question Answering</title><link>https://arxiv.org/abs/2410.14132</link><description>https://arxiv.org/abs/2410.14132&lt;br /&gt;ViConsFormer introduces a novel transformer-based method for improving text-based visual question answering (VQA) by effectively utilizing the meanings of scene texts in Vietnamese, achieving state-of-the-art results on relevant datasets.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Coherence-Driven Multimodal Safety Dialogue with Active Learning for Embodied Agents</title><link>https://arxiv.org/abs/2410.14141</link><description>https://arxiv.org/abs/2410.14141&lt;br /&gt;M-CoDAL is a coherence-driven multimodal dialogue system for embodied agents that enhances safety communication by leveraging discourse coherence and a novel active learning mechanism, shown to improve user sentiment and response efficacy in safety-critical scenarios.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Do LLMs estimate uncertainty well in instruction-following?</title><link>https://arxiv.org/abs/2410.14582</link><description>https://arxiv.org/abs/2410.14582&lt;br /&gt;This research evaluates the uncertainties in large language models' (LLMs) ability to follow user instructions, revealing significant limitations and challenges in current methods for estimating these uncertainties, ultimately highlighting the need for more reliable AI agents in critical applications.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>A Fundamental Trade-off in Aligned Language Models and its Relation to Sampling Adaptors</title><link>https://arxiv.org/abs/2406.10203</link><description>https://arxiv.org/abs/2406.10203&lt;br /&gt;This paper investigates the trade-off between the quality and probability of strings generated by aligned language models, revealing how sampling adaptors can strategically balance the average reward and the average log-likelihood to optimize performance based on human preferences.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework</title><link>https://arxiv.org/abs/2410.12855</link><description>https://arxiv.org/abs/2410.12855&lt;br /&gt;JAILJUDGE is a comprehensive benchmark for evaluating LLM defenses against jailbreak attacks, introducing a multi-agent framework for explainable evaluation and enhancing model performance through advanced evaluation methods and diverse risk scenarios.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>BenTo: Benchmark Task Reduction with In-Context Transferability</title><link>https://arxiv.org/abs/2410.13804</link><description>https://arxiv.org/abs/2410.13804&lt;br /&gt;BenTo proposes a method for efficiently reducing benchmark tasks for evaluating large language models (LLMs) by assessing task transferability and relevance without compromising evaluation quality, enabling a significant reduction in tasks while maintaining near-identical evaluation outcomes.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Agent Skill Acquisition for Large Language Models via CycleQD</title><link>https://arxiv.org/abs/2410.14735</link><description>https://arxiv.org/abs/2410.14735&lt;br /&gt;The study fine-tunes pre-trained large language models (LLMs) on veterinary electronic health records to automate clinical diagnosis coding using standardized SNOMED-CT codes, achieving superior performance compared to previous methods.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>SemiEvol: Semi-supervised Fine-tuning for LLM Adaptation</title><link>https://arxiv.org/abs/2410.14745</link><description>https://arxiv.org/abs/2410.14745&lt;br /&gt;The paper investigates vulnerabilities of large language models (LLMs) in producing dangerous chemical synthesis instructions, introducing SMILES-prompting as a new technique that bypasses existing safety mechanisms, highlighting the need for improved safeguards in chemistry-related LLM applications.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Accounting for Sycophancy in Language Model Uncertainty Estimation</title><link>https://arxiv.org/abs/2410.14746</link><description>https://arxiv.org/abs/2410.14746&lt;br /&gt;This paper presents a method for real-time, continuous backchannel prediction in conversations using a fine-tuned Voice Activity Projection model, improving the naturalness and engagement of dialogue systems by accurately predicting backchannel utterances.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Effects of Soft-Domain Transfer and Named Entity Information on Deception Detection</title><link>https://arxiv.org/abs/2410.14814</link><description>https://arxiv.org/abs/2410.14814&lt;br /&gt;This survey provides a comprehensive overview of Emotion Recognition in Conversations (ERC), discussing the advancements, challenges, and various methodologies used in the field, including the application of neural architectures and the impact of data imbalances and subjectivity in emotion annotations.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Transit Pulse: Utilizing Social Media as a Source for Customer Feedback and Information Extraction with Large Language Model</title><link>https://arxiv.org/abs/2410.15016</link><description>https://arxiv.org/abs/2410.15016&lt;br /&gt;This study demonstrates the effectiveness of fine-tuning large language models (LLMs) on veterinary health records to automate the coding of diagnoses using standardized medical terminologies, achieving improved accuracy compared to prior methods.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>DM-Codec: Distilling Multimodal Representations for Speech Tokenization</title><link>https://arxiv.org/abs/2410.15017</link><description>https://arxiv.org/abs/2410.15017&lt;br /&gt;This study demonstrates the effective fine-tuning of large language models to automate the coding of veterinary diagnoses from electronic health records, leading to improved interoperability and quality of veterinary medical records.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>A Survey of Ontology Expansion for Conversational Understanding</title><link>https://arxiv.org/abs/2410.15019</link><description>https://arxiv.org/abs/2410.15019&lt;br /&gt;This study fine-tunes ten pre-trained large language models (LLMs) on veterinary health records to automate the coding of diagnoses using the complete set of 7,739 SNOMED-CT codes, significantly enhancing the accuracy and interoperability of veterinary medical records.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Theoretical Aspects of Bias and Diversity in Minimum Bayes Risk Decoding</title><link>https://arxiv.org/abs/2410.15021</link><description>https://arxiv.org/abs/2410.15021&lt;br /&gt;This study demonstrates the fine-tuning of pre-trained large language models (LLMs) to automate the coding of veterinary diagnoses from electronic health records, achieving superior performance in standardizing medical terminologies to improve interoperability in veterinary and human health research.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Enhancing Multimodal Sentiment Analysis for Missing Modality through Self-Distillation and Unified Modality Cross-Attention</title><link>https://arxiv.org/abs/2410.15029</link><description>https://arxiv.org/abs/2410.15029&lt;br /&gt;This study investigates the fine-tuning of large language models (LLMs) to automate the coding of veterinary diagnoses from clinical records, achieving improved accuracy using a comprehensive set of SNOMED-CT diagnosis codes and highlighting the potential for integrating veterinary and human health records.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Improving General Text Embedding Model: Tackling Task Conflict and Data Imbalance through Model Merging</title><link>https://arxiv.org/abs/2410.15035</link><description>https://arxiv.org/abs/2410.15035&lt;br /&gt;This study demonstrates the effective fine-tuning of ten pre-trained large language models (LLMs) to automate the coding of veterinary diagnoses from clinical notes, resulting in improved accuracy and interoperability of veterinary health records using standardized medical terminologies.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>mHumanEval -- A Multilingual Benchmark to Evaluate Large Language Models for Code Generation</title><link>https://arxiv.org/abs/2410.15037</link><description>https://arxiv.org/abs/2410.15037&lt;br /&gt;This study demonstrates the effectiveness of fine-tuning pre-trained large language models (LLMs) on veterinary health records to automate the coding of diagnoses using the full range of SNOMED-CT codes, resulting in improved accuracy and interoperability in veterinary electronic health records.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Are LLMs Good Zero-Shot Fallacy Classifiers?</title><link>https://arxiv.org/abs/2410.15050</link><description>https://arxiv.org/abs/2410.15050&lt;br /&gt;This study investigates the fine-tuning of pre-trained large language models (LLMs) to automate the coding of veterinary diagnoses from electronic health records (EHRs), achieving superior performance by integrating extensive labeled data while also demonstrating methods that can produce comparable results with limited resources.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Weakly-supervised diagnosis identification from Italian discharge letters</title><link>https://arxiv.org/abs/2410.15051</link><description>https://arxiv.org/abs/2410.15051&lt;br /&gt;This study fine-tunes pre-trained large language models (LLMs) to automate the coding of veterinary diagnoses from electronic health records, demonstrating enhanced performance in coding accuracy for a broad range of standardized medical terminology (SNOMED-CT) through the use of expansive labeled datasets.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Toward Robust RALMs: Revealing the Impact of Imperfect Retrieval on Retrieval-Augmented Language Models</title><link>https://arxiv.org/abs/2410.15107</link><description>https://arxiv.org/abs/2410.15107&lt;br /&gt;This study explores fine-tuning pre-trained large language models (LLMs) to automate the coding of veterinary diagnoses from electronic health records, achieving superior performance by incorporating all distinct SNOMED-CT codes and leveraging both expansive labeled data and limited resources.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models</title><link>https://arxiv.org/abs/2410.15116</link><description>https://arxiv.org/abs/2410.15116&lt;br /&gt;This study explores the fine-tuning of pre-trained large language models (LLMs) to automate the coding of veterinary diagnoses from clinical notes, significantly improving the quality and interoperability of veterinary electronic health records (EHRs) while facilitating integrated health research for both animals and humans.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>MELT: Materials-aware Continued Pre-training for Language Model Adaptation to Materials Science</title><link>https://arxiv.org/abs/2410.15126</link><description>https://arxiv.org/abs/2410.15126&lt;br /&gt;This study fine-tunes pre-trained large language models (LLMs) on veterinary health records to automate the coding of diagnoses using standardized terms, significantly improving the quality and interoperability of veterinary electronic health records (EHRs) for clinical research.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Augmenting the Veracity and Explanations of Complex Fact Checking via Iterative Self-Revision with LLMs</title><link>https://arxiv.org/abs/2410.15135</link><description>https://arxiv.org/abs/2410.15135&lt;br /&gt;This study demonstrates the effectiveness of fine-tuning large language models (LLMs) on veterinary health records to automate the coding of veterinary diagnoses using the SNOMED-CT medical terminology, leading to improved quality and interoperability of electronic health records.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>CAST: Corpus-Aware Self-similarity Enhanced Topic modelling</title><link>https://arxiv.org/abs/2410.15136</link><description>https://arxiv.org/abs/2410.15136&lt;br /&gt;This study explores the fine-tuning of ten pre-trained large language models (LLMs) to automate the coding of veterinary diagnoses from health records, achieving improved performance and interoperability in veterinary clinical data by utilizing the full set of SNOMED-CT codes.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>A survey of neural-network-based methods utilising comparable data for finding translation equivalents</title><link>https://arxiv.org/abs/2410.15144</link><description>https://arxiv.org/abs/2410.15144&lt;br /&gt;This study investigates the fine-tuning of large language models (LLMs) to automatically code veterinary diagnosis from clinical notes, demonstrating improved accuracy and interoperability of veterinary health records by utilizing all available SNOMED-CT diagnosis codes and enhancing integration with human health databases.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Less is More: Parameter-Efficient Selection of Intermediate Tasks for Transfer Learning</title><link>https://arxiv.org/abs/2410.15148</link><description>https://arxiv.org/abs/2410.15148&lt;br /&gt;This study demonstrates the fine-tuning of pre-trained large language models (LLMs) to automate the coding of veterinary diagnoses from medical records, significantly improving the quality and interoperability of electronic health records in veterinary medicine.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Evaluating Deep Unlearning in Large Language Models</title><link>https://arxiv.org/abs/2410.15153</link><description>https://arxiv.org/abs/2410.15153&lt;br /&gt;This study demonstrates the fine-tuning of large language models on veterinary health records to automate the coding of diagnoses, achieving improved accuracy in clinical coding using standardized medical terminologies while addressing interoperability challenges in veterinary and human health records.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making</title><link>https://arxiv.org/abs/2410.15168</link><description>https://arxiv.org/abs/2410.15168&lt;br /&gt;This study demonstrates the fine-tuning of pre-trained large language models (LLMs) on veterinary health records to automate the coding of diagnoses using standardized medical terminologies, significantly improving the quality and interoperability of veterinary electronic health records.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Uncovering Autoregressive LLM Knowledge of Thematic Fit in Event Representation</title><link>https://arxiv.org/abs/2410.15173</link><description>https://arxiv.org/abs/2410.15173&lt;br /&gt;This study demonstrates the effective fine-tuning of large language models (LLMs) to automate the coding of veterinary diagnoses from clinical notes, improving interoperability and data quality in veterinary health records using a comprehensive set of standardized terminology.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Fine-tuning foundational models to code diagnoses from veterinary health records</title><link>https://arxiv.org/abs/2410.15186</link><description>https://arxiv.org/abs/2410.15186&lt;br /&gt;This study demonstrates the successful fine-tuning of pre-trained large language models (LLMs) to automate the coding of veterinary diagnoses from diverse clinical records, significantly improving the quality and interoperability of veterinary electronic health records.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Neural Search Space in Gboard Decoder</title><link>https://arxiv.org/abs/2410.15575</link><description>https://arxiv.org/abs/2410.15575&lt;br /&gt;The paper discusses the vulnerabilities of large language models (LLMs) in chemistry regarding their ability to provide dangerous synthesis instructions, introducing a new attack technique called SMILES-prompting that successfully bypasses existing safety mechanisms.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>AMPLE: Emotion-Aware Multimodal Fusion Prompt Learning for Fake News Detection</title><link>https://arxiv.org/abs/2410.15591</link><description>https://arxiv.org/abs/2410.15591&lt;br /&gt;This study investigates the security vulnerabilities of large language models (LLMs) in the field of chemistry and introduces a novel attack technique called SMILES-prompting, which can bypass existing safety mechanisms to potentially provide instructions for synthesizing hazardous substances.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Selecting Influential Samples for Long Context Alignment via Homologous Models' Guidance and Contextual Awareness Measurement</title><link>https://arxiv.org/abs/2410.15633</link><description>https://arxiv.org/abs/2410.15633&lt;br /&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in chemistry, introducing a novel attack method called SMILES-prompting that demonstrates the capacity to bypass safety measures and provide instructions for synthesizing hazardous substances, thereby underscoring the need for improved safeguards.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Resource-Efficient Medical Report Generation using Large Language Models</title><link>https://arxiv.org/abs/2410.15642</link><description>https://arxiv.org/abs/2410.15642&lt;br /&gt;This paper introduces a novel method for continuous and real-time backchannel prediction in conversations using a fine-tuned Voice Activity Projection (VAP) model, significantly enhancing the naturalness of conversational agents by accurately predicting backchannel utterances.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Scalable Data Ablation Approximations for Language Models through Modular Training and Merging</title><link>https://arxiv.org/abs/2410.15661</link><description>https://arxiv.org/abs/2410.15661&lt;br /&gt;This paper presents a method for continuous backchannel prediction in conversations using a fine-tuned Voice Activity Projection model, significantly enhancing the responsiveness of conversational agents by accurately predicting short utterances that signal attentiveness and understanding in real-time.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>RAC: Efficient LLM Factuality Correction with Retrieval Augmentation</title><link>https://arxiv.org/abs/2410.15667</link><description>https://arxiv.org/abs/2410.15667&lt;br /&gt;This paper introduces a method for continuous and real-time prediction of backchannel utterances in conversations using a fine-tuned Voice Activity Projection model, enhancing the responsiveness of conversational agents.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Learning to Generate and Evaluate Fact-checking Explanations with Transformers</title><link>https://arxiv.org/abs/2410.15669</link><description>https://arxiv.org/abs/2410.15669&lt;br /&gt;This paper presents a method for continuous and real-time prediction of backchannel utterances in human conversations using a fine-tuned Voice Activity Projection model, enhancing the responsiveness and naturalness of conversational agents.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Revealing and Mitigating the Local Pattern Shortcuts of Mamba</title><link>https://arxiv.org/abs/2410.15678</link><description>https://arxiv.org/abs/2410.15678&lt;br /&gt;This paper presents a method for real-time backchannel prediction in conversations using a fine-tuned Voice Activity Projection model, improving the timing and type prediction of backchannel utterances, which are critical for creating more natural conversational agents.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>DomainSum: A Hierarchical Benchmark for Fine-Grained Domain Shift in Abstractive Text Summarization</title><link>https://arxiv.org/abs/2410.15687</link><description>https://arxiv.org/abs/2410.15687&lt;br /&gt;This paper introduces a method for real-time prediction of backchannel utterances in conversations using a fine-tuned Voice Activity Projection model, significantly improving dialogue systems' naturalness and responsiveness.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Efficient Terminology Integration for LLM-based Translation in Specialized Domains</title><link>https://arxiv.org/abs/2410.15690</link><description>https://arxiv.org/abs/2410.15690&lt;br /&gt;This paper presents a novel method for real-time continuous backchannel prediction using a fine-tuned Voice Activity Projection model, enhancing the responsiveness and human-likeness of conversational agents in dialogue systems.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Tokenization as Finite-State Transduction</title><link>https://arxiv.org/abs/2410.15696</link><description>https://arxiv.org/abs/2410.15696&lt;br /&gt;This paper introduces a fine-tuned Voice Activity Projection (VAP) model for real-time, continuous prediction of backchannel utterances in conversations, enhancing the responsiveness of conversational agents in interactive spoken dialogue applications.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Mitigating Hallucinations of Large Language Models in Medical Information Extraction via Contrastive Decoding</title><link>https://arxiv.org/abs/2410.15702</link><description>https://arxiv.org/abs/2410.15702&lt;br /&gt;This paper presents a novel method for real-time prediction of backchannel utterances in conversations using a fine-tuned Voice Activity Projection model, enhancing natural interactions in dialogue systems and interactive spoken applications.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Reducing annotator bias by belief elicitation</title><link>https://arxiv.org/abs/2410.15726</link><description>https://arxiv.org/abs/2410.15726&lt;br /&gt;The paper presents a method for continuous real-time backchannel prediction using a fine-tuned Voice Activity Projection model, which enhances the naturalness of conversational agents by accurately predicting short vocal acknowledgments that facilitate smooth dialogue.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Who's Who: Large Language Models Meet Knowledge Conflicts in Practice</title><link>https://arxiv.org/abs/2410.15737</link><description>https://arxiv.org/abs/2410.15737&lt;br /&gt;This paper presents a novel method for real-time, continuous backchannel prediction in conversations using a fine-tuned Voice Activity Projection (VAP) model, aiming to enhance the naturalness of dialogue systems by accurately predicting short utterances that signal attentiveness.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Toeing the Party Line: Election Manifestos as a Key to Understand Political Discourse on Twitter</title><link>https://arxiv.org/abs/2410.15743</link><description>https://arxiv.org/abs/2410.15743&lt;br /&gt;This paper introduces a novel Voice Activity Projection model for real-time, continuous prediction of backchannel utterances in conversations, significantly enhancing the responsiveness of conversational agents.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Natural Language Querying System Through Entity Enrichment</title><link>https://arxiv.org/abs/2410.15753</link><description>https://arxiv.org/abs/2410.15753&lt;br /&gt;This paper introduces a fine-tuned Voice Activity Projection (VAP) model for real-time backchannel prediction in conversations, enhancing the responsiveness of dialogue systems by accurately predicting short utterances like 'yeah' and 'oh' in a continuous manner on unbalanced, real-world datasets.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Learning-to-Defer for Extractive Question Answering</title><link>https://arxiv.org/abs/2410.15761</link><description>https://arxiv.org/abs/2410.15761&lt;br /&gt;This paper presents a novel method for predicting backchannel utterances in real-time conversations using a fine-tuned Voice Activity Projection (VAP) model, improving the responsiveness and naturalness of dialogue systems.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Improve Dense Passage Retrieval with Entailment Tuning</title><link>https://arxiv.org/abs/2410.15801</link><description>https://arxiv.org/abs/2410.15801&lt;br /&gt;This paper presents a method for real-time continuous prediction of backchannel utterances using a fine-tuned Voice Activity Projection model, aimed at enhancing the naturalness of conversational agents by accurately predicting the timing and type of backchannels in dialogue.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Did somebody say "Gest-IT"? A pilot exploration of multimodal data management</title><link>https://arxiv.org/abs/2410.15825</link><description>https://arxiv.org/abs/2410.15825&lt;br /&gt;This paper introduces a real-time, continuous backchannel prediction method using a fine-tuned Voice Activity Projection model, which enhances the responsiveness and naturalness of conversational agents by predicting short utterances like 'yeah' and 'oh' in dialogue.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Principles of semantic and functional efficiency in grammatical patterning</title><link>https://arxiv.org/abs/2410.15865</link><description>https://arxiv.org/abs/2410.15865&lt;br /&gt;This paper presents a new method for real-time and continuous prediction of backchannel utterances in conversations using a fine-tuned Voice Activity Projection model, enhancing the naturalness of dialogue systems by accurately predicting backchannels like 'yeah' and 'oh'.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Using GPT Models for Qualitative and Quantitative News Analytics in the 2024 US Presidental Election Process</title><link>https://arxiv.org/abs/2410.15884</link><description>https://arxiv.org/abs/2410.15884&lt;br /&gt;The paper presents a new method for real-time prediction of backchannel utterances in conversations using a fine-tuned Voice Activity Projection model, enhancing the naturalness of dialogue systems by predicting timing and type of backchannels in a continuous manner.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>DefVerify: Do Hate Speech Models Reflect Their Dataset's Definition?</title><link>https://arxiv.org/abs/2410.15911</link><description>https://arxiv.org/abs/2410.15911&lt;br /&gt;This paper presents a method for real-time backchannel prediction in conversations by utilizing a fine-tuned Voice Activity Projection (VAP) model, enhancing the responsiveness and naturalness of conversational agents.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection</title><link>https://arxiv.org/abs/2410.15929</link><description>https://arxiv.org/abs/2410.15929&lt;br /&gt;This paper introduces a method for continuous real-time prediction of backchannel utterances in conversations using a fine-tuned Voice Activity Projection (VAP) model, enhancing the responsiveness and naturalness of conversational agents.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>BrainTransformers: SNN-LLM</title><link>https://arxiv.org/abs/2410.14687</link><description>https://arxiv.org/abs/2410.14687&lt;br /&gt;ChitroJera introduces a large-scale, regionally relevant Visual Question Answering dataset for the Bangla language, addressing the lack of appropriate benchmarks and showing improved performance of dual-encoder models and large language models on multimodal tasks.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Polymath: A Challenging Multi-modal Mathematical Reasoning Benchmark</title><link>https://arxiv.org/abs/2410.14702</link><description>https://arxiv.org/abs/2410.14702&lt;br /&gt;ChitroJera is a large-scale Visual Question Answering (VQA) dataset for Bangla, featuring over 15,000 samples from diverse local sources and designed to improve the performance of models in this low-resource language by addressing the lack of regionally relevant data.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>QuAILoRA: Quantization-Aware Initialization for LoRA</title><link>https://arxiv.org/abs/2410.14713</link><description>https://arxiv.org/abs/2410.14713&lt;br /&gt;ChitroJera is a large-scale visual question answering dataset designed for the Bangla language, comprising over 15,000 samples that leverage diverse and locally relevant data sources to facilitate improved performance in multimodal models and LLMs on VQA tasks.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>A Systematic Survey on Large Language Models for Algorithm Design</title><link>https://arxiv.org/abs/2410.14716</link><description>https://arxiv.org/abs/2410.14716&lt;br /&gt;ChitroJera is a comprehensive visual question answering dataset for Bangla, addressing the lack of culturally relevant benchmarks in this low-resource language by providing over 15,000 samples and demonstrating improved performance with dual-encoder and large language models using prompt-based techniques.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Rethinking Token Reduction for State Space Models</title><link>https://arxiv.org/abs/2410.14725</link><description>https://arxiv.org/abs/2410.14725&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering dataset specifically designed for the Bangla language, addressing the need for regionally relevant resources by providing over 15,000 samples that enhance the performance of various models in VQA tasks.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Tokens on Demand: Token Condensation as Training-free Test-time Adaptation</title><link>https://arxiv.org/abs/2410.14729</link><description>https://arxiv.org/abs/2410.14729&lt;br /&gt;ChitroJera is a large-scale, regionally relevant Visual Question Answering dataset for Bangla, consisting of over 15,000 samples that target local cultural nuances and assess various models for improved performance in multimodal tasks.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>MatryoshkaKV: Adaptive KV Compression via Trainable Orthogonal Projection</title><link>https://arxiv.org/abs/2410.14731</link><description>https://arxiv.org/abs/2410.14731&lt;br /&gt;ChitroJera is a comprehensive visual question answering dataset for the Bangla language, designed to improve the performance of models in this domain by providing culturally relevant and diverse examples.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Knowledge Graph Embeddings: A Comprehensive Survey on Capturing Relation Properties</title><link>https://arxiv.org/abs/2410.14733</link><description>https://arxiv.org/abs/2410.14733&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering dataset designed for the Bangla language, featuring over 15k samples and addressing the lack of culturally relevant VQA resources for this language.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries</title><link>https://arxiv.org/abs/2410.14748</link><description>https://arxiv.org/abs/2410.14748&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering dataset for the Bangla language, comprising over 15,000 samples that are regionally relevant and aimed at improving the performance of Vision-Language models in a low-resource language context.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>TimeSeriesExam: A time series understanding exam</title><link>https://arxiv.org/abs/2410.14752</link><description>https://arxiv.org/abs/2410.14752&lt;br /&gt;ChitroJera is a comprehensive visual question answering dataset designed for the Bangla language, addressing the scarcity of culturally relevant resources by providing over 15,000 samples that improve the performance of vision-language models in this underrepresented language context.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Collaboratively adding new knowledge to an LLM</title><link>https://arxiv.org/abs/2410.14753</link><description>https://arxiv.org/abs/2410.14753&lt;br /&gt;ChitroJera is a large-scale Visual Question Answering dataset specifically designed for the Bangla language, comprising over 15,000 samples from diverse and locally relevant sources, aimed at improving the performance of models in Vision-Language tasks while addressing the lack of culturally relevant data in the field.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>What's New in My Data? Novelty Exploration via Contrastive Generation</title><link>https://arxiv.org/abs/2410.14765</link><description>https://arxiv.org/abs/2410.14765&lt;br /&gt;ChitroJera is a new large-scale Visual Question Answering dataset designed for the Bangla language, which includes over 15k samples derived from diverse and locally relevant sources, aiming to enhance model performance in VQA tasks specific to Bangla culture and context.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Making LLMs Vulnerable to Prompt Injection via Poisoning Alignment</title><link>https://arxiv.org/abs/2410.14827</link><description>https://arxiv.org/abs/2410.14827&lt;br /&gt;ChitroJera is a novel large-scale Visual Question Answering dataset designed for the Bangla language, containing over 15,000 samples that utilize locally relevant data and surpass existing models in performance through the use of dual-encoder architectures and large language models with prompt-based techniques.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Class-RAG: Content Moderation with Retrieval Augmented Generation</title><link>https://arxiv.org/abs/2410.14881</link><description>https://arxiv.org/abs/2410.14881&lt;br /&gt;ChitroJera introduces a large-scale Visual Question Answering (VQA) dataset specifically designed for the Bangla language, addressing the lack of culturally relevant benchmarks in this area and demonstrating enhanced performance with novel dual-encoder models and prompt-based techniques using large language models (LLMs).</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>A Hybrid Defense Strategy for Boosting Adversarial Robustness in Vision-Language Models</title><link>https://arxiv.org/abs/2410.14911</link><description>https://arxiv.org/abs/2410.14911&lt;br /&gt;ChitroJera is a new large-scale Visual Question Answering dataset designed for the Bangla language, consisting of over 15,000 samples that enhance regional relevance and performance of models for VQA tasks in a low-resource language context.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Baichuan Alignment Technical Report</title><link>https://arxiv.org/abs/2410.14940</link><description>https://arxiv.org/abs/2410.14940&lt;br /&gt;ChitroJera is a large-scale Visual Question Answering dataset specifically for the Bangla language, designed to enhance the evaluation of models on culturally relevant visual contexts and improve performance on Vision-Language tasks in low-resource settings.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>BrainECHO: Semantic Brain Signal Decoding through Vector-Quantized Spectrogram Reconstruction for Whisper-Enhanced Text Generation</title><link>https://arxiv.org/abs/2410.14971</link><description>https://arxiv.org/abs/2410.14971&lt;br /&gt;ChitroJera is a large-scale Visual Question Answering dataset designed for the Bangla language, featuring over 15,000 culturally relevant samples and demonstrating that dual-encoder models and large language models can achieve improved performance in VQA tasks compared to other text and image encoders.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Do Large Language Models Truly Grasp Mathematics? An Empirical Exploration</title><link>https://arxiv.org/abs/2410.14979</link><description>https://arxiv.org/abs/2410.14979&lt;br /&gt;ChitroJera is a newly introduced large-scale Visual Question Answering dataset for Bangla that contains over 15,000 samples and aims to improve the cultural relevance and performance of VQA models in this language by utilizing diverse and locally relevant data sources.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>ChitroJera: A Regionally Relevant Visual Question Answering Dataset for Bangla</title><link>https://arxiv.org/abs/2410.14991</link><description>https://arxiv.org/abs/2410.14991&lt;br /&gt;ChitroJera is a comprehensive visual question answering dataset for the Bangla language, featuring over 15,000 samples sourced from diverse and culturally relevant materials, thus addressing the shortage of localized VQA datasets for low-resource languages.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Language Models are Symbolic Learners in Arithmetic</title><link>https://arxiv.org/abs/2410.15580</link><description>https://arxiv.org/abs/2410.15580&lt;br /&gt;This survey reviews advancements in Emotion Recognition in Conversations (ERC), addressing challenges such as emotional dynamics, real-time processing, interpretability, and dataset imbalances, while also highlighting effective practices and neural architectures used in the field.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>CPE-Pro: A Structure-Sensitive Deep Learning Model for Protein Representation and Origin Evaluation</title><link>https://arxiv.org/abs/2410.15592</link><description>https://arxiv.org/abs/2410.15592&lt;br /&gt;This survey provides a comprehensive overview of Emotion Recognition in Conversations (ERC), addressing the advancements, challenges, techniques, and datasets in the field, with a focus on improving human-machine interaction through effective emotion understanding.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>A Comprehensive Survey of Datasets, Theories, Variants, and Applications in Direct Preference Optimization</title><link>https://arxiv.org/abs/2410.15595</link><description>https://arxiv.org/abs/2410.15595&lt;br /&gt;This survey reviews advances in Emotion Recognition in Conversations (ERC), outlining challenges, opportunities, emotion taxonomies, benchmark datasets, prominent works, and effective practices while emphasizing the benefits of using pre-trained models and addressing issues like unbalanced datasets and annotation subjectivity.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Moonshine: Speech Recognition for Live Transcription and Voice Commands</title><link>https://arxiv.org/abs/2410.15608</link><description>https://arxiv.org/abs/2410.15608&lt;br /&gt;This survey provides an extensive overview of Emotion Recognition in Conversations (ERC), discussing its challenges, opportunities, various emotion taxonomies, benchmark datasets, and key methods like pre-trained transformer models, while emphasizing the importance of addressing data imbalances and incorporating subjectivity in annotations for improving performance.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Acoustic Model Optimization over Multiple Data Sources: Merging and Valuation</title><link>https://arxiv.org/abs/2410.15620</link><description>https://arxiv.org/abs/2410.15620&lt;br /&gt;This survey provides a comprehensive overview of Emotion Recognition in Conversations (ERC), discussing its challenges, advancements, taxonomies, datasets, and various neural architectures while highlighting best practices and the importance of addressing issues like annotation subjectivity and unbalanced data.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Improving Parallel Program Performance Through DSL-Driven Code Generation with LLM Optimizers</title><link>https://arxiv.org/abs/2410.15625</link><description>https://arxiv.org/abs/2410.15625&lt;br /&gt;This survey on Emotion Recognition in Conversations (ERC) discusses advancements, challenges, and opportunities in the field, highlighting key issues such as emotion dynamics, context, and the use of neural architectures, while providing an overview of existing benchmarks and best practices for improving ERC frameworks.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>CL-HOI: Cross-Level Human-Object Interaction Distillation from Vision Large Language Models</title><link>https://arxiv.org/abs/2410.15657</link><description>https://arxiv.org/abs/2410.15657&lt;br /&gt;This survey provides a comprehensive overview of Emotion Recognition in Conversations (ERC), discussing its challenges, opportunities, various emotion taxonomies, benchmark datasets, and comparing methodologies including neural architectures and handling unbalanced data in ERC.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>InternLM2.5-StepProver: Advancing Automated Theorem Proving via Expert Iteration on Large-Scale LEAN Problems</title><link>https://arxiv.org/abs/2410.15700</link><description>https://arxiv.org/abs/2410.15700&lt;br /&gt;This survey reviews the advancements and challenges in Emotion Recognition in Conversations (ERC), highlighting key areas such as emotion dynamics, speaker context, and the impact of informal language, while discussing various neural architectures and methods to improve ERC performance across different datasets.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Mitigating Object Hallucination via Concentric Causal Attention</title><link>https://arxiv.org/abs/2410.15926</link><description>https://arxiv.org/abs/2410.15926&lt;br /&gt;This survey provides a comprehensive overview of Emotion Recognition in Conversations (ERC), discussing challenges, opportunities, methodologies, and various datasets, while emphasizing the need for better practices to address issues like annotation subjectivity and dataset imbalance.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>On-Device LLMs for SMEs: Challenges and Opportunities</title><link>https://arxiv.org/abs/2410.16070</link><description>https://arxiv.org/abs/2410.16070&lt;br /&gt;This survey reviews advancements in Emotion Recognition in Conversations (ERC), highlighting challenges such as contextual understanding, real-time processing, and the diversity of emotion taxonomies across datasets, while discussing neural architectures and methods for improving ERC through balanced data handling and subjective annotation integration.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>CartesianMoE: Boosting Knowledge Sharing among Experts via Cartesian Product Routing in Mixture-of-Experts</title><link>https://arxiv.org/abs/2410.16077</link><description>https://arxiv.org/abs/2410.16077&lt;br /&gt;This survey on Emotion Recognition in Conversations (ERC) outlines recent advancements and ongoing challenges in the field, covering aspects such as emotional dynamics, common sense interpretation, real-time recognition, and the use of various neural architectures while providing recommendations for future work.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Can Large Audio-Language Models Truly Hear? Tackling Hallucinations with Multi-Task Assessment and Stepwise Audio Reasoning</title><link>https://arxiv.org/abs/2410.16130</link><description>https://arxiv.org/abs/2410.16130&lt;br /&gt;This survey reviews advancements in Emotion Recognition in Conversations (ERC), discussing challenges such as context utilization, speaker dynamics, interpretability, and the use of various neural architectures while highlighting practices for improving frameworks dealing with unbalanced datasets and emotional complexity.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Composite Spatial Reasoning</title><link>https://arxiv.org/abs/2410.16162</link><description>https://arxiv.org/abs/2410.16162&lt;br /&gt;This survey provides a comprehensive overview of Emotion Recognition in Conversations (ERC), discussing the advancements, challenges, and opportunities in the field while highlighting various techniques, benchmark datasets, and the importance of addressing subjectivity and unbalance in annotations.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Beyond Filtering: Adaptive Image-Text Quality Enhancement for MLLM Pretraining</title><link>https://arxiv.org/abs/2410.16166</link><description>https://arxiv.org/abs/2410.16166&lt;br /&gt;This survey provides an extensive overview of Emotion Recognition in Conversations (ERC), detailing its advancements, challenges, key benchmarks, methodologies, and best practices, particularly focusing on neural architectures and the use of pre-trained models to enhance emotion detection in dialogues.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Systematic Review: Text Processing Algorithms in Machine Learning and Deep Learning for Mental Health Detection on Social Media</title><link>https://arxiv.org/abs/2410.16204</link><description>https://arxiv.org/abs/2410.16204&lt;br /&gt;This survey critically examines Emotion Recognition in Conversations (ERC), discussing its advancements, challenges, and methodologies, including the use of neural architectures and benchmarks for improved emotion detection within textual conversations.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>CoT-TL: Low-Resource Temporal Knowledge Representation of Planning Instructions Using Chain-of-Thought Reasoning</title><link>https://arxiv.org/abs/2410.16207</link><description>https://arxiv.org/abs/2410.16207&lt;br /&gt;This survey provides a comprehensive overview of Emotion Recognition in Conversations (ERC), highlighting the advancements, challenges, and opportunities in the field while comparing various methods and datasets used in ERC, emphasizing the importance of pre-trained models and techniques to handle unbalanced data and subjective annotations.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Compute-Constrained Data Selection</title><link>https://arxiv.org/abs/2410.16208</link><description>https://arxiv.org/abs/2410.16208&lt;br /&gt;This survey on Deep Emotion Recognition in Conversations (ERC) highlights the advancements, challenges, and methodologies in recognizing emotions within textual conversations, emphasizing the need for addressing factors such as conversational context, emotion dynamics, and unbalanced datasets while exploring the use of advanced neural architectures.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs</title><link>https://arxiv.org/abs/2410.16267</link><description>https://arxiv.org/abs/2410.16267&lt;br /&gt;This survey comprehensively reviews the advancements and challenges in Emotion Recognition in Conversations (ERC), discussing various models, taxonomies, dataset benchmarks, and best practices for enhancing human-machine interaction through effective emotional understanding.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Understanding and Mitigating the Uncertainty in Zero-Shot Translation</title><link>https://arxiv.org/abs/2205.10068</link><description>https://arxiv.org/abs/2205.10068&lt;br /&gt;This survey reviews advancements in Emotion Recognition in Conversations (ERC), highlighting challenges such as context dynamics, sarcasm detection, and dataset imbalance, while discussing various methodologies and architectures employed in the field.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Deep Emotion Recognition in Textual Conversations: A Survey</title><link>https://arxiv.org/abs/2211.09172</link><description>https://arxiv.org/abs/2211.09172&lt;br /&gt;This survey presents an overview of Emotion Recognition in Conversations (ERC), highlighting recent advancements, challenges, and opportunities, while comparing various methods and architectures used in the field to enhance human-machine interaction.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Spirit LM: Interleaved Spoken and Written Language Model</title><link>https://arxiv.org/abs/2402.05755</link><description>https://arxiv.org/abs/2402.05755&lt;br /&gt;This paper presents the Counterfactual Augmented Calibration Network (FACTUAL), a novel approach to mitigate biases in stance detection by calibrating large language models (LLMs) and enhancing their performance through counterfactual augmented data.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Back to School: Translation Using Grammar Books</title><link>https://arxiv.org/abs/2410.15263</link><description>https://arxiv.org/abs/2410.15263&lt;br&gt;This paper investigates the effectiveness of scaling inference in large language models by comparing repeated sampling methods against a baseline that enumerates answers based on their prevalence, revealing that baselines can outperform or match coverage from sampling in certain contexts.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Hey GPT, Can You be More Racist? Analysis from Crowdsourced Attempts to Elicit Biased Content from Generative AI</title><link>https://arxiv.org/abs/2410.15467</link><description>https://arxiv.org/abs/2410.15467&lt;br&gt;This paper investigates the vulnerabilities of large language models (LLMs) in chemistry, particularly their ability to provide instructions for synthesizing hazardous substances, and introduces a novel attack technique called SMILES-prompting, which effectively bypasses current safety mechanisms.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>SceneGraMMi: Scene Graph-boosted Hybrid-fusion for Multi-Modal Misinformation Veracity Prediction</title><link>https://arxiv.org/abs/2410.15517</link><description>https://arxiv.org/abs/2410.15517&lt;br&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in the field of chemistry, exploring prompt injection attacks and introducing a novel attack method called SMILES-prompting that effectively bypasses safety mechanisms, emphasizing the need for improved safeguards.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>M-RewardBench: Evaluating Reward Models in Multilingual Settings</title><link>https://arxiv.org/abs/2410.15522</link><description>https://arxiv.org/abs/2410.15522&lt;br&gt;This paper examines security vulnerabilities of large language models (LLMs) in chemistry, evaluating prompt injection attack methods and introducing SMILES-prompting as a novel technique that bypasses safety mechanisms for synthesizing hazardous substances.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>WHoW: A Cross-domain Approach for Analysing Conversation Moderation</title><link>https://arxiv.org/abs/2410.15551</link><description>https://arxiv.org/abs/2410.15551&lt;br&gt;This paper examines the vulnerabilities of large language models (LLMs) in providing instructions for synthesizing hazardous substances in chemistry and introduces a novel attack method called SMILES-prompting that effectively bypasses safety mechanisms, emphasizing the need for improved domain-specific safeguards.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Multi-IF: Benchmarking LLMs on Multi-Turn and Multilingual Instructions Following</title><link>https://arxiv.org/abs/2410.15553</link><description>https://arxiv.org/abs/2410.15553&lt;br&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in the chemistry domain, demonstrating that SMILES-prompting can be used to bypass safety mechanisms to generate instructions for synthesizing hazardous substances, highlighting the need for improved safeguards.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Stacking Small Language Models for Generalizability</title><link>https://arxiv.org/abs/2410.15570</link><description>https://arxiv.org/abs/2410.15570&lt;br&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in the field of chemistry, introducing a novel attack technique called SMILES-prompting that exploits prompt injection to bypass safety mechanisms and potentially facilitate the synthesis of hazardous substances.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>A Survey of Conversational Search</title><link>https://arxiv.org/abs/2410.15576</link><description>https://arxiv.org/abs/2410.15576&lt;br&gt;This paper investigates the security vulnerabilities of large language models in the chemistry domain, introducing a novel attack technique called SMILES-prompting that effectively bypasses safety mechanisms designed to prevent the dissemination of hazardous substance synthesis instructions.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Guardians of Discourse: Evaluating LLMs on Multilingual Offensive Language Detection</title><link>https://arxiv.org/abs/2410.15623</link><description>https://arxiv.org/abs/2410.15623&lt;br&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in chemistry, particularly through novel prompt injection attacks like SMILES-prompting that exploit the generation of hazardous substance synthesis instructions, emphasizing the necessity for improved safeguards against such misuse.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Can Large Language Models Invent Algorithms to Improve Themselves?</title><link>https://arxiv.org/abs/2410.15639</link><description>https://arxiv.org/abs/2410.15639&lt;br&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in chemistry, particularly focusing on the effectiveness of various prompt injection attack methods, including a novel technique called SMILES-prompting, which can bypass safety mechanisms and provide instructions for synthesizing hazardous substances.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>SMILES-Prompting: A Novel Approach to LLM Jailbreak Attacks in Chemical Synthesis</title><link>https://arxiv.org/abs/2410.15641</link><description>https://arxiv.org/abs/2410.15641&lt;br&gt;This paper investigates the security vulnerabilities of large language models (LLMs) in the field of chemistry, specifically through a novel attack method called SMILES-prompting, which exploits LLMs' capabilities to provide instructions for synthesizing hazardous substances, revealing significant shortcomings in current safety mechanisms.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item><item><title>Persona-aware Generative Model for Code-mixed Language</title><link>https://arxiv.org/abs/2309.02915</link><description>https://arxiv.org/abs/2309.02915&lt;br&gt;This paper introduces the Counterfactual Augmented Calibration Network (FACTUAL) to mitigate biases in stance detection of Large Language Models (LLMs) by using counterfactual augmented data to improve bias representation and achieve better generalization.</description><pubDate>Tue, 22 Oct 2024 10:19:58 GMT</pubDate></item></channel></rss>