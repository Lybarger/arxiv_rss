<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Relevant arXiv Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss_relevant.xml</link><description>Relevant arXiv Papers</description><lastBuildDate>Mon, 21 Oct 2024 10:13:12 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>RiTeK: A Dataset for Large Language Models Complex Reasoning over Textual Knowledge Graphs</title><link>https://arxiv.org/abs/2410.13987</link><description>https://arxiv.org/abs/2410.13987&lt;br /&gt;RiTeK is a dataset designed for Large Language Models to facilitate complex reasoning over Textual Knowledge Graphs, particularly in the medical domain, by synthesizing realistic user queries and introducing a Relational Monte Carlo Tree Search method to enhance relational path retrieval and inference capabilities.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>Style-Compress: An LLM-Based Prompt Compression Framework Considering Task-Specific Styles</title><link>https://arxiv.org/abs/2410.14042</link><description>https://arxiv.org/abs/2410.14042&lt;br&gt;Style-Compress is a prompt compression framework that allows smaller language models to efficiently generate task-specific compressed prompts for larger models, improving performance on various downstream tasks while reducing computational costs.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs</title><link>https://arxiv.org/abs/2410.14052</link><description>https://arxiv.org/abs/2410.14052&lt;br&gt;MemTree is a dynamic tree-structured memory representation designed for large language models that optimizes information organization and retrieval, enhancing context-awareness and reasoning in complex interactions and dialogue systems.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item><item><title>CAPE: A Chinese Dataset for Appraisal-based Emotional Generation using Large Language Models</title><link>https://arxiv.org/abs/2410.14145</link><description>https://arxiv.org/abs/2410.14145&lt;br&gt;CAPE introduces a new Chinese dataset for generating emotionally appropriate responses in conversations, leveraging Cognitive Appraisal theory to enhance emotional expression in conversational agents through two prediction tasks.</description><pubDate>Mon, 21 Oct 2024 10:13:12 GMT</pubDate></item></channel></rss>