<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Relevant arXiv Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss_relevant.xml</link><description>Relevant arXiv Papers</description><lastBuildDate>Mon, 28 Oct 2024 07:58:07 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>All Entities are Not Created Equal: Examining the Long Tail for Fine-Grained Entity Typing</title><link>https://arxiv.org/abs/2410.17355</link><description>https://arxiv.org/abs/2410.17355&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) system evaluates the distinct personality traits of Large Language Models (LLMs) by adapting a personality assessment questionnaire to their outputs, enabling quantitative measurement of their linguistic personalities and contributing to Human-Computer Interaction research.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Artificial Intelligence in Brazilian News: A Mixed-Methods Analysis</title><link>https://arxiv.org/abs/2410.17423</link><description>https://arxiv.org/abs/2410.17423&lt;br /&gt;The LMLPA introduces a system for assessing the linguistic personality traits of Large Language Models (LLMs) using an adapted version of the Big Five Inventory, demonstrating that LLMs exhibit distinct personality traits that can be quantitatively analyzed, thereby contributing to Human-Computer Interaction and Human-Centered AI.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Navigate Complex Physical Worlds via Geometrically Constrained LLM</title><link>https://arxiv.org/abs/2410.17529</link><description>https://arxiv.org/abs/2410.17529&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a framework for evaluating the linguistic personalities of Large Language Models (LLMs) using an adapted version of the Big Five Inventory, enabling the quantification of personality traits reflected in their language generation outputs.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>MM-Eval: A Multilingual Meta-Evaluation Benchmark for LLM-as-a-Judge and Reward Models</title><link>https://arxiv.org/abs/2410.17578</link><description>https://arxiv.org/abs/2410.17578&lt;br /&gt;LMLPA introduces a framework for assessing the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory to evaluate LLM-generated text, enhancing understanding of LLMs' language capabilities and contributing to fields like Human-Computer Interaction.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Cross-model Control: Improving Multiple Large Language Models in One-time Training</title><link>https://arxiv.org/abs/2410.17599</link><description>https://arxiv.org/abs/2410.17599&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system for evaluating the linguistic personalities of Large Language Models (LLMs) by adapting personality assessment frameworks to quantify personality traits reflected in their language generation capabilities.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages</title><link>https://arxiv.org/abs/2410.17973</link><description>https://arxiv.org/abs/2410.17973&lt;br /&gt;The paper presents a CPI+DMC approach for the early detection of signs of anorexia, emphasizing a time-aware methodology that integrates temporal factors into the learning process, leading to significant improvements in detection precision and speed as measured by the ERDE metrics.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Cross-lingual Transfer of Reward Models in Multilingual Alignment</title><link>https://arxiv.org/abs/2410.18027</link><description>https://arxiv.org/abs/2410.18027&lt;br /&gt;This research paper presents a time-aware approach for the early detection of anorexia that combines precision and speed as a single objective, utilizing temporal metrics in the learning process to achieve strong performance in the eRisk 2024 competition.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for Russian Scientific Keyphrases</title><link>https://arxiv.org/abs/2410.18040</link><description>https://arxiv.org/abs/2410.18040&lt;br /&gt;The paper presents a time-aware approach for early detection of anorexia, implementing a CPI+DMC methodology that balances precision and speed, and integrates temporal metrics in the learning process, achieving notable performance in risk detection tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering</title><link>https://arxiv.org/abs/2410.18050</link><description>https://arxiv.org/abs/2410.18050&lt;br /&gt;This research paper presents a time-aware approach to early detection of anorexia in an online environment, utilizing a CPI+DMC framework and incorporating temporal metrics to enhance both precision and speed in identifying early risk signs.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Temporal Relational Reasoning of Large Language Models for Detecting Stock Portfolio Crashes</title><link>https://arxiv.org/abs/2410.17266</link><description>https://arxiv.org/abs/2410.17266&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, utilizing a combined model that optimizes both precision and speed in identifying risk signs, achieving notable results in the context of the eRisk 2024 competition.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Are Large Language Models Ready for Travel Planning?</title><link>https://arxiv.org/abs/2410.17333</link><description>https://arxiv.org/abs/2410.17333&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, integrating precision and speed into a combined objective during the learning process, leading to improved performance metrics in detecting early signs of anorexia.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Intera\c{c}\~ao entre rob\^os humanoides: desenvolvendo a colabora\c{c}\~ao e comunica\c{c}\~ao aut\^onoma</title><link>https://arxiv.org/abs/2410.17450</link><description>https://arxiv.org/abs/2410.17450&lt;br /&gt;The study proposes a time-aware approach to early detection of anorexia by integrating temporal factors into the learning process, focusing on both precision and speed in risk detection, and achieving strong results in established evaluation metrics.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation</title><link>https://arxiv.org/abs/2410.17462</link><description>https://arxiv.org/abs/2410.17462&lt;br /&gt;This paper presents a time-aware method for early detection of anorexia, incorporating precision and speed as combined objectives during training, which yielded strong performance in the eRisk 2024 competition.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Which Client is Reliable?: A Reliable and Personalized Prompt-based Federated Learning for Medical Image Question Answering</title><link>https://arxiv.org/abs/2410.17484</link><description>https://arxiv.org/abs/2410.17484&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, optimizing precision and speed in risk detection through a combined objective learning process and achieving exceptional results on relevant metrics.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks</title><link>https://arxiv.org/abs/2410.17498</link><description>https://arxiv.org/abs/2410.17498&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia within the eRisk 2024 framework, using a CPI+DMC methodology and integrating temporal metrics to improve both precision and speed in detecting early risk signs on the web.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control</title><link>https://arxiv.org/abs/2410.17520</link><description>https://arxiv.org/abs/2410.17520&lt;br /&gt;This research paper presents a time-aware approach for the early detection of anorexia, focusing on precision and speed in the detection process, where temporal metrics were integrated into the learning phase to optimize model performance on relevant tasks in the eRisk 2024 competition.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Differentially Private Learning Needs Better Model Initialization and Self-Distillation</title><link>https://arxiv.org/abs/2410.17566</link><description>https://arxiv.org/abs/2410.17566&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, focusing on precision and speed by integrating temporal aspects into the learning process, leading to high performance on relevant evaluation metrics.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Markov Chain of Thought for Efficient Mathematical Reasoning</title><link>https://arxiv.org/abs/2410.17635</link><description>https://arxiv.org/abs/2410.17635&lt;br /&gt;This paper discusses a time-aware approach for the early detection of anorexia within an online risk detection framework, highlighting a novel CPI+DMC strategy that integrates temporal metrics in the learning process to enhance both precision and speed in identifying signs of the disorder.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024</title><link>https://arxiv.org/abs/2410.17963</link><description>https://arxiv.org/abs/2410.17963&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, focusing on optimizing both precision and speed in the detection process through a CPI+DMC method and the integration of temporal metrics during model training.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>RaTEScore: A Metric for Radiology Report Generation</title><link>https://arxiv.org/abs/2406.16845</link><description>https://arxiv.org/abs/2406.16845&lt;br /&gt;This paper explores the security challenges associated with the proliferation of Generative AI across various industries and proposes potential research directions for mitigating these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding</title><link>https://arxiv.org/abs/2406.18925</link><description>https://arxiv.org/abs/2406.18925&lt;br /&gt;This paper explores the security challenges associated with the growing use of Generative AI across various industries and suggests potential research directions to address these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Attribute or Abstain: Large Language Models as Long Document Assistants</title><link>https://arxiv.org/abs/2407.07799</link><description>https://arxiv.org/abs/2407.07799&lt;br /&gt;This paper discusses the security challenges introduced by generative AI technologies across various industries and proposes potential research directions for addressing these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>S2-Attention: Hardware-Aware Context Sharding Among Attention Heads</title><link>https://arxiv.org/abs/2407.17678</link><description>https://arxiv.org/abs/2407.17678&lt;br /&gt;This paper discusses the security challenges associated with the growing adoption of Generative AI across various industries and suggests potential research directions for mitigating these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>NVLM: Open Frontier-Class Multimodal LLMs</title><link>https://arxiv.org/abs/2409.11402</link><description>https://arxiv.org/abs/2409.11402&lt;br /&gt;This paper examines the unique security challenges associated with Generative AI's proliferation across various industries and proposes research directions to address these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation</title><link>https://arxiv.org/abs/2409.15240</link><description>https://arxiv.org/abs/2409.15240&lt;br /&gt;This paper analyzes the security challenges introduced by Generative AI across various industries and proposes potential research directions for addressing these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>A Comparative Study on Reasoning Patterns of OpenAI's o1 Model</title><link>https://arxiv.org/abs/2410.13639</link><description>https://arxiv.org/abs/2410.13639&lt;br /&gt;This paper addresses the security challenges associated with the proliferation of Generative AI technologies across various industries and proposes potential research directions for mitigating these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs</title><link>https://arxiv.org/abs/2410.16144</link><description>https://arxiv.org/abs/2410.16144&lt;br /&gt;This paper explores the security challenges associated with the growing use of Generative AI across various industries and suggests potential research directions to address these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Linear Adversarial Concept Erasure</title><link>https://arxiv.org/abs/2201.12091</link><description>https://arxiv.org/abs/2201.12091&lt;br /&gt;This paper discusses the security challenges posed by Generative AI as it becomes more prevalent across various industries and proposes potential research directions to manage these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Captions Speak Louder than Images (CASLIE): Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data</title><link>https://arxiv.org/abs/2410.17337</link><description>https://arxiv.org/abs/2410.17337&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system to quantitatively assess the linguistic personalities of Large Language Models (LLMs) using a modified Big Five Inventory, highlighting distinct personality traits in LLMs for Human-Computer Interaction and Human-Centered AI applications.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>AMUSD: Asynchronous Multi-Device Speculative Decoding for LLM Acceleration</title><link>https://arxiv.org/abs/2410.17375</link><description>https://arxiv.org/abs/2410.17375&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the linguistic personalities of large language models (LLMs) using an adapted Big Five Inventory to provide quantitative assessments of personality traits in LLMs' outputs.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities</title><link>https://arxiv.org/abs/2410.17385</link><description>https://arxiv.org/abs/2410.17385&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the personality traits of Large Language Models using a modified version of the Big Five Inventory, contributing to Human-Computer Interaction research by providing quantifiable measures of AI personality traits.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Scalable Influence and Fact Tracing for Large Language Model Pretraining</title><link>https://arxiv.org/abs/2410.17413</link><description>https://arxiv.org/abs/2410.17413&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA) to evaluate the personality traits of large language models (LLMs) through linguistic outputs, applying an adapted Big Five Inventory framework and demonstrating their distinct personality profiles.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Evaluating AI-Generated Essays with GRE Analytical Writing Assessment</title><link>https://arxiv.org/abs/2410.17439</link><description>https://arxiv.org/abs/2410.17439&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating personality traits of large language models based on their linguistic outputs, using a modified version of the Big Five Inventory to provide insights into their conversational capabilities.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>In Context Learning and Reasoning for Symbolic Regression with Large Language Models</title><link>https://arxiv.org/abs/2410.17448</link><description>https://arxiv.org/abs/2410.17448&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system designed to assess the personality traits of Large Language Models (LLMs) by adapting human-centric psychometric methods to evaluate their linguistic outputs.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination</title><link>https://arxiv.org/abs/2410.17477</link><description>https://arxiv.org/abs/2410.17477&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system to evaluate and quantify the distinct personality traits of Large Language Models (LLMs) using adapted psychometric techniques.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don't mimic the full human distribution</title><link>https://arxiv.org/abs/2410.17482</link><description>https://arxiv.org/abs/2410.17482&lt;br /&gt;The LMLPA system evaluates and quantifies the linguistic personalities of Large Language Models using a modified Big Five Inventory, contributing to the understanding of LLMs in conversational interactions.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning</title><link>https://arxiv.org/abs/2410.17485</link><description>https://arxiv.org/abs/2410.17485&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the linguistic personalities of large language models (LLMs) using a questionnaire based on the Big Five Inventory, adapted for LLMs to assess their language generation capabilities in conversational settings.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Large Language Models Still Exhibit Bias in Long Text</title><link>https://arxiv.org/abs/2410.17519</link><description>https://arxiv.org/abs/2410.17519&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system designed to evaluate and quantify the linguistic personality traits of large language models using the Big Five Inventory for better understanding of their language generation capabilities.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact</title><link>https://arxiv.org/abs/2410.17532</link><description>https://arxiv.org/abs/2410.17532&lt;br /&gt;The paper presents the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the distinct personality traits of LLMs through adapted Big Five Inventory-based psychometrics, contributing insights into LLMs' language generation capabilities and their applications in Human-Computer Interaction and AI.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification</title><link>https://arxiv.org/abs/2410.17546</link><description>https://arxiv.org/abs/2410.17546&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA) to evaluate and quantify distinct personality traits of Large Language Models (LLMs) through a modified Big Five Inventory, contributing to improvements in Human-Computer Interaction and Human-Centered AI.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>ESpeW: Robust Copyright Protection for LLM-based EaaS via Embedding-Specific Watermark</title><link>https://arxiv.org/abs/2410.17552</link><description>https://arxiv.org/abs/2410.17552&lt;br /&gt;LMLPA introduces a system to evaluate the linguistic personalities of LLMs using an adapted Big Five Inventory questionnaire to quantitatively assess personality traits in AI-generated text, contributing to Human-Computer Interaction and Human-Centered AI.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective</title><link>https://arxiv.org/abs/2410.17600</link><description>https://arxiv.org/abs/2410.17600&lt;br /&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA) to evaluate the linguistic personalities of large language models (LLMs), adapting the Big Five Inventory for measuring personality traits in LLMs to improve understanding of their language generation capabilities.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>LMLPA: Language Model Linguistic Personality Assessment</title><link>https://arxiv.org/abs/2410.17632</link><description>https://arxiv.org/abs/2410.17632&lt;br /&gt;This paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a framework for evaluating the linguistic personalities of Large Language Models (LLMs) by adapting a personality assessment questionnaire to measure distinct personality traits in their linguistic outputs.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents</title><link>https://arxiv.org/abs/2410.17657</link><description>https://arxiv.org/abs/2410.17657&lt;br /&gt;The paper analyzes changes in the German political discourse from 1871 to present using a time-series variant of LDA to identify significant events and shifts in political topics, leveraging digitized plenary session logs of the German Bundestag.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Quantifying the Risks of Tool-assisted Rephrasing to Linguistic Diversity</title><link>https://arxiv.org/abs/2410.17670</link><description>https://arxiv.org/abs/2410.17670&lt;br /&gt;The paper utilizes a time series variant of LDA to analyze digitized plenary sessions of the German Bundestag, identifying changes and lasting impacts on political discourse from 1949 to the present.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Towards a Similarity-adjusted Surprisal Theory</title><link>https://arxiv.org/abs/2410.17676</link><description>https://arxiv.org/abs/2410.17676&lt;br /&gt;The paper uses a time series variant of the topic model LDA to analyze changes in the German political discourse from the formation of the Federal Republic of Germany in 1949 onwards, identifying key events that have impacted political topics over the years.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&amp;A Platforms</title><link>https://arxiv.org/abs/2410.17694</link><description>https://arxiv.org/abs/2410.17694&lt;br /&gt;The paper analyzes texts from the German Bundestag using a time series variant of the topic model LDA to identify significant changes in political discourse over time.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Beware of Calibration Data for Pruning Large Language Models</title><link>https://arxiv.org/abs/2410.17711</link><description>https://arxiv.org/abs/2410.17711&lt;br /&gt;The paper investigates changes in the German political discourse over time by analyzing texts from German Bundestag sessions using a time series variant of topic modeling LDA to detect shifts in political topics and key discussion points.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>CogSteer: Cognition-Inspired Selective Layer Intervention for Efficient Semantic Steering in Large Language Models</title><link>https://arxiv.org/abs/2410.17714</link><description>https://arxiv.org/abs/2410.17714&lt;br /&gt;The paper examines changes in German political discourse over time using a time series model of LDA to analyze digitized texts from the Bundestag, focusing on how events have influenced political topics and word frequency.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Dialectal and Low Resource Machine Translation for Aromanian</title><link>https://arxiv.org/abs/2410.17728</link><description>https://arxiv.org/abs/2410.17728&lt;br /&gt;The paper investigates changes in political discourse within the German Bundestag from 1871 onwards by using a time series variant of the LDA topic model to analyze the digitized transcripts of plenary sessions.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Local Contrastive Editing of Gender Stereotypes</title><link>https://arxiv.org/abs/2410.17739</link><description>https://arxiv.org/abs/2410.17739&lt;br /&gt;This paper uses a time series variant of the topic model LDA to analyze changes in German political discourse by examining digitized plenary session texts from the German Bundestag over time.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Latent Structures of Intertextuality in French Fiction</title><link>https://arxiv.org/abs/2410.17759</link><description>https://arxiv.org/abs/2410.17759&lt;br /&gt;The paper utilizes a time series variant of the topic model LDA to analyze the digitized plenary session logs of the German Bundestag, examining how political discourse and topics have evolved over time in response to significant events.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Understanding When Tree of Thoughts Succeeds: Larger Models Excel in Generation, Not Discrimination</title><link>https://arxiv.org/abs/2410.17820</link><description>https://arxiv.org/abs/2410.17820&lt;br /&gt;This paper investigates changes in the German political discourse over time using a time series variant of the topic model LDA on digitized texts from the German Bundestag sessions.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Understanding Layer Significance in LLM Alignment</title><link>https://arxiv.org/abs/2410.17875</link><description>https://arxiv.org/abs/2410.17875&lt;br /&gt;The paper analyzes the evolution of political discourse in the German Bundestag from 1949 onwards using a time series variant of the topic model LDA to detect changes in word frequency and key discussion points over time.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>SpeakGer: A meta-data enriched speech corpus of German state and federal parliaments</title><link>https://arxiv.org/abs/2410.17886</link><description>https://arxiv.org/abs/2410.17886&lt;br /&gt;The paper explores changes in the German political discourse over time by applying a time series variant of the topic model LDA to Bundestag session logs, identifying key events and shifts in political topics.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Scaling Diffusion Language Models via Adaptation from Autoregressive Models</title><link>https://arxiv.org/abs/2410.17891</link><description>https://arxiv.org/abs/2410.17891&lt;br /&gt;The paper analyzes changes in the German political discourse over time using a time series variant of the topic model LDA, examining how significant events influenced political topics in the Bundestag's digitized plenary sessions.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Value Residual Learning For Alleviating Attention Concentration In Transformers</title><link>https://arxiv.org/abs/2410.17897</link><description>https://arxiv.org/abs/2410.17897&lt;br /&gt;This paper analyzes the German political discourse from 1949 onwards using a time series variant of the LDA topic model to detect changes in word frequency and key discussion points over time.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Zeitenwenden: Detecting changes in the German political discourse</title><link>https://arxiv.org/abs/2410.17960</link><description>https://arxiv.org/abs/2410.17960&lt;br /&gt;The paper analyzes changes in the German political discourse over time using a time series variant of the topic model LDA to detect shifts in word frequency and key discussion points in the Bundestag plenary session texts.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Dependency Graph Parsing as Sequence Labeling</title><link>https://arxiv.org/abs/2410.17972</link><description>https://arxiv.org/abs/2410.17972&lt;br /&gt;This research paper presents a time-aware approach for the early detection of anorexia by integrating time into the learning process, demonstrating effective performance in precision and speed using temporal metrics.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning</title><link>https://arxiv.org/abs/2410.18035</link><description>https://arxiv.org/abs/2410.18035&lt;br /&gt;This paper presents a time-aware approach for early detection of anorexia by integrating temporal metrics during training, achieving notable results in precision and speed for early risk detection tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Literature Meets Data: A Synergistic Approach to Hypothesis Generation</title><link>https://arxiv.org/abs/2410.17309</link><description>https://arxiv.org/abs/2410.17309&lt;br /&gt;The paper discusses a time-aware approach to early detection of anorexia, focusing on the balance between precision and speed by integrating temporal metrics during training to optimize models for early risk detection on the web.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents</title><link>https://arxiv.org/abs/2410.17401</link><description>https://arxiv.org/abs/2410.17401&lt;br /&gt;The paper presents a time-aware approach for early detection of anorexia that integrates time in the learning process to optimize precision and speed, achieving significant results on the ERDE50 metric.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers</title><link>https://arxiv.org/abs/2410.17492</link><description>https://arxiv.org/abs/2410.17492&lt;br /&gt;The paper presents a time-aware approach for the early detection of anorexia focused on enhancing precision and speed, using explicit time integration during the learning process to excel in early risk detection (ERD) metrics.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference</title><link>https://arxiv.org/abs/2410.17954</link><description>https://arxiv.org/abs/2410.17954&lt;br /&gt;The paper presents a time-aware method for the early detection of anorexia signs by integrating time explicitly during the learning process to optimize precision and speed using the ERDE metrics as objectives, achieving strong results in the eRisk 2024 challenge.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>A Bi-consolidating Model for Joint Relational Triple Extraction</title><link>https://arxiv.org/abs/2404.03881</link><description>https://arxiv.org/abs/2404.03881&lt;br /&gt;The paper introduces a unified framework called Fast and Slow Generating (FS-GEN) to collaboratively decode between large and small language models, addressing challenges like latency and hallucinations by analyzing the effective conditions for their cooperation based on parameter scaling laws and uncertainty management.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Annotator-Centric Active Learning for Subjective NLP Tasks</title><link>https://arxiv.org/abs/2404.15720</link><description>https://arxiv.org/abs/2404.15720&lt;br /&gt;The paper explores a collaborative decoding framework, Fast and Slow Generating (FS-GEN), leveraging large and small language models to mitigate challenges like high inference latency and generation of hallucinations, focusing on the distinct roles of fast, intuitive systems and slow, deliberate ones.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs</title><link>https://arxiv.org/abs/2406.14282</link><description>https://arxiv.org/abs/2406.14282&lt;br /&gt;The paper explores the unique security challenges associated with Generative AI and suggests potential research directions for managing these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics</title><link>https://arxiv.org/abs/2406.14703</link><description>https://arxiv.org/abs/2406.14703&lt;br /&gt;This paper explores the security challenges associated with Generative AI and suggests potential research directions for mitigating these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>AlleNoise: large-scale text classification benchmark dataset with real-world label noise</title><link>https://arxiv.org/abs/2407.10992</link><description>https://arxiv.org/abs/2407.10992&lt;br /&gt;This paper explores the security challenges posed by Generative AI and outlines potential research directions to manage these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>NutriBench: A Dataset for Evaluating Large Language Models in Carbohydrate Estimation from Meal Descriptions</title><link>https://arxiv.org/abs/2407.12843</link><description>https://arxiv.org/abs/2407.12843&lt;br /&gt;The paper explores the security challenges presented by Generative AI as it becomes more prevalent across various industries, and suggests research directions for mitigating these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer</title><link>https://arxiv.org/abs/2408.01119</link><description>https://arxiv.org/abs/2408.01119&lt;br /&gt;The paper discusses the security challenges posed by Generative AI and suggests potential research directions to manage these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Can Language Models Induce Grammatical Knowledge from Indirect Evidence?</title><link>https://arxiv.org/abs/2410.06022</link><description>https://arxiv.org/abs/2410.06022&lt;br /&gt;The paper discusses the unique security challenges posed by Generative AI and suggests potential research directions to manage these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems</title><link>https://arxiv.org/abs/2410.13334</link><description>https://arxiv.org/abs/2410.13334&lt;br /&gt;The paper discusses the unique security challenges of Generative AI and proposes research directions to manage these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>On the Diversity of Synthetic Data and its Impact on Training Large Language Models</title><link>https://arxiv.org/abs/2410.15226</link><description>https://arxiv.org/abs/2410.15226&lt;br /&gt;The paper explores the security challenges associated with Generative AI across various industries and suggests research directions for risk management.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs</title><link>https://arxiv.org/abs/2410.15956</link><description>https://arxiv.org/abs/2410.15956&lt;br /&gt;The paper explores the security challenges posed by Generative AI across various industries and suggests research directions to manage these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the U.S</title><link>https://arxiv.org/abs/2410.16451</link><description>https://arxiv.org/abs/2410.16451&lt;br /&gt;The paper explores the unique security challenges posed by Generative AI and outlines potential research directions for managing these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Generative AI Security: Challenges and Countermeasures</title><link>https://arxiv.org/abs/2402.12617</link><description>https://arxiv.org/abs/2402.12617&lt;br /&gt;The paper explores the security challenges associated with Generative AI and suggests potential research directions for managing these risks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>LLMScan: Causal Scan for LLM Misbehavior Detection</title><link>https://arxiv.org/abs/2410.16638</link><description>https://arxiv.org/abs/2410.16638&lt;br /&gt;LLMScan is a technique utilizing causality analysis to monitor and detect misbehavior in Large Language Models (LLMs) by analyzing causal contributions of input tokens and transformer layers.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Non-myopic Generation of Language Model for Reasoning and Planning</title><link>https://arxiv.org/abs/2410.17195</link><description>https://arxiv.org/abs/2410.17195&lt;br /&gt;LLMScan introduces a causal inference-based technique to monitor and detect misbehavior in Large Language Models (LLMs) by analyzing the causal contributions of input tokens and transformer layers.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>R2Gen-Mamba: A Selective State Space Model for Radiology Report Generation</title><link>https://arxiv.org/abs/2410.18135</link><description>https://arxiv.org/abs/2410.18135&lt;br /&gt;DoG is a novel framework that combines LLMs and Knowledge Graphs to generate well-formed chains for reliable and robust question answering through a process called graph-aware constrained decoding.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Analyzing Nobel Prize Literature with Large Language Models</title><link>https://arxiv.org/abs/2410.18142</link><description>https://arxiv.org/abs/2410.18142&lt;br /&gt;DoG (Decoding on Graphs) is a framework that enhances question answering with large language models by using knowledge graphs to guide the generation of well-formed reasoning chains via graph-aware constrained decoding.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Meaning Typed Prompting: A Technique for Efficient, Reliable Structured Output Generation</title><link>https://arxiv.org/abs/2410.18146</link><description>https://arxiv.org/abs/2410.18146&lt;br /&gt;The paper presents DoG, a framework that combines large language models and knowledge graphs for improved question answering, by generating well-formed chains of fact triplets to ensure faithful and sound reasoning.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Future Token Prediction -- Causal Language Modelling with Per-Token Semantic State Vector for Multi-Token Prediction</title><link>https://arxiv.org/abs/2410.18160</link><description>https://arxiv.org/abs/2410.18160&lt;br /&gt;DoG is a framework that combines large language models with knowledge graphs through constrained decoding to generate well-formed reasoning chains for enhanced question answering.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Gazelle: An Instruction Dataset for Arabic Writing Assistance</title><link>https://arxiv.org/abs/2410.18163</link><description>https://arxiv.org/abs/2410.18163&lt;br /&gt;The paper introduces DoG, a framework that enhances question answering by integrating large language models with knowledge graphs to generate well-formed reasoning chains using constrained decoding.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>CorrectionLM: Self-Corrections with SLM for Dialogue State Tracking</title><link>https://arxiv.org/abs/2410.18209</link><description>https://arxiv.org/abs/2410.18209&lt;br /&gt;DoG is a framework that enhances question answering on knowledge graphs by utilizing large language models to generate well-formed reasoning chains through graph-aware constrained decoding, improving the synergy between LLMs' reasoning capabilities and the structured nature of knowledge graphs.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Towards Understanding the Fragility of Multilingual LLMs against Fine-Tuning Attacks</title><link>https://arxiv.org/abs/2410.18210</link><description>https://arxiv.org/abs/2410.18210&lt;br /&gt;Decoding on Graphs (DoG) is a framework that enhances the reasoning abilities of large language models by generating well-formed chains from knowledge graphs, facilitating reliable question answering through graph-aware constrained decoding.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Generalizations across filler-gap dependencies in neural language models</title><link>https://arxiv.org/abs/2410.18225</link><description>https://arxiv.org/abs/2410.18225&lt;br /&gt;DoG (Decoding on Graphs) introduces a method for improving question answering by combining large language models with knowledge graphs through a graph-aware constrained decoding process that generates well-formed reasoning chains.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Multi-Draft Speculative Sampling: Canonical Architectures and Theoretical Limits</title><link>https://arxiv.org/abs/2410.18234</link><description>https://arxiv.org/abs/2410.18234&lt;br /&gt;The paper presents DoG (Decoding on Graphs), a novel framework that integrates large language models with knowledge graphs to generate well-formed chains of reasoning, enhancing the accuracy and reliability of knowledge graph-based question answering.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Multilingual Hallucination Gaps in Large Language Models</title><link>https://arxiv.org/abs/2410.18270</link><description>https://arxiv.org/abs/2410.18270&lt;br /&gt;DoG (Decoding on Graphs) is a framework that enhances the synergy between large language models (LLMs) and knowledge graphs (KGs) by employing graph-aware constrained decoding to generate well-formed chains for faithful and sound reasoning in KG-based question answering.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>LEGO: Language Model Building Blocks</title><link>https://arxiv.org/abs/2410.18287</link><description>https://arxiv.org/abs/2410.18287&lt;br /&gt;DoG is a novel framework that uses constrained decoding on knowledge graphs to enhance large language models' reasoning capabilities, generating well-formed chains for more reliable question-answering systems.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Measuring individual semantic networks: A simulation study</title><link>https://arxiv.org/abs/2410.18326</link><description>https://arxiv.org/abs/2410.18326&lt;br /&gt;The paper introduces DoG (Decoding on Graphs), a framework that enhances large language models' reasoning on knowledge graphs by generating well-formed chains of fact triplets to ensure faithful and sound question answering.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Assessing the Creativity of LLMs in Proposing Novel Solutions to Mathematical Problems</title><link>https://arxiv.org/abs/2410.18336</link><description>https://arxiv.org/abs/2410.18336&lt;br /&gt;The paper introduces DoG, a novel framework that enhances the integration of large language models (LLMs) with knowledge graphs (KGs) to generate accurate and structured answers through graph-aware constrained decoding.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Aggregated Knowledge Model: Enhancing Domain-Specific QA with Fine-Tuned and Retrieval-Augmented Generation Models</title><link>https://arxiv.org/abs/2410.18344</link><description>https://arxiv.org/abs/2410.18344&lt;br /&gt;The paper presents DoG (Decoding on Graphs), a novel framework that integrates large language models (LLMs) with Knowledge Graphs (KGs) to facilitate structured, faithful, and sound reasoning by generating well-formed chains within KGs for question answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>AdaEDL: Early Draft Stopping for Speculative Decoding of Large Language Models via an Entropy-based Lower Bound on Token Acceptance Probability</title><link>https://arxiv.org/abs/2410.18351</link><description>https://arxiv.org/abs/2410.18351&lt;br /&gt;DoG is a novel framework that integrates large language models with knowledge graphs to generate well-formed reasoning chains for question answering tasks, improving reasoning by using graph-aware constrained decoding.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Improving Model Factuality with Fine-grained Critique-based Evaluator</title><link>https://arxiv.org/abs/2410.18359</link><description>https://arxiv.org/abs/2410.18359&lt;br /&gt;DoG (Decoding on Graphs) utilizes graph-aware constrained decoding to enable large language models (LLMs) to generate faithful and sound reasoning paths on Knowledge Graphs (KGs) for question answering.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Monolingual and Multilingual Misinformation Detection for Low-Resource Languages: A Comprehensive Survey</title><link>https://arxiv.org/abs/2410.18390</link><description>https://arxiv.org/abs/2410.18390&lt;br /&gt;The paper introduces DoG, a framework that integrates large language models with knowledge graphs through graph-aware constrained decoding to generate well-formed chains for faithful and sound reasoning in knowledge graph-based question answering.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness</title><link>https://arxiv.org/abs/2410.18393</link><description>https://arxiv.org/abs/2410.18393&lt;br /&gt;The paper introduces DoG (Decoding on Graphs), a framework that synergizes the reasoning abilities of large language models with the structured knowledge of knowledge graphs to generate faithful reasoning chains for question answering.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>MoMQ: Mixture-of-Experts Enhances Multi-Dialect Query Generation across Relational and Non-Relational Databases</title><link>https://arxiv.org/abs/2410.18406</link><description>https://arxiv.org/abs/2410.18406&lt;br /&gt;DoG (Decoding on Graphs) is a novel framework that enhances knowledge graph question answering by integrating large language models' step-wise reasoning with graph-aware constrained decoding to generate well-formed reasoning chains.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains</title><link>https://arxiv.org/abs/2410.18415</link><description>https://arxiv.org/abs/2410.18415&lt;br /&gt;DoG is a framework that enhances question answering by combining large language models with knowledge graphs through graph-aware constrained decoding to generate well-formed reasoning chains.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Building Dialogue Understanding Models for Low-resource Language Indonesian from Scratch</title><link>https://arxiv.org/abs/2410.18430</link><description>https://arxiv.org/abs/2410.18430&lt;br /&gt;The paper introduces SPEED, a framework that aligns small open-source models to efficiently generate large-scale, high-quality synthetic embedding data, reducing reliance on costly proprietary models like GPT-4.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>ToolFlow: Boosting LLM Tool-Calling Through Natural and Coherent Dialogue Synthesis</title><link>https://arxiv.org/abs/2410.18447</link><description>https://arxiv.org/abs/2410.18447&lt;br /&gt;The paper presents SPEED, a framework for aligning open-source models for efficient generation of large-scale synthetic embedding data, surpassing existing methods while significantly reducing reliance on expensive proprietary models.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>LOGO -- Long cOntext aliGnment via efficient preference Optimization</title><link>https://arxiv.org/abs/2410.18533</link><description>https://arxiv.org/abs/2410.18533&lt;br /&gt;The paper introduces SPEED, a framework for synthesizing high-quality text embedding data using small open-source models, significantly reducing reliance on costly proprietary models like GPT-4 while maintaining performance.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>STTATTS: Unified Speech-To-Text And Text-To-Speech Model</title><link>https://arxiv.org/abs/2410.18607</link><description>https://arxiv.org/abs/2410.18607&lt;br /&gt;This paper introduces SPEED, a framework that efficiently generates large-scale high-quality synthetic embedding data using small open-source models, significantly reducing reliance on expensive GPT models and enhancing data quality through fine-tuning and preference optimization.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>BioMistral-NLU: Towards More Generalizable Medical Language Understanding through Instruction Tuning</title><link>https://arxiv.org/abs/2410.18955</link><description>https://arxiv.org/abs/2410.18955&lt;br /&gt;CoreInfer is an inference method that accelerates large language model processing using sentence-level adaptive sparse activation to identify critical neurons, leading to significant performance improvements without additional computational costs.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Skywork-Reward: Bag of Tricks for Reward Modeling in LLMs</title><link>https://arxiv.org/abs/2410.18451</link><description>https://arxiv.org/abs/2410.18451&lt;br /&gt;XC-Cache enhances efficiency in large language model inference by using cross-attention to reference cached context, reducing space requirements significantly while maintaining performance in conditional generation tasks like Question-Answering.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>KVSharer: Efficient Inference via Layer-Wise Dissimilar KV Cache Sharing</title><link>https://arxiv.org/abs/2410.18517</link><description>https://arxiv.org/abs/2410.18517&lt;br /&gt;The paper introduces XC-Cache, a model that uses cross-attention to efficiently perform conditional generation for in-context learning with significantly reduced caching space requirements, demonstrated on Question-Answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Speech perception: a model of word recognition</title><link>https://arxiv.org/abs/2410.18590</link><description>https://arxiv.org/abs/2410.18590&lt;br /&gt;The paper introduces XC-Cache, a model architecture that uses cross-attention for efficient in-context learning in large language models during inference, outperforming traditional methods and significantly reducing memory requirements.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>$C^2$: Scalable Auto-Feedback for LLM-based Chart Generation</title><link>https://arxiv.org/abs/2410.18652</link><description>https://arxiv.org/abs/2410.18652&lt;br /&gt;The paper introduces LABE, a benchmark to evaluate social biases in language agency in content generated by large language models (LLMs), revealing significant gender, racial, and intersectional biases, particularly against demographic groups such as Black females.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Health Misinformation in Social Networks: A Survey of IT Approaches</title><link>https://arxiv.org/abs/2410.18670</link><description>https://arxiv.org/abs/2410.18670&lt;br /&gt;XC-Cache introduces a cross-attention framework for efficient large language model inference, improving conditional generation and reducing space requirements by avoiding traditional context caching.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>A Little Help Goes a Long Way: Efficient LLM Training by Leveraging Small LMs</title><link>https://arxiv.org/abs/2410.18779</link><description>https://arxiv.org/abs/2410.18779&lt;br /&gt;The paper introduces XC-Cache, a cross-attention mechanism for efficient LLM inference that reduces space requirements by using encoder-decoder inspired architecture to condition generation on reference text, outperforming traditional in-context learning in question-answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>An LLM Agent for Automatic Geospatial Data Analysis</title><link>https://arxiv.org/abs/2410.18792</link><description>https://arxiv.org/abs/2410.18792&lt;br /&gt;XC-Cache introduces an efficient inference method for large language models in question-answering tasks by using cross-attention mechanisms to condition generation on reference context, drastically reducing memory requirements compared to traditional in-context learning approaches.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>A Combinatorial Approach to Neural Emergent Communication</title><link>https://arxiv.org/abs/2410.18806</link><description>https://arxiv.org/abs/2410.18806&lt;br /&gt;XC-Cache introduces a method using cross-attention to efficiently condition language model generation on reference text, drastically reducing the space needed compared to standard key-value caching, and demonstrating effectiveness in question-answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Demystifying Large Language Models for Medicine: A Primer</title><link>https://arxiv.org/abs/2410.18856</link><description>https://arxiv.org/abs/2410.18856&lt;br /&gt;The paper introduces XC-Cache, a model that uses cross-attention instead of prompts to condition large language model generation on reference text, thereby improving efficiency and reducing cache space requirements, and demonstrates its effectiveness in question-answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Provably Robust Watermarks for Open-Source Language Models</title><link>https://arxiv.org/abs/2410.18861</link><description>https://arxiv.org/abs/2410.18861&lt;br /&gt;XC-Cache introduces a cross-attention based approach to efficiently condition large language model inference on reference text without prompts, reducing cache requirements and improving performance on question-answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Schema-Guided Culture-Aware Complex Event Simulation with Multi-Agent Role-Play</title><link>https://arxiv.org/abs/2410.18935</link><description>https://arxiv.org/abs/2410.18935&lt;br /&gt;The paper introduces XC-Cache, a model that utilizes cross-attention for conditional generation in LLMs to efficiently perform question-answering tasks, significantly reducing memory usage compared to conventional caching methods.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning</title><link>https://arxiv.org/abs/2410.18963</link><description>https://arxiv.org/abs/2410.18963&lt;br /&gt;XC-Cache introduces a model that leverages cross-attention for efficient language model inference by using cached context without relying on prompts, offering improved performance and reduced space requirements compared to traditional caching methods.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms</title><link>https://arxiv.org/abs/2410.18967</link><description>https://arxiv.org/abs/2410.18967&lt;br /&gt;The paper introduces XC-Cache, a model that uses cross-attention to condition generation on reference text, improving efficiency and storage in in-context learning without sacrificing performance compared to traditional methods.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Unbounded: A Generative Infinite Game of Character Life Simulation</title><link>https://arxiv.org/abs/2410.18975</link><description>https://arxiv.org/abs/2410.18975&lt;br /&gt;The paper introduces XC-Cache, a model using cross-attention to efficiently condition decoder-only LLM generation on reference contexts without prompting, reducing cache space requirements while maintaining performance in question-answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>CAMEL-Bench: A Comprehensive Arabic LMM Benchmark</title><link>https://arxiv.org/abs/2410.18976</link><description>https://arxiv.org/abs/2410.18976&lt;br /&gt;XC-Cache introduces an efficient in-context learning approach by using cross-attention to condition language model generation on reference text, significantly reducing memory footprint compared to traditional KV caching in self-attention operations.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>RET-LLM: Towards a General Read-Write Memory for Large Language Models</title><link>https://arxiv.org/abs/2305.14322</link><description>https://arxiv.org/abs/2305.14322&lt;br /&gt;XC-Cache introduces cross-attention mechanisms for efficient language model inference by conditioning generation on reference text without prompts, improving performance and reducing cache space requirements in question-answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Head-wise Shareable Attention for Large Language Models</title><link>https://arxiv.org/abs/2402.11819</link><description>https://arxiv.org/abs/2402.11819&lt;br /&gt;XC-Cache introduces a model that uses cross-attention for efficient large language model inference, reducing memory usage and enhancing conditional text generation without traditional prompts.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models</title><link>https://arxiv.org/abs/2403.00953</link><description>https://arxiv.org/abs/2403.00953&lt;br /&gt;XC-Cache enhances efficient LLM inference by using a cross-attention mechanism to leverage cached contexts without prompts, significantly reducing memory space requirements and maintaining competitive performance in question-answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>White Men Lead, Black Women Help? Benchmarking Language Agency Social Biases in LLMs</title><link>https://arxiv.org/abs/2404.10508</link><description>https://arxiv.org/abs/2404.10508&lt;br /&gt;XC-Cache introduces a model that uses cross-attention to condition language model generation on reference text without using prompts, improving efficiency in Question-Answering tasks while significantly reducing memory requirements.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>XC-Cache: Cross-Attending to Cached Context for Efficient LLM Inference</title><link>https://arxiv.org/abs/2404.15420</link><description>https://arxiv.org/abs/2404.15420&lt;br /&gt;XC-Cache introduces a cross-attention mechanism in transformer models to improve efficiency in language model inference by reducing the space footprint of in-context learning, and demonstrates its effectiveness in question-answering tasks.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>AutoPSV: Automated Process-Supervised Verifier</title><link>https://arxiv.org/abs/2405.16802</link><description>https://arxiv.org/abs/2405.16802&lt;br /&gt;The paper presents a scaling law that describes the cross-entropy loss curves of neural language models during training, incorporating learning rate annealing, and demonstrates its application in predicting model loss across different learning rate schedulers, thereby improving training efficiency and understanding.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>On the Noise Robustness of In-Context Learning for Text Generation</title><link>https://arxiv.org/abs/2405.17264</link><description>https://arxiv.org/abs/2405.17264&lt;br /&gt;The paper presents ALT (ALignment with Textual feedback), a method to align language models with user preferences expressed in text, showing its effectiveness in various tasks like toxicity reduction and summarization by conditioning model generation on textual feedback.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Analyzing Human Questioning Behavior and Causal Curiosity through Natural Queries</title><link>https://arxiv.org/abs/2405.20318</link><description>https://arxiv.org/abs/2405.20318&lt;br /&gt;The paper introduces ALT (ALignment with Textual feedback), an approach that aligns language models with user preferences expressed through textual feedback, achieving improvements in tasks like toxicity reduction and summarization while using fewer samples.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>CollabStory: Multi-LLM Collaborative Story Generation and Authorship Analysis</title><link>https://arxiv.org/abs/2406.12665</link><description>https://arxiv.org/abs/2406.12665&lt;br /&gt;The paper presents ALT, a method aligning language models with user preferences through textual feedback, offering expressiveness and efficiency across tasks like toxicity reduction and summarization, while outperforming traditional approaches.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Cutting Through the Noise: Boosting LLM Performance on Math Word Problems</title><link>https://arxiv.org/abs/2406.15444</link><description>https://arxiv.org/abs/2406.15444&lt;br /&gt;The paper presents ALT, a method that aligns language models with user preferences through textual feedback, demonstrating superior performance and efficiency across various tasks such as toxicity reduction and summarization compared to traditional PPO approaches.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>"Vorbe\c{s}ti Rom\^ane\c{s}te?" A Recipe to Train Powerful Romanian LLMs with English Instructions</title><link>https://arxiv.org/abs/2406.18266</link><description>https://arxiv.org/abs/2406.18266&lt;br /&gt;The paper introduces ALT, an approach that aligns language models with user preferences expressed in text, demonstrating superior performance to PPO in tasks like toxicity reduction and exploring efficiency and effectiveness in various tasks through textual feedback.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Zero-shot Persuasive Chatbots with LLM-Generated Strategies and Information Retrieval</title><link>https://arxiv.org/abs/2407.03585</link><description>https://arxiv.org/abs/2407.03585&lt;br /&gt;The paper introduces ALT, an approach for aligning language models with textual feedback to improve performance on tasks like toxicity reduction, summarization, and dialogue response, and argues that text provides richer feedback than simple preferences.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Self-training Language Models for Arithmetic Reasoning</title><link>https://arxiv.org/abs/2407.08400</link><description>https://arxiv.org/abs/2407.08400&lt;br /&gt;The paper presents a scaling law for neural language models that accounts for learning rate annealing over training steps, allowing for accurate prediction of validation loss across different learning rate schedulers, thereby reducing computational costs and improving understanding of training dynamics.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>MoESD: Mixture of Experts Stable Diffusion to Mitigate Gender Bias</title><link>https://arxiv.org/abs/2407.11002</link><description>https://arxiv.org/abs/2407.11002&lt;br /&gt;This paper introduces a new approach called ALT (Alignment with Textual feedback) to align language models with user preferences expressed in text, showing improvements in tasks such as toxicity reduction and summarization by utilizing more expressive feedback mechanisms.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Localizing and Mitigating Errors in Long-form Question Answering</title><link>https://arxiv.org/abs/2407.11930</link><description>https://arxiv.org/abs/2407.11930&lt;br /&gt;The paper proposes ALT (Alignment with Textual feedback), a method to align language models with user preferences expressed in text, demonstrating that text feedback can enhance model alignment in various tasks such as toxicity reduction, summarization, and dialog response generation, outperforming traditional methods.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval</title><link>https://arxiv.org/abs/2407.12883</link><description>https://arxiv.org/abs/2407.12883&lt;br /&gt;This paper introduces ALT, a method that aligns language models with user preferences through rich textual feedback, demonstrating effectiveness in tasks like toxicity reduction, summarization, and dialog response generation compared to traditional methods.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Learning Goal-Conditioned Representations for Language Reward Models</title><link>https://arxiv.org/abs/2407.13887</link><description>https://arxiv.org/abs/2407.13887&lt;br /&gt;The paper proposes ALT (ALignment with Textual feedback), a method that enhances language model alignment using user-preference textual feedback, demonstrating efficiency and effectiveness across tasks like toxicity reduction, summarization, and dialogue response generation.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Towards Aligning Language Models with Textual Feedback</title><link>https://arxiv.org/abs/2407.16970</link><description>https://arxiv.org/abs/2407.16970&lt;br /&gt;This paper presents ALT (Alignment with Textual feedback), a method for aligning language models with user preferences using textual feedback, demonstrating improved performance in reducing toxicity and matching summarization capabilities while offering insights into natural language feedback alignment.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Scaling Law with Learning Rate Annealing</title><link>https://arxiv.org/abs/2408.11029</link><description>https://arxiv.org/abs/2408.11029&lt;br /&gt;The paper introduces ALT, an approach that leverages textual feedback to align language models with user preferences, enhancing efficiency and effectiveness in tasks such as toxicity reduction and dialog response generation.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Effects of Scale on Language Model Robustness</title><link>https://arxiv.org/abs/2407.18213</link><description>https://arxiv.org/abs/2407.18213&lt;br /&gt;This study explores the interactions between humanoid robots NAO and Pepper, demonstrating their potential in educational settings for autonomous communication, collaboration, and the integration of AI to enhance learning and social skills among students.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Uncovering Biases with Reflective Large Language Models</title><link>https://arxiv.org/abs/2408.13464</link><description>https://arxiv.org/abs/2408.13464&lt;br /&gt;This study explores the autonomous communication and collaboration between humanoid robots NAO and Pepper in educational settings, highlighting their potential to enhance learning environments and develop social and emotional skills in students.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets</title><link>https://arxiv.org/abs/2409.04286</link><description>https://arxiv.org/abs/2409.04286&lt;br /&gt;The study explores the interaction between humanoid robots NAO and Pepper in educational settings, demonstrating their potential for autonomous communication and collaboration to enhance learning environments.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>DENEB: A Hallucination-Robust Automatic Evaluation Metric for Image Captioning</title><link>https://arxiv.org/abs/2409.19255</link><description>https://arxiv.org/abs/2409.19255&lt;br /&gt;This study explores interactions between humanoid robots NAO and Pepper for autonomous communication and collaboration, highlighting potential applications in enhancing educational environments with AI integration.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Composing Global Optimizers to Reasoning Tasks via Algebraic Objects in Neural Nets</title><link>https://arxiv.org/abs/2410.01779</link><description>https://arxiv.org/abs/2410.01779&lt;br /&gt;This study explores the interactions between humanoid robots NAO and Pepper in educational settings, highlighting their capabilities for autonomous communication and collaboration to enhance learning environments through artificial intelligence integration.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Learning Code Preference via Synthetic Evolution</title><link>https://arxiv.org/abs/2410.03837</link><description>https://arxiv.org/abs/2410.03837&lt;br /&gt;The study examines the autonomous communication and collaborative capabilities of humanoid robots NAO and Pepper in educational environments, highlighting their potential to enhance learning and social skill development through AI integration.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Chain of Ideas: Revolutionizing Research in Novel Idea Development with LLM Agents</title><link>https://arxiv.org/abs/2410.13185</link><description>https://arxiv.org/abs/2410.13185&lt;br /&gt;This study explores the interaction between humanoid robots NAO and Pepper, showcasing their capabilities for autonomous communication and collaboration in educational settings, and highlights their potential for enhancing learning environments with AI integration.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>ViConsFormer: Constituting Meaningful Phrases of Scene Texts using Transformer-based Method in Vietnamese Text-based Visual Question Answering</title><link>https://arxiv.org/abs/2410.14132</link><description>https://arxiv.org/abs/2410.14132&lt;br /&gt;The study explores the interaction between humanoid robots NAO and Pepper to develop autonomous communication and collaboration, showcasing their potential as educational tools for enhancing learning and developing social skills.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>RSA-Control: A Pragmatics-Grounded Lightweight Controllable Text Generation Framework</title><link>https://arxiv.org/abs/2410.19109</link><description>https://arxiv.org/abs/2410.19109&lt;br&gt;This paper investigates the impact of pruning large language models on reducing hallucinations during abstractive summarization, finding that pruned models exhibit less hallucination by relying more on the source document.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal Assistant</title><link>https://arxiv.org/abs/2410.19144</link><description>https://arxiv.org/abs/2410.19144&lt;br&gt;The paper investigates the impact of model pruning on hallucination occurrences in large language models used for abstractive summarization, finding that pruned models tend to hallucinate less and rely more on source documents.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Adversarial Attacks on Large Language Models Using Regularized Relaxation</title><link>https://arxiv.org/abs/2410.19160</link><description>https://arxiv.org/abs/2410.19160&lt;br&gt;The paper investigates the effect of pruning on hallucinations in large language models for abstractive summarization and finds that pruned models exhibit fewer hallucinations, likely due to increased reliance on the source document.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark</title><link>https://arxiv.org/abs/2410.19168</link><description>https://arxiv.org/abs/2410.19168&lt;br&gt;This paper explores the impact of pruning on large language models used for abstractive summarization, finding that pruned models exhibit fewer hallucinations by depending more on the source document.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Indication Finding: a novel use case for representation learning</title><link>https://arxiv.org/abs/2410.19174</link><description>https://arxiv.org/abs/2410.19174&lt;br&gt;The paper investigates the impact of pruning on large language models (LLMs) used for abstractive summarization, finding that pruned models may reduce hallucinations by relying more on the source document.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Making Social Platforms Accessible: Emotion-Aware Speech Generation with Integrated Text Analysis</title><link>https://arxiv.org/abs/2410.19199</link><description>https://arxiv.org/abs/2410.19199&lt;br&gt;This paper provides an empirical study on the effects of pruning large language models on hallucinations during abstractive summarization, revealing that pruned models exhibit fewer hallucinations by relying more on source documents.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Inference time LLM alignment in single and multidomain preference spectrum</title><link>https://arxiv.org/abs/2410.19206</link><description>https://arxiv.org/abs/2410.19206&lt;br&gt;The paper investigates the effect of pruning on large language models for abstractive summarization, finding that pruned models exhibit fewer hallucinations due to increased reliance on the source document.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Mirror Matrix on the Wall: coding and vector notation as tools for introspection</title><link>https://arxiv.org/abs/2410.19549</link><description>https://arxiv.org/abs/2410.19549&lt;br&gt;This paper investigates the impact of pruning on hallucinations in large language models for abstractive summarization, finding that pruned models tend to exhibit fewer hallucinations due to increased reliance on the source document.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>IPPON: Common Sense Guided Informative Path Planning for Object Goal Navigation</title><link>https://arxiv.org/abs/2410.19697</link><description>https://arxiv.org/abs/2410.19697&lt;br&gt;This paper investigates the impact of pruning on hallucinations in large language models used for abstractive summarization, finding that pruned models impose less hallucinatory content due to increased reliance on the source document.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Towards End-to-End Open Conversational Machine Reading</title><link>https://arxiv.org/abs/2210.07113</link><description>https://arxiv.org/abs/2210.07113&lt;br&gt;This paper explores the impact of pruning on large language models (LLMs) for abstractive summarization, finding that pruned models exhibit fewer hallucinations by relying more on source documents, thus producing summaries with higher lexical overlap.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Demonstration-based learning for few-shot biomedical named entity recognition under machine reading comprehension</title><link>https://arxiv.org/abs/2308.06454</link><description>https://arxiv.org/abs/2308.06454&lt;br&gt;This paper investigates the impact of pruning on hallucinations in large language models used for abstractive summarization, finding that pruned models rely more on source documents, reducing hallucinations.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Hate speech detection in algerian dialect using deep learning</title><link>https://arxiv.org/abs/2309.11611</link><description>https://arxiv.org/abs/2309.11611&lt;br&gt;This paper investigates the impact of pruning on hallucinations in large language models used for abstractive summarization, finding that pruned models produce fewer hallucinations by relying more on source documents.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Large Language Models Can Be Contextual Privacy Protection Learners</title><link>https://arxiv.org/abs/2310.02469</link><description>https://arxiv.org/abs/2310.02469&lt;br&gt;The paper investigates how pruning reduces hallucinations in large language models (LLMs) used for abstractive summarization, finding that pruned models rely more on the source document and thus produce more accurate summaries.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models</title><link>https://arxiv.org/abs/2406.01436</link><description>https://arxiv.org/abs/2406.01436&lt;br&gt;This paper explores the impact of data augmentation techniques on improving confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, especially in safety-critical fields like healthcare and finance.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Shortcomings of LLMs for Low-Resource Translation: Retrieval and Understanding are Both the Problem</title><link>https://arxiv.org/abs/2406.15625</link><description>https://arxiv.org/abs/2406.15625&lt;br&gt;The paper examines the use of data augmentation methods to enhance confidence calibration and uncertainty estimation in Named Entity Recognition (NER) tasks, focusing on improving the applicability of DNNs in safety-critical fields like healthcare and finance.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>TinyAgent: Function Calling at the Edge</title><link>https://arxiv.org/abs/2409.00608</link><description>https://arxiv.org/abs/2409.00608&lt;br&gt;The paper proposes LoReKT, a low-resource knowledge tracing framework that employs supervised pre-training and importance mechanism fine-tuning to improve the transferability and performance of DLKT models in scenarios with limited student interaction data.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Bayesian scaling laws for in-context learning</title><link>https://arxiv.org/abs/2410.16531</link><description>https://arxiv.org/abs/2410.16531&lt;br&gt;The paper introduces LoReKT, a framework employing pre-training and an importance mechanism to enhance the performance of deep learning-based knowledge tracing models in low-resource settings by leveraging data from rich-resource datasets.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item><item><title>Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning</title><link>https://arxiv.org/abs/2403.06725</link><description>https://arxiv.org/abs/2403.06725&lt;br&gt;The paper introduces LoReKT, a framework for improving knowledge tracing tasks in low-resource settings by leveraging supervised pre-training and importance mechanism fine-tuning to enhance parameter adaptation and model performance.</description><pubDate>Mon, 28 Oct 2024 07:58:07 GMT</pubDate></item></channel></rss>