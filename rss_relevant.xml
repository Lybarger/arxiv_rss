<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>Relevant arXiv Papers</title><link>https://Lybarger.github.io/arxiv_rss/rss_relevant.xml</link><description>Relevant arXiv Papers</description><lastBuildDate>Thu, 24 Oct 2024 11:34:58 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>All Entities are Not Created Equal: Examining the Long Tail for Fine-Grained Entity Typing</title><link>https://arxiv.org/abs/2410.17355</link><description>https://arxiv.org/abs/2410.17355&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) system evaluates the distinct personality traits of Large Language Models (LLMs) by adapting a personality assessment questionnaire to their outputs, enabling quantitative measurement of their linguistic personalities and contributing to Human-Computer Interaction research.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Artificial Intelligence in Brazilian News: A Mixed-Methods Analysis</title><link>https://arxiv.org/abs/2410.17423</link><description>https://arxiv.org/abs/2410.17423&lt;br /&gt;The LMLPA introduces a system for assessing the linguistic personality traits of Large Language Models (LLMs) using an adapted version of the Big Five Inventory, demonstrating that LLMs exhibit distinct personality traits that can be quantitatively analyzed, thereby contributing to Human-Computer Interaction and Human-Centered AI.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Navigate Complex Physical Worlds via Geometrically Constrained LLM</title><link>https://arxiv.org/abs/2410.17529</link><description>https://arxiv.org/abs/2410.17529&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a framework for evaluating the linguistic personalities of Large Language Models (LLMs) using an adapted version of the Big Five Inventory, enabling the quantification of personality traits reflected in their language generation outputs.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>MM-Eval: A Multilingual Meta-Evaluation Benchmark for LLM-as-a-Judge and Reward Models</title><link>https://arxiv.org/abs/2410.17578</link><description>https://arxiv.org/abs/2410.17578&lt;br /&gt;LMLPA introduces a framework for assessing the linguistic personalities of Large Language Models (LLMs) by adapting the Big Five Inventory to evaluate LLM-generated text, enhancing understanding of LLMs' language capabilities and contributing to fields like Human-Computer Interaction.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Cross-model Control: Improving Multiple Large Language Models in One-time Training</title><link>https://arxiv.org/abs/2410.17599</link><description>https://arxiv.org/abs/2410.17599&lt;br /&gt;The Language Model Linguistic Personality Assessment (LMLPA) introduces a system for evaluating the linguistic personalities of Large Language Models (LLMs) by adapting personality assessment frameworks to quantify personality traits reflected in their language generation capabilities.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Together We Can: Multilingual Automatic Post-Editing for Low-Resource Languages</title><link>https://arxiv.org/abs/2410.17973</link><description>https://arxiv.org/abs/2410.17973&lt;br /&gt;The paper presents a CPI+DMC approach for the early detection of signs of anorexia, emphasizing a time-aware methodology that integrates temporal factors into the learning process, leading to significant improvements in detection precision and speed as measured by the ERDE metrics.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Cross-lingual Transfer of Reward Models in Multilingual Alignment</title><link>https://arxiv.org/abs/2410.18027</link><description>https://arxiv.org/abs/2410.18027&lt;br /&gt;This research paper presents a time-aware approach for the early detection of anorexia that combines precision and speed as a single objective, utilizing temporal metrics in the learning process to achieve strong performance in the eRisk 2024 competition.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Key Algorithms for Keyphrase Generation: Instruction-Based LLMs for Russian Scientific Keyphrases</title><link>https://arxiv.org/abs/2410.18040</link><description>https://arxiv.org/abs/2410.18040&lt;br /&gt;The paper presents a time-aware approach for early detection of anorexia, implementing a CPI+DMC methodology that balances precision and speed, and integrates temporal metrics in the learning process, achieving notable performance in risk detection tasks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>LongRAG: A Dual-Perspective Retrieval-Augmented Generation Paradigm for Long-Context Question Answering</title><link>https://arxiv.org/abs/2410.18050</link><description>https://arxiv.org/abs/2410.18050&lt;br /&gt;This research paper presents a time-aware approach to early detection of anorexia in an online environment, utilizing a CPI+DMC framework and incorporating temporal metrics to enhance both precision and speed in identifying early risk signs.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Temporal Relational Reasoning of Large Language Models for Detecting Stock Portfolio Crashes</title><link>https://arxiv.org/abs/2410.17266</link><description>https://arxiv.org/abs/2410.17266&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, utilizing a combined model that optimizes both precision and speed in identifying risk signs, achieving notable results in the context of the eRisk 2024 competition.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Are Large Language Models Ready for Travel Planning?</title><link>https://arxiv.org/abs/2410.17333</link><description>https://arxiv.org/abs/2410.17333&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, integrating precision and speed into a combined objective during the learning process, leading to improved performance metrics in detecting early signs of anorexia.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Intera\c{c}\~ao entre rob\^os humanoides: desenvolvendo a colabora\c{c}\~ao e comunica\c{c}\~ao aut\^onoma</title><link>https://arxiv.org/abs/2410.17450</link><description>https://arxiv.org/abs/2410.17450&lt;br /&gt;The study proposes a time-aware approach to early detection of anorexia by integrating temporal factors into the learning process, focusing on both precision and speed in risk detection, and achieving strong results in established evaluation metrics.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Decoding Time Series with LLMs: A Multi-Agent Framework for Cross-Domain Annotation</title><link>https://arxiv.org/abs/2410.17462</link><description>https://arxiv.org/abs/2410.17462&lt;br /&gt;This paper presents a time-aware method for early detection of anorexia, incorporating precision and speed as combined objectives during training, which yielded strong performance in the eRisk 2024 competition.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Which Client is Reliable?: A Reliable and Personalized Prompt-based Federated Learning for Medical Image Question Answering</title><link>https://arxiv.org/abs/2410.17484</link><description>https://arxiv.org/abs/2410.17484&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, optimizing precision and speed in risk detection through a combined objective learning process and achieving exceptional results on relevant metrics.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Mechanisms of Symbol Processing for In-Context Learning in Transformer Networks</title><link>https://arxiv.org/abs/2410.17498</link><description>https://arxiv.org/abs/2410.17498&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia within the eRisk 2024 framework, using a CPI+DMC methodology and integrating temporal metrics to improve both precision and speed in detecting early risk signs on the web.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control</title><link>https://arxiv.org/abs/2410.17520</link><description>https://arxiv.org/abs/2410.17520&lt;br /&gt;This research paper presents a time-aware approach for the early detection of anorexia, focusing on precision and speed in the detection process, where temporal metrics were integrated into the learning phase to optimize model performance on relevant tasks in the eRisk 2024 competition.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Differentially Private Learning Needs Better Model Initialization and Self-Distillation</title><link>https://arxiv.org/abs/2410.17566</link><description>https://arxiv.org/abs/2410.17566&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, focusing on precision and speed by integrating temporal aspects into the learning process, leading to high performance on relevant evaluation metrics.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Markov Chain of Thought for Efficient Mathematical Reasoning</title><link>https://arxiv.org/abs/2410.17635</link><description>https://arxiv.org/abs/2410.17635&lt;br /&gt;This paper discusses a time-aware approach for the early detection of anorexia within an online risk detection framework, highlighting a novel CPI+DMC strategy that integrates temporal metrics in the learning process to enhance both precision and speed in identifying signs of the disorder.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>A Time-Aware Approach to Early Detection of Anorexia: UNSL at eRisk 2024</title><link>https://arxiv.org/abs/2410.17963</link><description>https://arxiv.org/abs/2410.17963&lt;br /&gt;This paper presents a time-aware approach for the early detection of anorexia, focusing on optimizing both precision and speed in the detection process through a CPI+DMC method and the integration of temporal metrics during model training.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>RaTEScore: A Metric for Radiology Report Generation</title><link>https://arxiv.org/abs/2406.16845</link><description>https://arxiv.org/abs/2406.16845&lt;br /&gt;This paper explores the security challenges associated with the proliferation of Generative AI across various industries and proposes potential research directions for mitigating these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Selective Vision is the Challenge for Visual Reasoning: A Benchmark for Visual Argument Understanding</title><link>https://arxiv.org/abs/2406.18925</link><description>https://arxiv.org/abs/2406.18925&lt;br /&gt;This paper explores the security challenges associated with the growing use of Generative AI across various industries and suggests potential research directions to address these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Attribute or Abstain: Large Language Models as Long Document Assistants</title><link>https://arxiv.org/abs/2407.07799</link><description>https://arxiv.org/abs/2407.07799&lt;br /&gt;This paper discusses the security challenges introduced by generative AI technologies across various industries and proposes potential research directions for addressing these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>S2-Attention: Hardware-Aware Context Sharding Among Attention Heads</title><link>https://arxiv.org/abs/2407.17678</link><description>https://arxiv.org/abs/2407.17678&lt;br /&gt;This paper discusses the security challenges associated with the growing adoption of Generative AI across various industries and suggests potential research directions for mitigating these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>NVLM: Open Frontier-Class Multimodal LLMs</title><link>https://arxiv.org/abs/2409.11402</link><description>https://arxiv.org/abs/2409.11402&lt;br /&gt;This paper examines the unique security challenges associated with Generative AI's proliferation across various industries and proposes research directions to address these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>MADial-Bench: Towards Real-world Evaluation of Memory-Augmented Dialogue Generation</title><link>https://arxiv.org/abs/2409.15240</link><description>https://arxiv.org/abs/2409.15240&lt;br /&gt;This paper analyzes the security challenges introduced by Generative AI across various industries and proposes potential research directions for addressing these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>A Comparative Study on Reasoning Patterns of OpenAI's o1 Model</title><link>https://arxiv.org/abs/2410.13639</link><description>https://arxiv.org/abs/2410.13639&lt;br /&gt;This paper addresses the security challenges associated with the proliferation of Generative AI technologies across various industries and proposes potential research directions for mitigating these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>1-bit AI Infra: Part 1.1, Fast and Lossless BitNet b1.58 Inference on CPUs</title><link>https://arxiv.org/abs/2410.16144</link><description>https://arxiv.org/abs/2410.16144&lt;br /&gt;This paper explores the security challenges associated with the growing use of Generative AI across various industries and suggests potential research directions to address these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Linear Adversarial Concept Erasure</title><link>https://arxiv.org/abs/2201.12091</link><description>https://arxiv.org/abs/2201.12091&lt;br /&gt;This paper discusses the security challenges posed by Generative AI as it becomes more prevalent across various industries and proposes potential research directions to manage these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Captions Speak Louder than Images (CASLIE): Generalizing Foundation Models for E-commerce from High-quality Multimodal Instruction Data</title><link>https://arxiv.org/abs/2410.17337</link><description>https://arxiv.org/abs/2410.17337&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system to quantitatively assess the linguistic personalities of Large Language Models (LLMs) using a modified Big Five Inventory, highlighting distinct personality traits in LLMs for Human-Computer Interaction and Human-Centered AI applications.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>AMUSD: Asynchronous Multi-Device Speculative Decoding for LLM Acceleration</title><link>https://arxiv.org/abs/2410.17375</link><description>https://arxiv.org/abs/2410.17375&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the linguistic personalities of large language models (LLMs) using an adapted Big Five Inventory to provide quantitative assessments of personality traits in LLMs' outputs.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference Under Ambiguities</title><link>https://arxiv.org/abs/2410.17385</link><description>https://arxiv.org/abs/2410.17385&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the personality traits of Large Language Models using a modified version of the Big Five Inventory, contributing to Human-Computer Interaction research by providing quantifiable measures of AI personality traits.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Scalable Influence and Fact Tracing for Large Language Model Pretraining</title><link>https://arxiv.org/abs/2410.17413</link><description>https://arxiv.org/abs/2410.17413&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA) to evaluate the personality traits of large language models (LLMs) through linguistic outputs, applying an adapted Big Five Inventory framework and demonstrating their distinct personality profiles.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Evaluating AI-Generated Essays with GRE Analytical Writing Assessment</title><link>https://arxiv.org/abs/2410.17439</link><description>https://arxiv.org/abs/2410.17439&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating personality traits of large language models based on their linguistic outputs, using a modified version of the Big Five Inventory to provide insights into their conversational capabilities.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>In Context Learning and Reasoning for Symbolic Regression with Large Language Models</title><link>https://arxiv.org/abs/2410.17448</link><description>https://arxiv.org/abs/2410.17448&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system designed to assess the personality traits of Large Language Models (LLMs) by adapting human-centric psychometric methods to evaluate their linguistic outputs.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Do Robot Snakes Dream like Electric Sheep? Investigating the Effects of Architectural Inductive Biases on Hallucination</title><link>https://arxiv.org/abs/2410.17477</link><description>https://arxiv.org/abs/2410.17477&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system to evaluate and quantify the distinct personality traits of Large Language Models (LLMs) using adapted psychometric techniques.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Is artificial intelligence still intelligence? LLMs generalize to novel adjective-noun pairs, but don't mimic the full human distribution</title><link>https://arxiv.org/abs/2410.17482</link><description>https://arxiv.org/abs/2410.17482&lt;br&gt;The LMLPA system evaluates and quantifies the linguistic personalities of Large Language Models using a modified Big Five Inventory, contributing to the understanding of LLMs in conversational interactions.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>VoiceTextBlender: Augmenting Large Language Models with Speech Capabilities via Single-Stage Joint Speech-Text Supervised Fine-Tuning</title><link>https://arxiv.org/abs/2410.17485</link><description>https://arxiv.org/abs/2410.17485&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the linguistic personalities of large language models (LLMs) using a questionnaire based on the Big Five Inventory, adapted for LLMs to assess their language generation capabilities in conversational settings.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Large Language Models Still Exhibit Bias in Long Text</title><link>https://arxiv.org/abs/2410.17519</link><description>https://arxiv.org/abs/2410.17519&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a system designed to evaluate and quantify the linguistic personality traits of large language models using the Big Five Inventory for better understanding of their language generation capabilities.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Responsible Multilingual Large Language Models: A Survey of Development, Applications, and Societal Impact</title><link>https://arxiv.org/abs/2410.17532</link><description>https://arxiv.org/abs/2410.17532&lt;br&gt;The paper presents the Language Model Linguistic Personality Assessment (LMLPA), a system for evaluating the distinct personality traits of LLMs through adapted Big Five Inventory-based psychometrics, contributing insights into LLMs' language generation capabilities and their applications in Human-Computer Interaction and AI.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification</title><link>https://arxiv.org/abs/2410.17546</link><description>https://arxiv.org/abs/2410.17546&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA) to evaluate and quantify distinct personality traits of Large Language Models (LLMs) through a modified Big Five Inventory, contributing to improvements in Human-Computer Interaction and Human-Centered AI.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>ESpeW: Robust Copyright Protection for LLM-based EaaS via Embedding-Specific Watermark</title><link>https://arxiv.org/abs/2410.17552</link><description>https://arxiv.org/abs/2410.17552&lt;br&gt;LMLPA introduces a system to evaluate the linguistic personalities of LLMs using an adapted Big Five Inventory questionnaire to quantitatively assess personality traits in AI-generated text, contributing to Human-Computer Interaction and Human-Centered AI.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Graphusion: A RAG Framework for Knowledge Graph Construction with a Global Perspective</title><link>https://arxiv.org/abs/2410.17600</link><description>https://arxiv.org/abs/2410.17600&lt;br&gt;The paper introduces the Language Model Linguistic Personality Assessment (LMLPA) to evaluate the linguistic personalities of large language models (LLMs), adapting the Big Five Inventory for measuring personality traits in LLMs to improve understanding of their language generation capabilities.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>LMLPA: Language Model Linguistic Personality Assessment</title><link>https://arxiv.org/abs/2410.17632</link><description>https://arxiv.org/abs/2410.17632&lt;br&gt;This paper introduces the Language Model Linguistic Personality Assessment (LMLPA), a framework for evaluating the linguistic personalities of Large Language Models (LLMs) by adapting a personality assessment questionnaire to measure distinct personality traits in their linguistic outputs.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents</title><link>https://arxiv.org/abs/2410.17657</link><description>https://arxiv.org/abs/2410.17657&lt;br&gt;The paper analyzes changes in the German political discourse from 1871 to present using a time-series variant of LDA to identify significant events and shifts in political topics, leveraging digitized plenary session logs of the German Bundestag.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Quantifying the Risks of Tool-assisted Rephrasing to Linguistic Diversity</title><link>https://arxiv.org/abs/2410.17670</link><description>https://arxiv.org/abs/2410.17670&lt;br&gt;The paper utilizes a time series variant of LDA to analyze digitized plenary sessions of the German Bundestag, identifying changes and lasting impacts on political discourse from 1949 to the present.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Towards a Similarity-adjusted Surprisal Theory</title><link>https://arxiv.org/abs/2410.17676</link><description>https://arxiv.org/abs/2410.17676&lt;br&gt;The paper uses a time series variant of the topic model LDA to analyze changes in the German political discourse from the formation of the Federal Republic of Germany in 1949 onwards, identifying key events that have impacted political topics over the years.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>An Adaptive Framework for Generating Systematic Explanatory Answer in Online Q&amp;A Platforms</title><link>https://arxiv.org/abs/2410.17694</link><description>https://arxiv.org/abs/2410.17694&lt;br&gt;The paper analyzes texts from the German Bundestag using a time series variant of the topic model LDA to identify significant changes in political discourse over time.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Beware of Calibration Data for Pruning Large Language Models</title><link>https://arxiv.org/abs/2410.17711</link><description>https://arxiv.org/abs/2410.17711&lt;br&gt;The paper investigates changes in the German political discourse over time by analyzing texts from German Bundestag sessions using a time series variant of topic modeling LDA to detect shifts in political topics and key discussion points.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>CogSteer: Cognition-Inspired Selective Layer Intervention for Efficient Semantic Steering in Large Language Models</title><link>https://arxiv.org/abs/2410.17714</link><description>https://arxiv.org/abs/2410.17714&lt;br&gt;The paper examines changes in German political discourse over time using a time series model of LDA to analyze digitized texts from the Bundestag, focusing on how events have influenced political topics and word frequency.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Dialectal and Low Resource Machine Translation for Aromanian</title><link>https://arxiv.org/abs/2410.17728</link><description>https://arxiv.org/abs/2410.17728&lt;br&gt;The paper investigates changes in political discourse within the German Bundestag from 1871 onwards by using a time series variant of the LDA topic model to analyze the digitized transcripts of plenary sessions.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Local Contrastive Editing of Gender Stereotypes</title><link>https://arxiv.org/abs/2410.17739</link><description>https://arxiv.org/abs/2410.17739&lt;br&gt;This paper uses a time series variant of the topic model LDA to analyze changes in German political discourse by examining digitized plenary session texts from the German Bundestag over time.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Latent Structures of Intertextuality in French Fiction</title><link>https://arxiv.org/abs/2410.17759</link><description>https://arxiv.org/abs/2410.17759&lt;br&gt;The paper utilizes a time series variant of the topic model LDA to analyze the digitized plenary session logs of the German Bundestag, examining how political discourse and topics have evolved over time in response to significant events.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Understanding When Tree of Thoughts Succeeds: Larger Models Excel in Generation, Not Discrimination</title><link>https://arxiv.org/abs/2410.17820</link><description>https://arxiv.org/abs/2410.17820&lt;br&gt;This paper investigates changes in the German political discourse over time using a time series variant of the topic model LDA on digitized texts from the German Bundestag sessions.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Understanding Layer Significance in LLM Alignment</title><link>https://arxiv.org/abs/2410.17875</link><description>https://arxiv.org/abs/2410.17875&lt;br&gt;The paper analyzes the evolution of political discourse in the German Bundestag from 1949 onwards using a time series variant of the topic model LDA to detect changes in word frequency and key discussion points over time.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>SpeakGer: A meta-data enriched speech corpus of German state and federal parliaments</title><link>https://arxiv.org/abs/2410.17886</link><description>https://arxiv.org/abs/2410.17886&lt;br&gt;The paper explores changes in the German political discourse over time by applying a time series variant of the topic model LDA to Bundestag session logs, identifying key events and shifts in political topics.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Scaling Diffusion Language Models via Adaptation from Autoregressive Models</title><link>https://arxiv.org/abs/2410.17891</link><description>https://arxiv.org/abs/2410.17891&lt;br&gt;The paper analyzes changes in the German political discourse over time using a time series variant of the topic model LDA, examining how significant events influenced political topics in the Bundestag's digitized plenary sessions.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Value Residual Learning For Alleviating Attention Concentration In Transformers</title><link>https://arxiv.org/abs/2410.17897</link><description>https://arxiv.org/abs/2410.17897&lt;br&gt;This paper analyzes the German political discourse from 1949 onwards using a time series variant of the LDA topic model to detect changes in word frequency and key discussion points over time.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Zeitenwenden: Detecting changes in the German political discourse</title><link>https://arxiv.org/abs/2410.17960</link><description>https://arxiv.org/abs/2410.17960&lt;br&gt;The paper analyzes changes in the German political discourse over time using a time series variant of the topic model LDA to detect shifts in word frequency and key discussion points in the Bundestag plenary session texts.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Dependency Graph Parsing as Sequence Labeling</title><link>https://arxiv.org/abs/2410.17972</link><description>https://arxiv.org/abs/2410.17972&lt;br&gt;This research paper presents a time-aware approach for the early detection of anorexia by integrating time into the learning process, demonstrating effective performance in precision and speed using temporal metrics.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>MiLoRA: Efficient Mixture of Low-Rank Adaptation for Large Language Models Fine-tuning</title><link>https://arxiv.org/abs/2410.18035</link><description>https://arxiv.org/abs/2410.18035&lt;br&gt;This paper presents a time-aware approach for early detection of anorexia by integrating temporal metrics during training, achieving notable results in precision and speed for early risk detection tasks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Literature Meets Data: A Synergistic Approach to Hypothesis Generation</title><link>https://arxiv.org/abs/2410.17309</link><description>https://arxiv.org/abs/2410.17309&lt;br&gt;The paper discusses a time-aware approach to early detection of anorexia, focusing on the balance between precision and speed by integrating temporal metrics during training to optimize models for early risk detection on the web.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>AdvWeb: Controllable Black-box Attacks on VLM-powered Web Agents</title><link>https://arxiv.org/abs/2410.17401</link><description>https://arxiv.org/abs/2410.17401&lt;br&gt;The paper presents a time-aware approach for early detection of anorexia that integrates time in the learning process to optimize precision and speed, achieving significant results on the ERDE50 metric.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>BadFair: Backdoored Fairness Attacks with Group-conditioned Triggers</title><link>https://arxiv.org/abs/2410.17492</link><description>https://arxiv.org/abs/2410.17492&lt;br&gt;The paper presents a time-aware approach for the early detection of anorexia focused on enhancing precision and speed, using explicit time integration during the learning process to excel in early risk detection (ERD) metrics.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>ExpertFlow: Optimized Expert Activation and Token Allocation for Efficient Mixture-of-Experts Inference</title><link>https://arxiv.org/abs/2410.17954</link><description>https://arxiv.org/abs/2410.17954&lt;br&gt;The paper presents a time-aware method for the early detection of anorexia signs by integrating time explicitly during the learning process to optimize precision and speed using the ERDE metrics as objectives, achieving strong results in the eRisk 2024 challenge.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>A Bi-consolidating Model for Joint Relational Triple Extraction</title><link>https://arxiv.org/abs/2404.03881</link><description>https://arxiv.org/abs/2404.03881&lt;br&gt;The paper introduces a unified framework called Fast and Slow Generating (FS-GEN) to collaboratively decode between large and small language models, addressing challenges like latency and hallucinations by analyzing the effective conditions for their cooperation based on parameter scaling laws and uncertainty management.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Annotator-Centric Active Learning for Subjective NLP Tasks</title><link>https://arxiv.org/abs/2404.15720</link><description>https://arxiv.org/abs/2404.15720&lt;br&gt;The paper explores a collaborative decoding framework, Fast and Slow Generating (FS-GEN), leveraging large and small language models to mitigate challenges like high inference latency and generation of hallucinations, focusing on the distinct roles of fast, intuitive systems and slow, deliberate ones.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Learning to Plan for Retrieval-Augmented Large Language Models from Knowledge Graphs</title><link>https://arxiv.org/abs/2406.14282</link><description>https://arxiv.org/abs/2406.14282&lt;br&gt;The paper explores the unique security challenges associated with Generative AI and suggests potential research directions for managing these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Do LLMs Have Distinct and Consistent Personality? TRAIT: Personality Testset designed for LLMs with Psychometrics</title><link>https://arxiv.org/abs/2406.14703</link><description>https://arxiv.org/abs/2406.14703&lt;br&gt;This paper explores the security challenges associated with Generative AI and suggests potential research directions for mitigating these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>AlleNoise: large-scale text classification benchmark dataset with real-world label noise</title><link>https://arxiv.org/abs/2407.10992</link><description>https://arxiv.org/abs/2407.10992&lt;br&gt;This paper explores the security challenges posed by Generative AI and outlines potential research directions to manage these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>NutriBench: A Dataset for Evaluating Large Language Models in Carbohydrate Estimation from Meal Descriptions</title><link>https://arxiv.org/abs/2407.12843</link><description>https://arxiv.org/abs/2407.12843&lt;br&gt;The paper explores the security challenges presented by Generative AI as it becomes more prevalent across various industries, and suggests research directions for mitigating these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer</title><link>https://arxiv.org/abs/2408.01119</link><description>https://arxiv.org/abs/2408.01119&lt;br&gt;The paper discusses the security challenges posed by Generative AI and suggests potential research directions to manage these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Can Language Models Induce Grammatical Knowledge from Indirect Evidence?</title><link>https://arxiv.org/abs/2410.06022</link><description>https://arxiv.org/abs/2410.06022&lt;br&gt;The paper discusses the unique security challenges posed by Generative AI and suggests potential research directions to manage these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems</title><link>https://arxiv.org/abs/2410.13334</link><description>https://arxiv.org/abs/2410.13334&lt;br&gt;The paper discusses the unique security challenges of Generative AI and proposes research directions to manage these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>On the Diversity of Synthetic Data and its Impact on Training Large Language Models</title><link>https://arxiv.org/abs/2410.15226</link><description>https://arxiv.org/abs/2410.15226&lt;br&gt;The paper explores the security challenges associated with Generative AI across various industries and suggests research directions for risk management.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs</title><link>https://arxiv.org/abs/2410.15956</link><description>https://arxiv.org/abs/2410.15956&lt;br&gt;The paper explores the security challenges posed by Generative AI across various industries and suggests research directions to manage these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Susu Box or Piggy Bank: Assessing Cultural Commonsense Knowledge between Ghana and the U.S</title><link>https://arxiv.org/abs/2410.16451</link><description>https://arxiv.org/abs/2410.16451&lt;br&gt;The paper explores the unique security challenges posed by Generative AI and outlines potential research directions for managing these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Generative AI Security: Challenges and Countermeasures</title><link>https://arxiv.org/abs/2402.12617</link><description>https://arxiv.org/abs/2402.12617&lt;br&gt;The paper explores the security challenges associated with Generative AI and suggests potential research directions for managing these risks.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>LLMScan: Causal Scan for LLM Misbehavior Detection</title><link>https://arxiv.org/abs/2410.16638</link><description>https://arxiv.org/abs/2410.16638&lt;br&gt;LLMScan is a technique utilizing causality analysis to monitor and detect misbehavior in Large Language Models (LLMs) by analyzing causal contributions of input tokens and transformer layers.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item><item><title>Non-myopic Generation of Language Model for Reasoning and Planning</title><link>https://arxiv.org/abs/2410.17195</link><description>https://arxiv.org/abs/2410.17195&lt;br&gt;LLMScan introduces a causal inference-based technique to monitor and detect misbehavior in Large Language Models (LLMs) by analyzing the causal contributions of input tokens and transformer layers.</description><pubDate>Thu, 24 Oct 2024 11:34:58 GMT</pubDate></item></channel></rss>